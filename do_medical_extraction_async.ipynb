{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSPy 3.0.3 Medical Data Extraction Pipeline\n",
        "\n",
        "This notebook demonstrates a comprehensive data extraction pipeline using DSPy 3.0.3 to extract structured dichotomous outcomes from medical research papers in markdown format.\n",
        "\n",
        "## Objective\n",
        "Extract structured data from medical research markdown  into the target format matching `dichotomous_outcomes.json`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy version: 3.0.3\n"
          ]
        }
      ],
      "source": [
        "import dspy\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "import aiofiles\n",
        "import traceback\n",
        "\n",
        "import tiktoken\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "import hashlib\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import diskcache as dc\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Print DSPy version\n",
        "print(f\"DSPy version: {dspy.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure DSPy Language Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language model configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Set your API key (uncomment and add your key)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "\n",
        "# Configure DSPy with OpenAI GPT-4o-mini for cost efficiency\n",
        "#lm = dspy.LM('gemini/gemini-2.5-pro', max_tokens=20000, temperature=1.0)\n",
        "#lm = dspy.LM('openai/gpt-5-mini-2025-08-07', max_tokens=20000, temperature=1.0)\n",
        "lm = dspy.LM(\"anthropic/claude-sonnet-4-20250514\")\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"Language model configured successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = lm(\"\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DSpy History Details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New log file will be created: dspy_history.csv\n",
            "DSPy History Logger for Notebooks Ready!\n",
            "Usage:\n",
            "  set_log_file('my_file.csv')  # Set custom log file\n",
            "  log_history()                # Log current DSPy history\n",
            "  show_stats()                 # Show summary statistics\n",
            "  view_recent(5)               # View recent 5 calls\n",
            "  clear_cache()                # Clear processed cache\n",
            "  export_full_history()        # Export complete history to JSON\n",
            "Loaded 4104 existing records from /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n"
          ]
        }
      ],
      "source": [
        "# Global variables to track processed calls\n",
        "_processed_hashes = set()\n",
        "_csv_path = \"dspy_history.csv\"\n",
        "\n",
        "def set_log_file(csv_path: str):\n",
        "    \"\"\"Set the CSV file path for logging.\"\"\"\n",
        "    global _csv_path, _processed_hashes\n",
        "    _csv_path = csv_path\n",
        "    \n",
        "    # Load existing hashes from CSV if it exists\n",
        "    if Path(csv_path).exists():\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'call_hash' in df.columns:\n",
        "                _processed_hashes = set(df['call_hash'].tolist())\n",
        "                print(f\"Loaded {len(_processed_hashes)} existing records from {csv_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load existing CSV: {e}\")\n",
        "    else:\n",
        "        print(f\"New log file will be created: {csv_path}\")\n",
        "\n",
        "def log_history():\n",
        "    \"\"\"Log current DSPy history to CSV. Call this after running DSPy operations.\"\"\"\n",
        "    global _processed_hashes, _csv_path\n",
        "    \n",
        "    # Get LM from dspy settings\n",
        "    try:\n",
        "        lm = dspy.settings.lm\n",
        "    except:\n",
        "        print(\"Error: No LM found in dspy.settings\")\n",
        "        return 0\n",
        "    \n",
        "    if not hasattr(lm, 'history') or not lm.history:\n",
        "        print(\"No history found in language model\")\n",
        "        return 0\n",
        "    \n",
        "    new_records = []\n",
        "    \n",
        "    for call_data in lm.history:\n",
        "        # Generate unique hash\n",
        "        hash_content = {\n",
        "            'messages': call_data.get('messages', []),\n",
        "            'timestamp': call_data.get('timestamp', ''),\n",
        "            'uuid': call_data.get('uuid', ''),\n",
        "        }\n",
        "        call_hash = hashlib.md5(json.dumps(hash_content, sort_keys=True, default=str).encode()).hexdigest()\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if call_hash in _processed_hashes:\n",
        "            continue\n",
        "        \n",
        "        # Extract call info\n",
        "        messages = call_data.get('messages', [])\n",
        "        system_msg = next((m.get('content', '') for m in messages if m.get('role') == 'system'), '')\n",
        "        user_msg = next((m.get('content', '') for m in messages if m.get('role') == 'user'), '')\n",
        "        \n",
        "        # Extract response\n",
        "        response_obj = call_data.get('response', {})\n",
        "        assistant_response = \"\"\n",
        "        if hasattr(response_obj, 'choices') and response_obj.choices:\n",
        "            assistant_response = response_obj.choices[0].message.content\n",
        "        \n",
        "        # Extract usage\n",
        "        usage = call_data.get('usage', {})\n",
        "        if isinstance(usage, dict):\n",
        "            prompt_tokens = usage.get('prompt_tokens', 0)\n",
        "            completion_tokens = usage.get('completion_tokens', 0) \n",
        "            total_tokens = usage.get('total_tokens', 0)\n",
        "        else:\n",
        "            prompt_tokens = completion_tokens = total_tokens = 0\n",
        "        \n",
        "        record = {\n",
        "            'call_hash': call_hash,\n",
        "            'timestamp': call_data.get('timestamp', datetime.now().isoformat()),\n",
        "            'uuid': call_data.get('uuid', ''),\n",
        "            'model': call_data.get('model', ''),\n",
        "            'cost': call_data.get('cost', 0.0),\n",
        "            'prompt_tokens': prompt_tokens,\n",
        "            'completion_tokens': completion_tokens,\n",
        "            'total_tokens': total_tokens,\n",
        "            'system_msg_length': len(system_msg),\n",
        "            'user_msg_preview': user_msg[:200] if user_msg else '',\n",
        "            'response_preview': assistant_response[:200] if assistant_response else '',\n",
        "            'cache_hit': getattr(response_obj, 'cache_hit', False) if response_obj else False,\n",
        "            'logged_at': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        new_records.append(record)\n",
        "        _processed_hashes.add(call_hash)\n",
        "    \n",
        "    if not new_records:\n",
        "        print(\"No new records to add\")\n",
        "        return 0\n",
        "    \n",
        "    # Save to CSV\n",
        "    new_df = pd.DataFrame(new_records)\n",
        "    \n",
        "    if Path(_csv_path).exists():\n",
        "        new_df.to_csv(_csv_path, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        Path(_csv_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "        new_df.to_csv(_csv_path, index=False)\n",
        "    \n",
        "    print(f\"Added {len(new_records)} new records to {_csv_path}\")\n",
        "    return len(new_records)\n",
        "\n",
        "def show_stats():\n",
        "    \"\"\"Show statistics from the logged history.\"\"\"\n",
        "    global _csv_path\n",
        "    \n",
        "    if not Path(_csv_path).exists():\n",
        "        print(\"No history file found\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(_csv_path)\n",
        "        \n",
        "        print(f\"\\nDSPy History Stats from {_csv_path}:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Total calls: {len(df)}\")\n",
        "        \n",
        "        if 'model' in df.columns:\n",
        "            print(f\"Unique models: {df['model'].nunique()}\")\n",
        "            print(\"Model breakdown:\")\n",
        "            for model, count in df['model'].value_counts().head().items():\n",
        "                print(f\"  {model}: {count} calls\")\n",
        "        \n",
        "        if 'cost' in df.columns:\n",
        "            # If prompt_tokens == 0, set cost = 0 for those rows\n",
        "            df.loc[df['prompt_tokens'] == 0, 'cost'] = 0\n",
        "\n",
        "            # Recompute totals\n",
        "            total_cost = df['cost'].sum()\n",
        "            avg_cost = df['cost'].mean()\n",
        "\n",
        "            print(f\"Total cost: ${total_cost:.4f}\")\n",
        "            print(f\"Average cost per call: ${avg_cost:.4f}\")\n",
        "\n",
        "        \n",
        "        if 'total_tokens' in df.columns:\n",
        "            total_tokens = df['total_tokens'].sum()\n",
        "            avg_tokens = df['total_tokens'].mean()\n",
        "            print(f\"Total tokens: {total_tokens:,}\")\n",
        "            print(f\"Average tokens per call: {avg_tokens:.1f}\")\n",
        "        \n",
        "        if 'cache_hit' in df.columns:\n",
        "            cache_rate = df['cache_hit'].mean() * 100\n",
        "            print(f\"Cache hit rate: {cache_rate:.1f}%\")\n",
        "        \n",
        "        if 'timestamp' in df.columns:\n",
        "            print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading history: {e}\")\n",
        "\n",
        "def view_recent(n=5):\n",
        "    \"\"\"View the most recent n logged calls.\"\"\"\n",
        "    global _csv_path\n",
        "    \n",
        "    if not Path(_csv_path).exists():\n",
        "        print(\"No history file found\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(_csv_path)\n",
        "        recent = df.tail(n)\n",
        "        \n",
        "        print(f\"\\nMost Recent {n} DSPy Calls:\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        for _, row in recent.iterrows():\n",
        "            print(f\"Time: {row['timestamp']}\")\n",
        "            print(f\"Model: {row['model']}\")\n",
        "            print(f\"Tokens: {row['total_tokens']} | Cost: ${row['cost']:.4f}\")\n",
        "            print(f\"User: {row['user_msg_preview'][:100]}...\")\n",
        "            print(f\"Response: {row['response_preview'][:100]}...\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading history: {e}\")\n",
        "\n",
        "def clear_cache():\n",
        "    \"\"\"Clear the processed hashes cache (will reprocess all history next time).\"\"\"\n",
        "    global _processed_hashes\n",
        "    _processed_hashes.clear()\n",
        "    print(\"Cleared processed hashes cache\")\n",
        "\n",
        "def export_full_history(output_file: str = \"full_dspy_history.json\"):\n",
        "    \"\"\"Export complete DSPy history with full messages to JSON.\"\"\"\n",
        "    try:\n",
        "        lm = dspy.settings.lm\n",
        "        if hasattr(lm, 'history') and lm.history:\n",
        "            with open(output_file, 'w') as f:\n",
        "                json.dump(lm.history, f, indent=2, default=str)\n",
        "            print(f\"Exported full history to {output_file}\")\n",
        "        else:\n",
        "            print(\"No history found to export\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting history: {e}\")\n",
        "\n",
        "# Initialize with default file\n",
        "set_log_file(\"dspy_history.csv\")\n",
        "\n",
        "print(\"DSPy History Logger for Notebooks Ready!\")\n",
        "print(\"Usage:\")\n",
        "print(\"  set_log_file('my_file.csv')  # Set custom log file\")\n",
        "print(\"  log_history()                # Log current DSPy history\") \n",
        "print(\"  show_stats()                 # Show summary statistics\")\n",
        "print(\"  view_recent(5)               # View recent 5 calls\")\n",
        "print(\"  clear_cache()                # Clear processed cache\")\n",
        "print(\"  export_full_history()        # Export complete history to JSON\")\n",
        "\n",
        "# Cell 1: Set your log file\n",
        "set_log_file(\"/nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No history found in language model\n",
            "\n",
            "DSPy History Stats from /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv:\n",
            "==================================================\n",
            "Total calls: 4104\n",
            "Unique models: 3\n",
            "Model breakdown:\n",
            "  gemini/gemini-2.5-pro: 4016 calls\n",
            "  openai/gpt-5-mini-2025-08-07: 58 calls\n",
            "  openai/gpt-4o-mini: 30 calls\n",
            "Total cost: $16.5535\n",
            "Average cost per call: $0.0040\n",
            "Total tokens: 3,020,487\n",
            "Average tokens per call: 736.0\n",
            "Cache hit rate: 75.3%\n",
            "Date range: 2025-09-16T10:33:45.131530 to 2025-09-18T18:49:54.231071\n"
          ]
        }
      ],
      "source": [
        "#Log the history  \n",
        "log_history()\n",
        "\n",
        "#Check stats anytime\n",
        "show_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Safe Json Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_json_parse(json_string, fallback=None):\n",
        "    \"\"\"Robust JSON parser with multiple recovery strategies.\"\"\"\n",
        "    if fallback is None:\n",
        "        fallback = {}\n",
        "    \n",
        "    if not json_string or not isinstance(json_string, str):\n",
        "        return fallback\n",
        "    \n",
        "    # Clean markdown fences first\n",
        "    import re\n",
        "    json_string = re.sub(r\"```[a-zA-Z]*\\n?\", \"\", json_string).replace(\"```\", \"\")\n",
        "    json_string = json_string.strip()\n",
        "    \n",
        "    # Strategy 1: Direct parsing\n",
        "    try:\n",
        "        result = json.loads(json_string)\n",
        "        if isinstance(result, str) and result.strip().startswith((\"{\", \"[\")):\n",
        "            return safe_json_parse(result, fallback)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    \n",
        "    # Strategy 2: Clean common issues and handle nested single quotes\n",
        "    try:\n",
        "        cleaned = json_string.strip()\n",
        "        cleaned = cleaned.replace('\\n', '\\\\n').replace('\\r', '\\\\r').replace('\\t', '\\\\t')\n",
        "        cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n",
        "        \n",
        "        if cleaned.startswith(\"'\") or \"': '\" in cleaned or \"': {'\" in cleaned:\n",
        "            cleaned = cleaned.replace(\"'\", '\"')\n",
        "            cleaned = cleaned.replace('\"\"', '\"')\n",
        "        else:\n",
        "            cleaned = re.sub(r\"'([^']*)':\", r'\"\\1\":', cleaned)\n",
        "            cleaned = re.sub(r\":\\s*'([^']*)'\", r': \"\\1\"', cleaned)\n",
        "        \n",
        "        result = safe_json_parse(cleaned)\n",
        "        if isinstance(result, str) and result.strip().startswith((\"{\", \"[\")):\n",
        "            return safe_json_parse(result, fallback)\n",
        "        return result\n",
        "    except (json.JSONDecodeError, AttributeError):\n",
        "        pass\n",
        "    \n",
        "    # Strategy 3: Extract key-value pairs manually\n",
        "    try:\n",
        "        data = {}\n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*(\\d+(?:\\.\\d+)?)', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = float(value) if '.' in value else int(value)\n",
        "        \n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*\"([^\"]*)\"', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = value\n",
        "        \n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*(true|false)', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = value == 'true'\n",
        "        \n",
        "        if data:\n",
        "            return data\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return fallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['id', 'pdf_path', 'unique_filename', 'marker', 'status', 'processing_timestamp'])\n",
            "Markdown content length: 32729 characters\n",
            "Token count: 8122\n",
            "Target data contains 1691 records\n"
          ]
        }
      ],
      "source": [
        "# Load source file\n",
        "source_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2467_Malmstrom_md/2467_Malmstrom_md.json\"\n",
        "target_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/jsons/dichotomous_outcomes.json\"\n",
        "\n",
        "with open(source_file, 'r') as f:\n",
        "    source_data = json.load(f)\n",
        "\n",
        "with open(target_file, 'r') as f:\n",
        "    target_data = json.load(f)\n",
        "\n",
        "print(source_data.keys())\n",
        "\n",
        "# Extract markdown content\n",
        "markdown_content = source_data['marker']['markdown']\n",
        "\n",
        "# Use OpenAI tokenizer (cl100k_base is the same one GPT-4/4o/5 use)\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "tokens = encoding.encode(markdown_content)\n",
        "\n",
        "print(f\"Markdown content length: {len(markdown_content)} characters\")\n",
        "print(f\"Token count: {len(tokens)}\")\n",
        "print(f\"Target data contains {len(target_data)} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 records in target data\n",
            "\n",
            "Example target record structure:\n",
            "Ref_ID: 2467\n",
            "First_Author: Malmstrom\n",
            "Trial_Name: NR\n",
            "Population: 2\n",
            "Intervention_Code: 6\n",
            "Intervention_Description: Ibuprofen 400 mg\n",
            "Outcome_Type: 5\n",
            "Outcome_Other_Specify: \n",
            "Follow_Up_Time: 24 hours\n",
            "N_Analyzed: 46\n",
            "Adverse_Effect_Specify: Nausea\n",
            "Adverse_Effects_All_Study: \n",
            "N_Events_Number: 8\n",
            "N_Events_Percentage: 17.4\n",
            "Comments: single dose, 0-24 hours\n",
            "filename: 2467_Malmstrom\n"
          ]
        }
      ],
      "source": [
        "# Filter target data for  study to understand expected output\n",
        "one_study_records = [record for record in target_data if record.get('filename') == '2467_Malmstrom']\n",
        "print(f\"Found {len(one_study_records)} records in target data\")\n",
        "\n",
        "# Show example record structure\n",
        "if one_study_records:\n",
        "    print(\"\\nExample target record structure:\")\n",
        "    for key, value in one_study_records[0].items():\n",
        "        print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DSPy Signature Definitions\n",
        "\n",
        "We'll define specialized signatures for each extraction task:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExtractStudyMetadata(dspy.Signature):\n",
        "    \"\"\"Extract basic study metadata from medical research paper markdown.\n",
        "    \n",
        "    This extracts core identifying information about the dental pain management study.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "\n",
        "    first_author: str = dspy.OutputField(\n",
        "        desc=\"Last name of the first author (e.g., 'Cooper'). Extract only the surname.\"\n",
        "    )\n",
        "    \n",
        "    population_code: str = dspy.OutputField(\n",
        "        desc=\"Numeric code representing the study population type. Codes: 1=simple tooth extraction, 2=surgical tooth extraction (third molar/wisdom teeth), 3=surgical tooth extraction (other teeth), 4=pulpitis or its complications. Can be multiple codes separated by commas (e.g., '2, 3')\"\n",
        "    )\n",
        "    \n",
        "\n",
        "\n",
        "class ExtractInterventions(dspy.Signature):\n",
        "    \"\"\"Extract intervention details from medical research paper markdown.\n",
        "    \n",
        "    This extracts information about pain management interventions used in dental studies.\n",
        "    Focus on medication types, dosages, and participant counts.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    \n",
        "    interventions_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string containing list of interventions. Each intervention object must have:\n",
        "        - intervention_code (integer): Numeric code 1-11 where:\n",
        "          1=Ibuprofen 200-400mg + Acetaminophen 500-1000mg\n",
        "          2=Oxycodone 5mg or Codeine 60mg  \n",
        "          3=Acetaminophen 650mg + Oxycodone 10mg\n",
        "          4=Ibuprofen 200mg + Hydrocodone 5mg\n",
        "          5=Hydrocodone 5mg + Acetaminophen 300-325mg\n",
        "          6=Ibuprofen 400mg (fast acting or acid)\n",
        "          7=Tramadol 37.5mg + Acetaminophen 325mg\n",
        "          8=Acetaminophen 500-1000mg\n",
        "          9=Acetaminophen 600-650mg + Codeine 60mg\n",
        "          10=Naproxen 400-440mg\n",
        "          11=Placebo/NA (If its not mentioned as a placebo, then it is NA)\n",
        "          #12=OTHER\n",
        "        - intervention_description (string): Full description with medication name and exact dose (e.g., \"Ibuprofen 400mg\", \"Naproxen sodium 440mg\")\n",
        "        - n_analyzed (integer): Number of participants analyzed for this intervention group\n",
        "        \n",
        "        Example: [{\"intervention_code\": 6, \"intervention_description\": \"Ibuprofen 400mg\", \"n_analyzed\": 40}]\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractAllOutcomes(dspy.Signature):\n",
        "    \"\"\"Extract ALL outcomes from medical research paper for systematic review.\n",
        "    \n",
        "    This implements COMPLETE DATA CAPTURE methodology - extract every data point\n",
        "    including rescue analgesia, adverse events, and other outcomes at all time points.\n",
        "    Focus on dichotomous outcomes from ALL data sources: main text, figures, tables,\n",
        "    and supplementary materials. Include zero-event outcomes (0/N patients).\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper including supplementary materials\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention to extract outcomes for (e.g., 'Ibuprofen 400mg', 'Placebo')\")\n",
        "    \n",
        "    all_outcomes_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string containing list of ALL outcomes for the specified intervention. Each outcome object must have:\n",
        "        \n",
        "        MANDATORY FIELDS FOR ALL OUTCOMES:\n",
        "        - outcome_type (integer): Outcome type code where:\n",
        "          1=Rescue analgesia at 6 hours\n",
        "          2=Rescue analgesia at 4 hours  \n",
        "          4=Rescue analgesia for pulpitis population\n",
        "          5=Adverse effects (nausea, vomiting, drowsiness, dizziness, headache, etc.)\n",
        "          6=Other outcomes (pain relief, time to onset, etc.)\n",
        "        - follow_up_time (string): Exact time point when outcome was measured (e.g., \"6 hours\", \"24hrs\", \"4 hours\", \"7 days\")\n",
        "        - n_analyzed (integer): Number of participants analyzed for this specific outcome\n",
        "        - n_events_number (integer): Number of patients who experienced this outcome\n",
        "        - n_events_percentage (float): Percentage of patients who experienced this outcome (e.g., 17.5, 0.6, 2.4, 0.0)\n",
        "        \n",
        "        CONDITIONAL FIELDS:\n",
        "        - adverse_effect_specify (string): Specific adverse effect name if outcome_type=5 (e.g., \"Drowsiness (sleepy, tired)\", \"Paraesthesia oral\", \"Vomiting\"). Use \"NA\" if outcome_type≠5\n",
        "        - other_outcome_specify (string): Detailed description if outcome_type=6 (e.g., \"Time to meaningful pain relief\", \"Pain intensity difference\"). Use \"NA\" if outcome_type≠6\n",
        "        - adverse_effects_all_study (string): List of all adverse effects if not reported per study arm, or \"NA\" if reported per arm\n",
        "        \n",
        "        DOCUMENTATION FIELDS:\n",
        "        - extraction_notes (string): Technical documentation including data source (\"From Table 2\", \"From Figure 5\", \"From Supplementary Table 3\"), extraction method (\"Direct from table\", \"Interpreted from Kaplan-Meier curve\"), and population used (\"Per-protocol population\", \"Safety population\", \"ITT population\")\n",
        "        - comments (string): Study-specific information including single vs multiple dose design, surgical techniques mentioned, methodological features, dropout rates, calculation details\n",
        "        \n",
        "        EXTRACTION REQUIREMENTS:\n",
        "        - Extract EVERY outcome reported, including zero-event outcomes (0/N)\n",
        "        - Create separate entries for each time point assessment\n",
        "        - Include outcomes from ALL data sources (main text, figures, supplements)\n",
        "        - Use appropriate analysis populations (efficacy vs safety)\n",
        "        - Document any calculations or interpretations performed\n",
        "        \n",
        "        Example: [\n",
        "          {\"outcome_type\": 1, \"follow_up_time\": \"6 hours\", \"n_analyzed\": 40, \"n_events_number\": 15, \"n_events_percentage\": 37.5, \"adverse_effect_specify\": \"NA\", \"other_outcome_specify\": \"NA\", \"adverse_effects_all_study\": \"NA\", \"extraction_notes\": \"From Table 3, per-protocol population\", \"comments\": \"single dose study with overnight monitoring\"},\n",
        "          {\"outcome_type\": 5, \"follow_up_time\": \"24 hours\", \"n_analyzed\": 40, \"n_events_number\": 7, \"n_events_percentage\": 17.5, \"adverse_effect_specify\": \"Drowsiness (sleepy, tired)\", \"other_outcome_specify\": \"NA\", \"adverse_effects_all_study\": \"NA\", \"extraction_notes\": \"From safety table, safety population\", \"comments\": \"mild to moderate severity\"}\n",
        "        ]\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class StructureComprehensiveOutcome(dspy.Signature):\n",
        "    \"\"\"Structure extracted data into the final comprehensive dichotomous outcome format.\n",
        "    \n",
        "    This combines study metadata, intervention details, and any outcome data (rescue analgesia,\n",
        "    adverse events, or other outcomes) into the standardized format used for systematic review\n",
        "    and meta-analysis. Each record represents one outcome for one intervention in one study.\n",
        "    \"\"\"\n",
        "    \n",
        "    study_metadata_json: str = dspy.InputField(desc=\"Study metadata as JSON string with first_author,  population_code\")\n",
        "    intervention_json: str = dspy.InputField(desc=\"Single intervention details as JSON string with intervention_code, intervention_description, n_analyzed\")\n",
        "    outcome_json: str = dspy.InputField(desc=\"Single outcome details as JSON string with all outcome fields including outcome_type, follow_up_time, n_events_number, etc.\")\n",
        "    \n",
        "    structured_record_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"Complete structured record as JSON string with exactly these fields:\n",
        "        - First_Author (string): First author last name (e.g., \"Cooper\")\n",
        "        - Population (integer): Population code (1-4)\n",
        "        - Intervention_Code (integer): Intervention code (1-11)\n",
        "        - Intervention_Description (string): Full intervention description with dose\n",
        "        - Outcome_Type (integer): Outcome type (1=rescue analgesia 6h, 2=rescue analgesia 4h, 4=rescue analgesia pulpitis, 5=adverse effects, 6=other)\n",
        "        - Outcome_Other_Specify (string): Detailed outcome description for type 6, or empty string for other types\n",
        "        - Follow_Up_Time (string): Time point (e.g., \"24hrs\", \"6 hours\")\n",
        "        - N_Analyzed (integer): Number of participants analyzed\n",
        "        - Adverse_Effect_Specify (string): Specific adverse effect name for type 5, or empty string for other types\n",
        "        - Adverse_Effects_All_Study (string): All study adverse effects if not reported per arm, or empty string\n",
        "        - N_Events_Number (integer): Number of patients with this outcome\n",
        "        - N_Events_Percentage (float): Percentage of patients with this outcome\n",
        "        - Comments (string): Study-specific methodology, design notes, and extraction details\n",
        "        \n",
        "        FIELD MAPPING RULES:\n",
        "        - For outcome_type 1,2,4 (rescue analgesia): Adverse_Effect_Specify=\"\" and Outcome_Other_Specify=\"\"\n",
        "        - For outcome_type 5 (adverse effects): Outcome_Other_Specify=\"\" and Adverse_Effect_Specify=specific adverse event name\n",
        "        - For outcome_type 6 (other outcomes): Adverse_Effect_Specify=\"\" and Outcome_Other_Specify=detailed outcome description\n",
        "        - Always include extraction methodology and data source information in Comments\n",
        "        - Ensure mathematical validation: (N_Events_Number/N_Analyzed)*100 = N_Events_Percentage\n",
        "        - Use appropriate analysis populations (efficacy vs safety) based on outcome type\n",
        "        \n",
        "        Example: {\"First_Author\": \"Cooper\",  \"Population\": 2, \"Intervention_Code\": 10, \"Intervention_Description\": \"Naproxen sodium 440mg\", \"Outcome_Type\": 5, \"Outcome_Other_Specify\": \"\", \"Follow_Up_Time\": \"24hrs\", \"N_Analyzed\": 166, \"Adverse_Effect_Specify\": \"Paraesthesia oral\", \"Adverse_Effects_All_Study\": \"\", \"N_Events_Number\": 1, \"N_Events_Percentage\": 0.6, \"Comments\": \"extracted from supplementary table 3, safety population, single dose study\"}\"\"\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DSPy Module Implementation\n",
        "\n",
        "Now we'll create DSPy modules that use these signatures with reasoning patterns:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async DSPy modules defined successfully\n"
          ]
        }
      ],
      "source": [
        "class AsyncStudyMetadataExtractor(dspy.Module):\n",
        "    \"\"\"Async module to extract study metadata using chain of thought reasoning.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_metadata = dspy.ChainOfThought(ExtractStudyMetadata)\n",
        "    \n",
        "    async def __call__(self, markdown_content: str) -> Dict[str, Any]:\n",
        "        \"\"\"Async call method that runs DSPy call in thread pool.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _extract():\n",
        "            return self.extract_metadata(markdown_content=markdown_content)\n",
        "        \n",
        "        # Run DSPy call in thread pool to avoid blocking event loop\n",
        "        result = await loop.run_in_executor(None, _extract)\n",
        "        \n",
        "        return {\n",
        "            \"first_author\": result.first_author,\n",
        "            \"population_code\": result.population_code\n",
        "        }\n",
        "    \n",
        "    def forward_sync(self, markdown_content: str) -> Dict[str, Any]:\n",
        "        \"\"\"Fallback sync method for backwards compatibility.\"\"\"\n",
        "        result = self.extract_metadata(markdown_content=markdown_content)\n",
        "        return {\n",
        "            \"first_author\": result.first_author,\n",
        "            \"population_code\": result.population_code\n",
        "        }\n",
        "\n",
        "\n",
        "class AsyncInterventionExtractor(dspy.Module):\n",
        "    \"\"\"Async module to extract intervention details.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_interventions = dspy.ChainOfThought(ExtractInterventions)\n",
        "    \n",
        "    async def __call__(self, markdown_content: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Async call method with error handling.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _extract():\n",
        "            return self.extract_interventions(markdown_content=markdown_content)\n",
        "        \n",
        "        try:\n",
        "            result = await loop.run_in_executor(None, _extract)\n",
        "            return safe_json_parse(result.interventions_json)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing interventions JSON: {e}, returning empty list\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error in intervention extraction: {e}, returning empty list\")\n",
        "            return []\n",
        "    \n",
        "    def forward_sync(self, markdown_content: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Fallback sync method.\"\"\"\n",
        "        result = self.extract_interventions(markdown_content=markdown_content)\n",
        "        try:\n",
        "            return safe_json_parse(result.interventions_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing interventions JSON, returning empty list\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class AsyncOutcomeExtractor(dspy.Module):\n",
        "    \"\"\"Async module to extract all outcomes for a specific intervention.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_all_outcomes = dspy.ChainOfThought(ExtractAllOutcomes)\n",
        "    \n",
        "    async def __call__(self, markdown_content: str, intervention_description: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Async call method with robust error handling.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _extract():\n",
        "            return self.extract_all_outcomes(\n",
        "                markdown_content=markdown_content,\n",
        "                intervention_description=intervention_description\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            result = await loop.run_in_executor(None, _extract)\n",
        "            return safe_json_parse(result.all_outcomes_json)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing outcomes JSON for '{intervention_description}': {e}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error in outcome extraction for '{intervention_description}': {e}\")\n",
        "            return []\n",
        "    \n",
        "    def forward_sync(self, markdown_content: str, intervention_description: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Fallback sync method.\"\"\"\n",
        "        result = self.extract_all_outcomes(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.all_outcomes_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing outcomes JSON, returning empty list\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class AsyncDataStructurer(dspy.Module):\n",
        "    \"\"\"Async module to structure data into final format.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.structure_data = dspy.ChainOfThought(StructureComprehensiveOutcome)\n",
        "    \n",
        "    async def __call__(self, study_metadata: Dict, intervention: Dict, outcome: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Async call method with comprehensive error handling.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _structure():\n",
        "            return self.structure_data(\n",
        "                study_metadata_json=json.dumps(study_metadata),\n",
        "                intervention_json=json.dumps(intervention),\n",
        "                outcome_json=json.dumps(outcome)\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            result = await loop.run_in_executor(None, _structure)\n",
        "            return safe_json_parse(result.structured_record_json)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing structured record JSON: {e}, using fallback\")\n",
        "            return self._create_fallback_record(study_metadata, intervention, outcome)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in data structuring: {e}, using fallback\")\n",
        "            return self._create_fallback_record(study_metadata, intervention, outcome)\n",
        "    \n",
        "    def _create_fallback_record(self, study_metadata: Dict, intervention: Dict, outcome: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Create fallback structured record when DSPy fails.\"\"\"\n",
        "        return {\n",
        "            \"First_Author\": study_metadata.get(\"first_author\", \"\"),\n",
        "            \"Population\": study_metadata.get(\"population_code\", \"\"),\n",
        "            \"Intervention_Code\": intervention.get(\"intervention_code\", \"\"),\n",
        "            \"Intervention_Description\": intervention.get(\"intervention_description\", \"\"),\n",
        "            \"Outcome_Type\": outcome.get(\"outcome_type\", 5),\n",
        "            \"Outcome_Other_Specify\": outcome.get(\"other_outcome_specify\", \"\"),\n",
        "            \"Follow_Up_Time\": outcome.get(\"follow_up_time\", \"\"),\n",
        "            \"N_Analyzed\": intervention.get(\"n_analyzed\", \"\"),\n",
        "            \"Adverse_Effect_Specify\": outcome.get(\"adverse_effect_specify\", \"\"),\n",
        "            \"Adverse_Effects_All_Study\": outcome.get(\"adverse_effects_all_study\", \"\"),\n",
        "            \"N_Events_Number\": outcome.get(\"n_events_number\", \"\"),\n",
        "            \"N_Events_Percentage\": outcome.get(\"n_events_percentage\", \"\"),\n",
        "            \"Comments\": f\"{outcome.get('extraction_notes', '')} {outcome.get('comments', '')}\".strip(),\n",
        "        }\n",
        "    \n",
        "    def forward_sync(self, study_metadata: Dict, intervention: Dict, outcome: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Fallback sync method.\"\"\"\n",
        "        result = self.structure_data(\n",
        "            study_metadata_json=json.dumps(study_metadata),\n",
        "            intervention_json=json.dumps(intervention),\n",
        "            outcome_json=json.dumps(outcome)\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.structured_record_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing structured record JSON, returning basic structure\")\n",
        "            return self._create_fallback_record(study_metadata, intervention, outcome)\n",
        "\n",
        "\n",
        "print(\"Async DSPy modules defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Complete Extraction Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async extraction pipeline defined successfully\n"
          ]
        }
      ],
      "source": [
        "class AsyncMedicalDataExtractionPipeline(dspy.Module):\n",
        "    \"\"\"Complete async pipeline for extracting structured data from medical research papers.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_concurrent: int = 5):\n",
        "        super().__init__()\n",
        "        self.metadata_extractor = AsyncStudyMetadataExtractor()\n",
        "        self.intervention_extractor = AsyncInterventionExtractor()\n",
        "        self.outcome_extractor = AsyncOutcomeExtractor()\n",
        "        self.data_structurer = AsyncDataStructurer()\n",
        "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "    \n",
        "    async def forward(self, markdown_content: str):\n",
        "        \"\"\"Extract all structured records from markdown content asynchronously.\"\"\"\n",
        "        \n",
        "        # Step 1 & 2: Extract metadata and interventions concurrently\n",
        "        print(\"Extracting metadata and interventions concurrently...\")\n",
        "        \n",
        "        metadata_task = self.metadata_extractor(markdown_content)\n",
        "        interventions_task = self.intervention_extractor(markdown_content)\n",
        "        \n",
        "        study_metadata, interventions = await asyncio.gather(metadata_task, interventions_task)\n",
        "        \n",
        "        print(f\"Study metadata: {study_metadata}\")\n",
        "        print(f\"Found {len(interventions)} interventions\")\n",
        "        \n",
        "        # Step 3: Process all interventions concurrently\n",
        "        all_records = []\n",
        "        \n",
        "        if interventions:\n",
        "            outcome_tasks = []\n",
        "            for intervention in interventions:\n",
        "                task = self._process_intervention_outcomes(\n",
        "                    markdown_content, study_metadata, intervention\n",
        "                )\n",
        "                outcome_tasks.append(task)\n",
        "            \n",
        "            # Gather all intervention results\n",
        "            intervention_results = await asyncio.gather(*outcome_tasks)\n",
        "            \n",
        "            # Flatten results\n",
        "            for records in intervention_results:\n",
        "                all_records.extend(records)\n",
        "        \n",
        "        print(f\"Total records extracted: {len(all_records)}\")\n",
        "        return dspy.Prediction(extracted_records=all_records)\n",
        "        #return all_records\n",
        "    \n",
        "    async def _process_intervention_outcomes(self, markdown_content: str, \n",
        "                                           study_metadata: Dict, intervention: Dict) -> List[Dict]:\n",
        "        \"\"\"Process outcomes for a single intervention with semaphore control.\"\"\"\n",
        "        async with self.semaphore:\n",
        "            intervention_desc = intervention.get('intervention_description', '')\n",
        "            print(f\"Processing intervention: {intervention_desc}\")\n",
        "            \n",
        "            outcomes = await self.outcome_extractor(markdown_content, intervention_desc)\n",
        "            print(f\"Found {len(outcomes)} outcomes for {intervention_desc}\")\n",
        "            \n",
        "            # Structure all outcomes for this intervention concurrently\n",
        "            if outcomes:\n",
        "                structure_tasks = [\n",
        "                    self.data_structurer(study_metadata, intervention, outcome)\n",
        "                    for outcome in outcomes\n",
        "                ]\n",
        "                structured_records = await asyncio.gather(*structure_tasks)\n",
        "                return structured_records\n",
        "            \n",
        "            return []\n",
        "    \n",
        "   \n",
        "\n",
        "print(\"Async extraction pipeline defined successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing AsyncMedicalDataExtractionPipeline through SyncPipelineWrapper...\n"
          ]
        }
      ],
      "source": [
        "class SyncPipelineWrapper(dspy.Module):\n",
        "    \"\"\"Synchronous wrapper for async pipeline to work with DSPy optimizers.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.async_pipeline = None\n",
        "    \n",
        "    def forward(self, markdown_content: str):\n",
        "        \"\"\"Synchronous forward method that runs async pipeline.\"\"\"\n",
        "        if self.async_pipeline is None:\n",
        "            # Create your async pipeline instance\n",
        "            self.async_pipeline = AsyncMedicalDataExtractionPipeline()\n",
        "        \n",
        "        # Handle event loop situations\n",
        "        try:\n",
        "            # Check if there's already an event loop running\n",
        "            loop = asyncio.get_running_loop()\n",
        "            if loop.is_running():\n",
        "                # If loop is running, we need nest_asyncio\n",
        "                try:\n",
        "                    import nest_asyncio\n",
        "                    nest_asyncio.apply()\n",
        "                except ImportError:\n",
        "                    raise ImportError(\"Please install nest_asyncio: pip install nest_asyncio\")\n",
        "        except RuntimeError:\n",
        "            # No event loop exists, which is fine\n",
        "            pass\n",
        "        \n",
        "        # Run the async pipeline synchronously\n",
        "        result = asyncio.run(self.async_pipeline.forward(markdown_content))\n",
        "        return result\n",
        "\n",
        "\n",
        "# Create the sync wrapper\n",
        "sync_pipeline = SyncPipelineWrapper()\n",
        "# Run the pipeline (this calls your async pipeline synchronously)\n",
        "print(\"Initializing AsyncMedicalDataExtractionPipeline through SyncPipelineWrapper...\")\n",
        "\n",
        "#     result = sync_pipeline.forward(markdown_content) \n",
        "#     print(f\"Pipeline completed successfully!\")\n",
        "#     print(f\"Number of records extracted: {len(result.extracted_records)}\")\n",
        "#     # Print first few records\n",
        "#     for i, record in enumerate(result.extracted_records[:1]):\n",
        "#         print(f\"\\nRecord {i+1}:\")\n",
        "#         for key, value in record.items():\n",
        "#             print(f\"  {key}: {value}\") \n",
        "#     print(f\"\\nTotal records: {len(result.extracted_records)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluation Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The 4 Core Outcomes in Classification\n",
        "\n",
        "When evaluating a system’s predictions against the **ground truth**, each result falls into one of four categories:\n",
        "\n",
        "#### 1. **True Positive (TP)**\n",
        "- System says **“Yes”**\n",
        "- Ground truth is **“Yes”**\n",
        "- ✅ Correct detection  \n",
        "- **Example:** System extracts `First_Author = Cooper`, and ground truth really has `Cooper`.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **False Positive (FP)**\n",
        "- System says **“Yes”**\n",
        "- Ground truth is **“No”**\n",
        "- ❌ Wrong detection (system “hallucinated”)  \n",
        "- **Example:** System extracts `First_Author = Jones`, but ground truth has `Smith`.\n",
        "\n",
        "\n",
        "\n",
        "#### 3. **True Negative (TN)**\n",
        "- System says **“No”**\n",
        "- Ground truth is **“No”**\n",
        "- ✅ Correct rejection  \n",
        "- **Example:** Ground truth has no `Adverse_Effect_Specify`, and system also leaves it empty.\n",
        "\n",
        "\n",
        "\n",
        "#### 4. **False Negative (FN)**\n",
        "- System says **“No”**\n",
        "- Ground truth is **“Yes”**\n",
        "- ❌ Missed detection (system failed to extract)  \n",
        "- **Example:** Ground truth has `Trial_Name = MOLAR`, but system extracts nothing (or extracts wrong value).\n",
        "\n",
        "\n",
        "\n",
        "#### In `MedicalExtractionEvaluator` Context\n",
        "\n",
        "- **TP (True Positive)** → A field value was extracted **and** it matched the ground truth.  \n",
        "- **FP (False Positive)** → A field value was extracted, but it was **wrong** (mismatch) or **extra** (system filled something that shouldn’t exist).  \n",
        "- **FN (False Negative)** → A ground-truth field existed, but the system didn’t produce it (missing record or missing field).  \n",
        "- **TN (True Negative)** → Neither system nor ground truth had a value for a field.  \n",
        "\n",
        "**Note:** TNs are **not explicitly tracked** in the evaluator, because in information extraction tasks the number of “true negatives” is usually very large and not informative. This is common in IR/NLP evaluation — most focus only on TP, FP, FN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class AsyncMedicalExtractionEvaluator:\n",
        "#     \"\"\"Async evaluator for medical data extraction with semantic matching and caching.\"\"\"\n",
        "    \n",
        "#     def __init__(self, use_semantic=True, semantic_threshold=0.8, max_concurrent=10):\n",
        "#         self.required_fields = [\n",
        "#             'First_Author', 'Population', 'Intervention_Code', 'Intervention_Description', \n",
        "#             'Outcome_Type', 'Follow_Up_Time', 'N_Analyzed', 'Adverse_Effect_Specify',\n",
        "#             'N_Events_Number', 'N_Events_Percentage', 'Comments'\n",
        "#         ]\n",
        "        \n",
        "#         self.use_semantic = use_semantic\n",
        "#         self.semantic_threshold = semantic_threshold\n",
        "#         self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "        \n",
        "#         # Caches\n",
        "#         self._matching_cache = {}\n",
        "#         self._embedding_cache = {}\n",
        "        \n",
        "#         if self.use_semantic:\n",
        "#             self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#             self.semantic_fields = ['Intervention_Description', 'Adverse_Effect_Specify', 'Follow_Up_Time']\n",
        "#             self.exact_fields = ['First_Author', 'Population', 'Intervention_Code', 'Outcome_Type', \n",
        "#                                'N_Analyzed', 'N_Events_Number', 'N_Events_Percentage']\n",
        "    \n",
        "#     async def _get_embedding(self, text: str):\n",
        "#         \"\"\"Get embedding for text with async caching.\"\"\"\n",
        "#         if text in self._embedding_cache:\n",
        "#             return self._embedding_cache[text]\n",
        "        \n",
        "#         # Run embedding generation in thread pool\n",
        "#         loop = asyncio.get_running_loop()\n",
        "#         embedding = await loop.run_in_executor(None, self.semantic_model.encode, text)\n",
        "        \n",
        "#         self._embedding_cache[text] = embedding\n",
        "#         return embedding\n",
        "    \n",
        "#     async def semantic_similarity(self, text1: str, text2: str) -> float:\n",
        "#         \"\"\"Calculate semantic similarity asynchronously.\"\"\"\n",
        "#         if not self.use_semantic or not text1.strip() or not text2.strip():\n",
        "#             return 1.0 if text1.strip() == text2.strip() else 0.0\n",
        "        \n",
        "#         # Get embeddings concurrently\n",
        "#         embedding1_task = self._get_embedding(text1)\n",
        "#         embedding2_task = self._get_embedding(text2)\n",
        "        \n",
        "#         embedding1, embedding2 = await asyncio.gather(embedding1_task, embedding2_task)\n",
        "        \n",
        "#         # Calculate similarity in thread pool\n",
        "#         loop = asyncio.get_running_loop()\n",
        "#         similarity = await loop.run_in_executor(\n",
        "#             None, lambda: cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "#         )\n",
        "        \n",
        "#         return float(similarity)\n",
        "    \n",
        "#     async def field_match_score(self, extracted_value: Any, ground_truth_value: Any, field_name: str) -> float:\n",
        "#         \"\"\"Calculate field-level match score asynchronously.\"\"\"\n",
        "#         ext_val = str(extracted_value).strip() if extracted_value is not None else \"\"\n",
        "#         gt_val = str(ground_truth_value).strip() if ground_truth_value is not None else \"\"\n",
        "        \n",
        "#         if not self.use_semantic or field_name in self.exact_fields:\n",
        "#             return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "        \n",
        "#         if field_name in self.semantic_fields:\n",
        "#             if not ext_val and not gt_val:\n",
        "#                 return 1.0\n",
        "#             if not ext_val or not gt_val:\n",
        "#                 return 0.0\n",
        "            \n",
        "#             similarity = await self.semantic_similarity(ext_val, gt_val)\n",
        "#             return 1.0 if similarity >= self.semantic_threshold else 0.0\n",
        "        \n",
        "#         return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "    \n",
        "#     async def calculate_record_similarity(self, extracted_record: Dict, ground_truth_record: Dict) -> float:\n",
        "#         \"\"\"Calculate similarity between two records asynchronously.\"\"\"\n",
        "#         async with self.semaphore:\n",
        "#             # Gather all field comparisons concurrently\n",
        "#             field_tasks = []\n",
        "#             for field in self.required_fields:\n",
        "#                 if field in extracted_record and field in ground_truth_record:\n",
        "#                     task = self.field_match_score(\n",
        "#                         extracted_record[field], \n",
        "#                         ground_truth_record[field], \n",
        "#                         field\n",
        "#                     )\n",
        "#                     field_tasks.append(task)\n",
        "            \n",
        "#             if not field_tasks:\n",
        "#                 return 0.0\n",
        "            \n",
        "#             match_scores = await asyncio.gather(*field_tasks)\n",
        "#             return sum(match_scores) / len(match_scores)\n",
        "    \n",
        "#     async def _compute_similarity_matrix(self, extracted_records: List[Dict], ground_truth_records: List[Dict]):\n",
        "#         \"\"\"Compute similarity matrix asynchronously.\"\"\"\n",
        "#         n_extracted = len(extracted_records)\n",
        "#         n_ground_truth = len(ground_truth_records)\n",
        "        \n",
        "#         # Create all similarity computation tasks\n",
        "#         tasks = []\n",
        "#         for i in range(n_extracted):\n",
        "#             for j in range(n_ground_truth):\n",
        "#                 task = self.calculate_record_similarity(extracted_records[i], ground_truth_records[j])\n",
        "#                 tasks.append((i, j, task))\n",
        "        \n",
        "#         # Execute all similarity computations concurrently\n",
        "#         results = await asyncio.gather(*[task for _, _, task in tasks])\n",
        "        \n",
        "#         # Build similarity matrix\n",
        "#         similarity_matrix = np.zeros((n_extracted, n_ground_truth))\n",
        "#         for idx, (i, j, _) in enumerate(tasks):\n",
        "#             similarity_matrix[i][j] = results[idx]\n",
        "        \n",
        "#         return similarity_matrix\n",
        "    \n",
        "#     async def hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "#         \"\"\"Compute Hungarian matching asynchronously with caching.\"\"\"\n",
        "#         cache_key = f\"{len(extracted_records)}_{len(ground_truth_records)}_{hash(str(extracted_records) + str(ground_truth_records))}\"\n",
        "        \n",
        "#         if cache_key in self._matching_cache:\n",
        "#             return self._matching_cache[cache_key]\n",
        "        \n",
        "#         if not extracted_records or not ground_truth_records:\n",
        "#             return []\n",
        "        \n",
        "#         # Compute similarity matrix asynchronously\n",
        "#         similarity_matrix = await self._compute_similarity_matrix(extracted_records, ground_truth_records)\n",
        "        \n",
        "#         # Apply Hungarian algorithm in thread pool\n",
        "#         loop = asyncio.get_running_loop()\n",
        "#         cost_matrix = 1.0 - similarity_matrix\n",
        "        \n",
        "#         # Pad matrix to square if needed\n",
        "#         n_extracted, n_ground_truth = similarity_matrix.shape\n",
        "#         max_size = max(n_extracted, n_ground_truth)\n",
        "#         if max_size > max(n_extracted, n_ground_truth):\n",
        "#             padded_cost = np.ones((max_size, max_size))\n",
        "#             padded_cost[:n_extracted, :n_ground_truth] = cost_matrix\n",
        "#             cost_matrix = padded_cost\n",
        "        \n",
        "#         row_indices, col_indices = await loop.run_in_executor(None, linear_sum_assignment, cost_matrix)\n",
        "        \n",
        "#         # Extract valid matches\n",
        "#         matches = []\n",
        "#         for i, j in zip(row_indices, col_indices):\n",
        "#             if i < n_extracted and j < n_ground_truth:\n",
        "#                 similarity = similarity_matrix[i][j]\n",
        "#                 if similarity > 0.0:\n",
        "#                     matches.append((i, j, similarity))\n",
        "        \n",
        "#         # Cache results\n",
        "#         self._matching_cache[cache_key] = matches\n",
        "#         return matches\n",
        "    \n",
        "#     async def evaluate_record_metrics(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "#         \"\"\"Calculate record-level metrics asynchronously.\"\"\"\n",
        "#         matches = await self.hungarian_matching(extracted_records, ground_truth)\n",
        "#         valid_matches = [match for match in matches if match[2] >= 0.5]\n",
        "        \n",
        "#         true_positives = len(valid_matches)\n",
        "#         false_positives = len(extracted_records) - true_positives\n",
        "#         false_negatives = len(ground_truth) - true_positives\n",
        "        \n",
        "#         precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "#         recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "#         f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        \n",
        "#         return {\n",
        "#             'precision': precision, 'recall': recall, 'f1': f1,\n",
        "#             'TP': true_positives, 'FP': false_positives, 'FN': false_negatives\n",
        "#         }\n",
        "    \n",
        "#     def evaluate_completeness(self, extracted_records: List[Dict]) -> float:\n",
        "#         \"\"\"Evaluate field completeness (synchronous).\"\"\"\n",
        "#         if not extracted_records:\n",
        "#             return 0.0\n",
        "        \n",
        "#         total_fields = len(self.required_fields) * len(extracted_records)\n",
        "#         filled_fields = sum(\n",
        "#             1 for record in extracted_records \n",
        "#             for field in self.required_fields \n",
        "#             if field in record and record[field] is not None and str(record[field]).strip()\n",
        "#         )\n",
        "        \n",
        "#         return filled_fields / total_fields if total_fields > 0 else 0.0\n",
        "    \n",
        "#     async def evaluate_accuracy(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "#         \"\"\"Evaluate extraction accuracy asynchronously.\"\"\"\n",
        "#         if not extracted_records or not ground_truth:\n",
        "#             return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        \n",
        "#         record_metrics = await self.evaluate_record_metrics(extracted_records, ground_truth)\n",
        "        \n",
        "#         return {\n",
        "#             **record_metrics,\n",
        "#             \"completeness\": self.evaluate_completeness(extracted_records)\n",
        "#         }\n",
        "    \n",
        "#     async def evaluate(self, extracted_records: List[Dict], ground_truth: List[Dict] = None) -> Dict[str, Any]:\n",
        "#         \"\"\"Complete evaluation asynchronously.\"\"\"\n",
        "#         results = {\n",
        "#             \"num_extracted\": len(extracted_records),\n",
        "#             \"completeness\": self.evaluate_completeness(extracted_records),\n",
        "#             \"semantic_enabled\": self.use_semantic,\n",
        "#             \"semantic_threshold\": self.semantic_threshold if self.use_semantic else None\n",
        "#         }\n",
        "        \n",
        "#         if ground_truth:\n",
        "#             accuracy_results = await self.evaluate_accuracy(extracted_records, ground_truth)\n",
        "#             results.update(accuracy_results)\n",
        "#             results[\"num_ground_truth\"] = len(ground_truth)\n",
        "        \n",
        "#         return results\n",
        "        \n",
        "# print(\"Async medical extraction evaluator defined successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any, Tuple\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import dspy\n",
        "\n",
        "\n",
        "class SemanticMatcher(dspy.Signature):\n",
        "    \"\"\"Determine if two medical texts are semantically equivalent for data extraction purposes.\"\"\"\n",
        "    text1: str = dspy.InputField(desc=\"First medical text to compare\")\n",
        "    text2: str = dspy.InputField(desc=\"Second medical text to compare\")\n",
        "    field_context: str = dspy.InputField(desc=\"Medical field being compared (e.g., Intervention_Description)\")\n",
        "    is_equivalent: str = dspy.OutputField(desc=\"Yes/No/True/False if texts are equivalent\")\n",
        "\n",
        "\n",
        "class AsyncMedicalExtractionEvaluator:\n",
        "    \"\"\"Async evaluator for medical data extraction with DSPy-based semantic matching and caching.\"\"\"\n",
        "\n",
        "    def __init__(self, use_semantic=True, max_concurrent=10):\n",
        "        self.required_fields = [\n",
        "            'First_Author', 'Population', 'Intervention_Code', 'Intervention_Description',\n",
        "            'Outcome_Type', 'Follow_Up_Time', 'N_Analyzed', 'Adverse_Effect_Specify',\n",
        "            'N_Events_Number', 'N_Events_Percentage', 'Comments'\n",
        "        ]\n",
        "\n",
        "        self.use_semantic = use_semantic\n",
        "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "\n",
        "        # Caches\n",
        "        self._matching_cache = {}\n",
        "        self._semantic_cache = {}\n",
        "\n",
        "        # Field types\n",
        "        self.semantic_fields = ['Intervention_Description', 'Adverse_Effect_Specify', 'Follow_Up_Time']\n",
        "        self.exact_fields = [\n",
        "            'First_Author', 'Population', 'Intervention_Code', 'Outcome_Type',\n",
        "            'N_Analyzed', 'N_Events_Number', 'N_Events_Percentage'\n",
        "        ]\n",
        "\n",
        "    # ----------------------------\n",
        "    # Core Semantic Matching\n",
        "    # ----------------------------\n",
        "    async def _run_dspy_semantic_match(self, text1: str, text2: str, field_name: str) -> bool:\n",
        "        \"\"\"Run DSPy semantic matching using GPT-4o-mini, normalized to boolean.\"\"\"\n",
        "        try:\n",
        "            with dspy.context(lm=dspy.LM(\"openai/gpt-4o-mini\")):\n",
        "                matcher = dspy.Predict(SemanticMatcher)\n",
        "                result = matcher(text1=text1, text2=text2, field_context=field_name)\n",
        "                log_history()\n",
        "\n",
        "            raw = getattr(result, \"is_equivalent\", \"\")\n",
        "            normalized = str(raw).strip().lower()\n",
        "            is_equiv = normalized in [\"true\", \"yes\", \"1\"]\n",
        "\n",
        "            print(f\"[SemanticMatch] {field_name}: '{text1}' vs '{text2}' → {raw} → {is_equiv}\")\n",
        "            return is_equiv\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[SemanticMatch ERROR] {field_name}: {e}\")\n",
        "            # Fallback exact match\n",
        "            return text1.strip().lower() == text2.strip().lower()\n",
        "\n",
        "    async def semantic_similarity(self, text1: str, text2: str, field_name: str) -> float:\n",
        "        \"\"\"Calculate semantic similarity (0/1) with caching.\"\"\"\n",
        "        if not self.use_semantic or not text1.strip() or not text2.strip():\n",
        "            return 1.0 if text1.strip() == text2.strip() else 0.0\n",
        "\n",
        "        cache_key = f\"{text1.strip()}||{text2.strip()}||{field_name}\"\n",
        "        if cache_key in self._semantic_cache:\n",
        "            return self._semantic_cache[cache_key]\n",
        "\n",
        "        is_equiv = await self._run_dspy_semantic_match(text1, text2, field_name)\n",
        "        score = 1.0 if is_equiv else 0.0\n",
        "\n",
        "        self._semantic_cache[cache_key] = score\n",
        "        return score\n",
        "\n",
        "    # ----------------------------\n",
        "    # Field-Level Matching\n",
        "    # ----------------------------\n",
        "    async def field_match_score(self, extracted_value: Any, ground_truth_value: Any, field_name: str) -> float:\n",
        "        ext_val = str(extracted_value).strip() if extracted_value is not None else \"\"\n",
        "        gt_val = str(ground_truth_value).strip() if ground_truth_value is not None else \"\"\n",
        "\n",
        "        # Exact fields\n",
        "        if not self.use_semantic or field_name in self.exact_fields:\n",
        "            return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "\n",
        "        # Semantic fields\n",
        "        if field_name in self.semantic_fields:\n",
        "            if not ext_val and not gt_val:\n",
        "                return 1.0\n",
        "            if not ext_val or not gt_val:\n",
        "                return 0.0\n",
        "            return await self.semantic_similarity(ext_val, gt_val, field_name)\n",
        "\n",
        "        # Default to exact\n",
        "        return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "\n",
        "    # ----------------------------\n",
        "    # Record-Level Matching\n",
        "    # ----------------------------\n",
        "    async def calculate_record_similarity(self, extracted_record: Dict, ground_truth_record: Dict) -> float:\n",
        "        async with self.semaphore:\n",
        "            field_tasks = [\n",
        "                self.field_match_score(extracted_record[field], ground_truth_record[field], field)\n",
        "                for field in self.required_fields\n",
        "                if field in extracted_record and field in ground_truth_record\n",
        "            ]\n",
        "            if not field_tasks:\n",
        "                return 0.0\n",
        "            scores = await asyncio.gather(*field_tasks)\n",
        "            return sum(scores) / len(scores)\n",
        "\n",
        "    async def _compute_similarity_matrix(self, extracted_records: List[Dict], ground_truth_records: List[Dict]):\n",
        "        n_extracted, n_ground_truth = len(extracted_records), len(ground_truth_records)\n",
        "        tasks = [(i, j, self.calculate_record_similarity(extracted_records[i], ground_truth_records[j]))\n",
        "                 for i in range(n_extracted) for j in range(n_ground_truth)]\n",
        "\n",
        "        results = await asyncio.gather(*[t for _, _, t in tasks])\n",
        "        matrix = np.zeros((n_extracted, n_ground_truth))\n",
        "        for idx, (i, j, _) in enumerate(tasks):\n",
        "            matrix[i][j] = results[idx]\n",
        "        return matrix\n",
        "\n",
        "    async def hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]):\n",
        "        if not extracted_records or not ground_truth_records:\n",
        "            return []\n",
        "\n",
        "        cache_key = f\"{len(extracted_records)}_{len(ground_truth_records)}_{hash(str(extracted_records)+str(ground_truth_records))}\"\n",
        "        if cache_key in self._matching_cache:\n",
        "            return self._matching_cache[cache_key]\n",
        "\n",
        "        sim_matrix = await self._compute_similarity_matrix(extracted_records, ground_truth_records)\n",
        "        cost_matrix = 1.0 - sim_matrix\n",
        "\n",
        "        row_idx, col_idx = linear_sum_assignment(cost_matrix)\n",
        "        matches = [(i, j, sim_matrix[i][j]) for i, j in zip(row_idx, col_idx) if sim_matrix[i][j] > 0.0]\n",
        "\n",
        "        self._matching_cache[cache_key] = matches\n",
        "        return matches\n",
        "\n",
        "    # ----------------------------\n",
        "    # Metrics\n",
        "    # ----------------------------\n",
        "    async def evaluate_record_metrics(self, extracted_records: List[Dict], ground_truth: List[Dict]):\n",
        "        matches = await self.hungarian_matching(extracted_records, ground_truth)\n",
        "        valid_matches = [m for m in matches if m[2] >= 0.5]\n",
        "\n",
        "        TP = len(valid_matches)\n",
        "        FP = len(extracted_records) - TP\n",
        "        FN = len(ground_truth) - TP\n",
        "\n",
        "        precision = TP / (TP + FP) if TP + FP > 0 else 0.0\n",
        "        recall = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "        return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"TP\": TP, \"FP\": FP, \"FN\": FN}\n",
        "\n",
        "    def evaluate_completeness(self, extracted_records: List[Dict]) -> float:\n",
        "        if not extracted_records:\n",
        "            return 0.0\n",
        "        total = len(self.required_fields) * len(extracted_records)\n",
        "        filled = sum(\n",
        "            1 for r in extracted_records for f in self.required_fields\n",
        "            if f in r and r[f] is not None and str(r[f]).strip()\n",
        "        )\n",
        "        return filled / total if total > 0 else 0.0\n",
        "\n",
        "    async def evaluate_accuracy(self, extracted_records: List[Dict], ground_truth: List[Dict]):\n",
        "        if not extracted_records or not ground_truth:\n",
        "            return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        rec_metrics = await self.evaluate_record_metrics(extracted_records, ground_truth)\n",
        "        return {**rec_metrics, \"completeness\": self.evaluate_completeness(extracted_records)}\n",
        "\n",
        "    async def evaluate(self, extracted_records: List[Dict], ground_truth: List[Dict] = None) -> Dict[str, Any]:\n",
        "        results = {\n",
        "            \"num_extracted\": len(extracted_records),\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records),\n",
        "            \"semantic_enabled\": self.use_semantic,\n",
        "        }\n",
        "        if ground_truth:\n",
        "            acc = await self.evaluate_accuracy(extracted_records, ground_truth)\n",
        "            results.update(acc)\n",
        "            results[\"num_ground_truth\"] = len(ground_truth)\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of your evaluator\n",
        "evaluator = AsyncMedicalExtractionEvaluator(use_semantic=True)\n",
        "\n",
        "def medical_extraction_metric(example, pred, trace=None):\n",
        "    \"\"\"Wrapper function for DSPy optimizer.\"\"\"\n",
        "    # Extract the data from DSPy format\n",
        "    extracted_records = pred.extracted_records  # however your prediction is structured\n",
        "    ground_truth = example.ground_truth  # however your ground truth is stored\n",
        "    \n",
        "    # Run the async evaluation synchronously\n",
        "    import asyncio\n",
        "    \n",
        "    # Handle event loop - DSPy might already have one running\n",
        "    try:\n",
        "        loop = asyncio.get_running_loop()\n",
        "        # If we're in an async context, create a new thread\n",
        "        import concurrent.futures\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            future = executor.submit(asyncio.run, evaluator.evaluate_accuracy(extracted_records, ground_truth))\n",
        "            results = future.result()\n",
        "    except RuntimeError:\n",
        "        # No event loop running, safe to use asyncio.run\n",
        "        results = asyncio.run(evaluator.evaluate_accuracy(extracted_records, ground_truth))\n",
        "    \n",
        "    # Return the metric DSPy should optimize (higher is better)\n",
        "    return results['f1']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. MedicalFileHandler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async Medical File Handler defined successfully\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import json\n",
        "import aiofiles\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "\n",
        "class AsyncMedicalFileHandler:\n",
        "    \"\"\"Async file handler for medical data extraction pipeline.\"\"\"\n",
        "    \n",
        "    def __init__(self, default_output_dir: str = None, default_csv_dir: str = \"/nlp/data/karthik9/Sprint1/Dental/Data/csvs\", \n",
        "                 default_json_path: str = \"/nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\"):\n",
        "        self.default_output_dir = default_output_dir\n",
        "        self.default_csv_dir = default_csv_dir\n",
        "        self.default_json_path = default_json_path\n",
        "    \n",
        "    def _generate_output_filename(self, source_file_path: str) -> str:\n",
        "        \"\"\"Generate output filename from source filename.\"\"\"\n",
        "        source_path = Path(source_file_path)\n",
        "        source_name = source_path.stem\n",
        "        \n",
        "        if source_name.endswith('_md'):\n",
        "            output_name = source_name[:-3] + '_do'\n",
        "        else:\n",
        "            output_name = source_name + '_do'\n",
        "        \n",
        "        return output_name + '.json'\n",
        "    \n",
        "    async def save_extracted_results(self, extracted_records: List[Dict], \n",
        "                                   source_file_path: str, \n",
        "                                   output_dir: str = None, \n",
        "                                   override: bool = False) -> str:\n",
        "        \"\"\"Save extracted results to JSON file asynchronously.\"\"\"\n",
        "        try:\n",
        "            output_filename = self._generate_output_filename(source_file_path)\n",
        "            \n",
        "            if output_dir is None:\n",
        "                if self.default_output_dir:\n",
        "                    output_dir = Path(self.default_output_dir)\n",
        "                else:\n",
        "                    output_dir = Path(source_file_path).parent\n",
        "            else:\n",
        "                output_dir = Path(output_dir)\n",
        "            \n",
        "            output_dir.mkdir(parents=True, exist_ok=True)\n",
        "            output_path = output_dir / output_filename\n",
        "            \n",
        "            if output_path.exists() and not override:\n",
        "                print(f\"Output file already exists: {output_path}\")\n",
        "                print(\"Use override=True to overwrite, or file will be skipped\")\n",
        "                return None\n",
        "            \n",
        "            save_data = {\n",
        "                \"metadata\": {\n",
        "                    \"source_file\": str(source_file_path),\n",
        "                    \"extraction_timestamp\": datetime.now().isoformat(),\n",
        "                    \"total_records\": len(extracted_records),\n",
        "                    \"pipeline_version\": \"DSPy_Async_1.0\"\n",
        "                },\n",
        "                \"extracted_records\": extracted_records\n",
        "            }\n",
        "            \n",
        "            async with aiofiles.open(output_path, 'w', encoding='utf-8') as f:\n",
        "                await f.write(json.dumps(save_data, indent=2, ensure_ascii=False))\n",
        "            \n",
        "            print(f\"Successfully saved {len(extracted_records)} records to: {output_path}\")\n",
        "            return str(output_path)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results: {e}\")\n",
        "            return None\n",
        "    \n",
        "    async def save_evaluation_to_csv(self, baseline_results: List[Dict], ground_truth: List[Dict], \n",
        "                                   source_file: str, matches: List[tuple], csv_dir: str = None, \n",
        "                                   override: bool = False):\n",
        "        \"\"\"Save evaluation results to CSV asynchronously.\"\"\"\n",
        "        csv_dir = csv_dir or self.default_csv_dir\n",
        "        Path(csv_dir).mkdir(parents=True, exist_ok=True)\n",
        "        csv_path = Path(csv_dir) / \"do_evaluation_results.csv\"\n",
        "        \n",
        "        # Prepare data rows\n",
        "        rows = []\n",
        "        matched_gt_indices = set()\n",
        "        matched_ext_indices = set()\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        \n",
        "        # Add matched pairs (TP) - FIXED: Process ground truth and extracted separately but consecutively\n",
        "        for ext_idx, gt_idx, score in matches:\n",
        "            if score >= 0.5:\n",
        "                matched_gt_indices.add(gt_idx)\n",
        "                matched_ext_indices.add(ext_idx)\n",
        "                \n",
        "                # Ground truth row (TP - correctly found)\n",
        "                gt_row = ground_truth[gt_idx].copy()\n",
        "                gt_row.update({\n",
        "                    'data_type': 'ground_truth', \n",
        "                    'source_file': source_file,\n",
        "                    'match_score': score, \n",
        "                    'pair_id': f\"{source_file}_{gt_idx}\",\n",
        "                    'classification': 'TP', \n",
        "                    'timestamp': timestamp\n",
        "                })\n",
        "                rows.append(gt_row)\n",
        "                \n",
        "                # Extracted row (TP - correct extraction)\n",
        "                ext_row = baseline_results[ext_idx].copy()\n",
        "                ext_row.update({\n",
        "                    'data_type': 'extracted', \n",
        "                    'source_file': source_file,\n",
        "                    'match_score': score, \n",
        "                    'pair_id': f\"{source_file}_{gt_idx}\",\n",
        "                    'classification': 'TP', \n",
        "                    'timestamp': timestamp\n",
        "                })\n",
        "                rows.append(ext_row)\n",
        "        \n",
        "        # Add unmatched ground truth (FN)\n",
        "        for gt_idx, gt_record in enumerate(ground_truth):\n",
        "            if gt_idx not in matched_gt_indices:\n",
        "                row = gt_record.copy()\n",
        "                row.update({\n",
        "                    'data_type': 'ground_truth', \n",
        "                    'source_file': source_file,\n",
        "                    'match_score': 0.0, \n",
        "                    'pair_id': f\"{source_file}_{gt_idx}_missing\",\n",
        "                    'classification': 'FN', \n",
        "                    'timestamp': timestamp\n",
        "                })\n",
        "                rows.append(row)\n",
        "        \n",
        "        # Add unmatched extractions (FP)\n",
        "        for ext_idx, ext_record in enumerate(baseline_results):\n",
        "            if ext_idx not in matched_ext_indices:\n",
        "                row = ext_record.copy()\n",
        "                row.update({\n",
        "                    'data_type': 'extracted', \n",
        "                    'source_file': source_file,\n",
        "                    'match_score': 0.0, \n",
        "                    'pair_id': f\"{source_file}_fp_{ext_idx}\",\n",
        "                    'classification': 'FP', \n",
        "                    'timestamp': timestamp\n",
        "                })\n",
        "                rows.append(row)\n",
        "        \n",
        "        # Save to CSV asynchronously\n",
        "        new_df = pd.DataFrame(rows)\n",
        "        \n",
        "        if not new_df.empty:\n",
        "            print(\"Length of new_df\", len(new_df))\n",
        "            if csv_path.exists() and not override:\n",
        "                # Load existing data asynchronously\n",
        "                async with aiofiles.open(csv_path, 'r') as f:\n",
        "                    content = await f.read()\n",
        "                existing_df = pd.read_csv(pd.io.common.StringIO(content))\n",
        "                print(\"Length of existing_df\", len(existing_df))\n",
        "                \n",
        "                if override:\n",
        "                    existing_df = existing_df[existing_df['source_file'] != source_file]\n",
        "                final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "                \n",
        "            else:\n",
        "                final_df = new_df\n",
        "            \n",
        "            # Save asynchronously\n",
        "            csv_content = final_df.to_csv(index=False)\n",
        "            async with aiofiles.open(csv_path, 'w') as f:\n",
        "                await f.write(csv_content)\n",
        "            \n",
        "            print(f\"Results saved to: {csv_path}\")\n",
        "            print(f\"Added {len(new_df)} rows for file: {source_file}\")\n",
        "            print(f\"Total rows in CSV: {len(final_df)}\")\n",
        "        \n",
        "        return str(csv_path)\n",
        "        \n",
        "    async def save_evaluation_to_json(self, evaluation_results: Dict, source_file: str, json_path: str = None):\n",
        "        \"\"\"Save evaluation results to JSON file asynchronously.\"\"\"\n",
        "        json_path = json_path or self.default_json_path\n",
        "        \n",
        "        new_entry = {\n",
        "            \"source_file\": source_file,\n",
        "            \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            **{k: v for k, v in evaluation_results.items() if k != 'field_accuracies'}\n",
        "        }\n",
        "        \n",
        "        # Ensure directory exists\n",
        "        json_path_obj = Path(json_path)\n",
        "        json_path_obj.parent.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Load existing data or create empty list\n",
        "        data = []\n",
        "        if json_path_obj.exists():\n",
        "            async with aiofiles.open(json_path, 'r') as f:\n",
        "                content = await f.read()\n",
        "                try:\n",
        "                    data = json.loads(content) if content.strip() else []\n",
        "                except json.JSONDecodeError:\n",
        "                    data = []\n",
        "        \n",
        "        # Check if source_file already exists and replace/append\n",
        "        existing_index = next((i for i, entry in enumerate(data) if entry.get('source_file') == source_file), None)\n",
        "        \n",
        "        if existing_index is not None:\n",
        "            data[existing_index] = new_entry\n",
        "            print(f\"Updated existing results for {source_file}\")\n",
        "        else:\n",
        "            data.append(new_entry)\n",
        "            print(f\"Added new results for {source_file}\")\n",
        "        \n",
        "        # Save asynchronously\n",
        "        async with aiofiles.open(json_path, 'w') as f:\n",
        "            await f.write(json.dumps(data, indent=2))\n",
        "        \n",
        "        print(f\"Results saved to: {json_path}\")\n",
        "        return json_path\n",
        "    \n",
        "    async def run_and_save(self, pipeline, markdown_content: str, source_file_path: str, \n",
        "                          output_dir: str = None, override: bool = False):\n",
        "        \"\"\"Run pipeline and save results asynchronously.\"\"\"\n",
        "        prediction = await pipeline.forward(markdown_content)\n",
        "        extracted_records = prediction if isinstance(prediction, list) else prediction.extracted_records\n",
        "        \n",
        "        result_path = await self.save_extracted_results(\n",
        "            extracted_records, source_file_path, output_dir, override\n",
        "        )\n",
        "        return result_path\n",
        "\n",
        "\n",
        "print(\"Async Medical File Handler defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Initial Baseline Extraction Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running async baseline extraction...\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Malmstrom', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: placebo\n",
            "Processing intervention: rofecoxib 50 mg\n",
            "Processing intervention: celecoxib 200 mg\n",
            "Processing intervention: ibuprofen 400 mg\n",
            "Found 7 outcomes for placebo\n",
            "Found 7 outcomes for ibuprofen 400 mg\n",
            "Found 7 outcomes for rofecoxib 50 mg\n",
            "Found 7 outcomes for celecoxib 200 mg\n",
            "Total records extracted: 28\n",
            "\n",
            "Baseline extraction completed. Extracted 28 records.\n",
            "\n",
            "First extracted record:\n",
            "------------------------------\n",
            "First_Author: Malmstrom\n",
            "Population: 2\n",
            "Intervention_Code: 11\n",
            "Intervention_Description: placebo\n",
            "Outcome_Type: 6\n",
            "...\n",
            "\n",
            "==================================================\n",
            "RUNNING EVALUATION AND SAVING RESULTS...\n",
            "==================================================\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Intervention_Description: 'placebo' vs 'Ibuprofen 400 mg' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Follow_Up_Time: '24 hours' vs '24 hours' → Yes → True\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Nausea' vs 'Nausea' → Yes → True\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Nausea' vs 'Headache' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Nausea' vs 'Vomiting' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Headache' vs 'Nausea' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Headache' vs 'Headache' → Yes → True\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Headache' vs 'Vomiting' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Vomiting' vs 'Nausea' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Vomiting' vs 'Headache' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Vomiting' vs 'Vomiting' → Yes → True\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Follow_Up_Time: '8 to 13 days' vs '24 hours' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Elevated alanine aminotransferase' vs 'Nausea' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Elevated alanine aminotransferase' vs 'Headache' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Elevated alanine aminotransferase' vs 'Vomiting' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Elevated aspartate aminotransferase' vs 'Nausea' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Elevated aspartate aminotransferase' vs 'Headache' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Elevated aspartate aminotransferase' vs 'Vomiting' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Follow_Up_Time: '8 hours' vs '24 hours' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Intervention_Description: 'rofecoxib 50 mg' vs 'Ibuprofen 400 mg' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Follow_Up_Time: '8 to 13 days after dosing' vs '24 hours' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Alanine aminotransferase levels 1.5 to 3.5 times the upper limit of normal' vs 'Nausea' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Alanine aminotransferase levels 1.5 to 3.5 times the upper limit of normal' vs 'Headache' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Alanine aminotransferase levels 1.5 to 3.5 times the upper limit of normal' vs 'Vomiting' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Aspartate aminotransferase levels 1.5 to 7 times the upper limit of normal' vs 'Nausea' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Aspartate aminotransferase levels 1.5 to 7 times the upper limit of normal' vs 'Headache' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Adverse_Effect_Specify: 'Aspartate aminotransferase levels 1.5 to 7 times the upper limit of normal' vs 'Vomiting' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Intervention_Description: 'celecoxib 200 mg' vs 'Ibuprofen 400 mg' → No → False\n",
            "Added 1 new records to /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n",
            "[SemanticMatch] Intervention_Description: 'ibuprofen 400 mg' vs 'Ibuprofen 400 mg' → Yes → True\n",
            "DEBUG: Got 6 matches from evaluation\n",
            "Length of new_df 34\n",
            "Added new results for /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2467_Malmstrom_md/2467_Malmstrom_md.json\n",
            "Successfully saved 28 records to: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2467_Malmstrom_md/2467_Malmstrom_do.json\n",
            "Length of existing_df 2512\n",
            "Results saved to: /nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\n",
            "Results saved to: /nlp/data/karthik9/Sprint1/Dental/Data/csvs/do_evaluation_results.csv\n",
            "Added 34 rows for file: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2467_Malmstrom_md/2467_Malmstrom_md.json\n",
            "Total rows in CSV: 2546\n",
            "\n",
            "==================================================\n",
            "BASELINE EVALUATION RESULTS:\n",
            "==================================================\n",
            "num_extracted: 28\n",
            "completeness: 0.974025974025974\n",
            "semantic_enabled: True\n",
            "precision: 0.21428571428571427\n",
            "recall: 1.0\n",
            "f1: 0.35294117647058826\n",
            "TP: 6\n",
            "FP: 22\n",
            "FN: 0\n",
            "num_ground_truth: 6\n",
            "\n",
            "Results saved to:\n",
            "  - Pipeline results: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2467_Malmstrom_md/2467_Malmstrom_do.json\n",
            "  - Evaluation JSON: /nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\n",
            "  - Evaluation CSV:  /nlp/data/karthik9/Sprint1/Dental/Data/csvs/do_evaluation_results.csv\n"
          ]
        }
      ],
      "source": [
        "async def run_async_extraction_and_evaluation(markdown_content: str, source_file: str, \n",
        "                                             one_study_records: List[Dict], \n",
        "                                             override: bool = False):\n",
        "    \"\"\"Run the complete async extraction and evaluation pipeline (using AsyncMedicalFileHandler for all I/O).\"\"\"\n",
        "    print(\"Running async baseline extraction...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Initialize pipeline, evaluator, and *file handler*\n",
        "        async_pipeline = AsyncMedicalDataExtractionPipeline(max_concurrent=5)\n",
        "        async_evaluator = AsyncMedicalExtractionEvaluator(use_semantic=True, max_concurrent=10)\n",
        "        file_handler = AsyncMedicalFileHandler()  # uses your default paths/dirs\n",
        "\n",
        "        # ---- Extraction ----\n",
        "        baseline_prediction = await async_pipeline(markdown_content)\n",
        "        baseline_results = (\n",
        "            baseline_prediction \n",
        "            if isinstance(baseline_prediction, list) \n",
        "            else getattr(baseline_prediction, \"extracted_records\", [])\n",
        "        )\n",
        "\n",
        "        print(f\"\\nBaseline extraction completed. Extracted {len(baseline_results)} records.\")\n",
        "        if baseline_results:\n",
        "            print(\"\\nFirst extracted record:\")\n",
        "            print(\"-\" * 30)\n",
        "            for key, value in list(baseline_results[0].items())[:5]:\n",
        "                print(f\"{key}: {value}\")\n",
        "            print(\"...\")\n",
        "\n",
        "        # ---- Evaluation + Saves ----\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"RUNNING EVALUATION AND SAVING RESULTS...\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Run evaluation first (so we can include metrics + matches in saves)\n",
        "        baseline_evaluation = await async_evaluator.evaluate(baseline_results, one_study_records)\n",
        "        \n",
        "\n",
        "        # Pull matches if evaluator returns them ([(ext_idx, gt_idx, score), ...]); fall back to empty\n",
        "        #matches = baseline_evaluation.get(\"matches\", [])\n",
        "        matches = await async_evaluator.hungarian_matching(baseline_results, one_study_records)\n",
        "        print(f\"DEBUG: Got {len(matches)} matches from evaluation\")\n",
        "        # Launch all saves concurrently via the file handler\n",
        "        pipeline_save_task = file_handler.save_extracted_results(\n",
        "            extracted_records=baseline_results,\n",
        "            source_file_path=source_file,\n",
        "            output_dir=None,      # default to same dir or file_handler.default_output_dir\n",
        "            override=override\n",
        "        )\n",
        "\n",
        "        json_save_task = file_handler.save_evaluation_to_json(\n",
        "            evaluation_results=baseline_evaluation,\n",
        "            source_file=source_file,\n",
        "            json_path=None        # will use file_handler.default_json_path\n",
        "        )\n",
        "\n",
        "        csv_save_task = file_handler.save_evaluation_to_csv(\n",
        "            baseline_results=baseline_results,\n",
        "            ground_truth=one_study_records,\n",
        "            source_file=source_file,\n",
        "            matches=matches,      # needed for TP/FP/FN marking\n",
        "            csv_dir=None,         # will use file_handler.default_csv_dir\n",
        "            override=override\n",
        "        )\n",
        "\n",
        "        pipeline_path, json_path, csv_path = await asyncio.gather(\n",
        "            pipeline_save_task, json_save_task, csv_save_task\n",
        "        )\n",
        "\n",
        "        # ---- Print Summary ----\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"BASELINE EVALUATION RESULTS:\")\n",
        "        print(\"=\" * 50)\n",
        "        for key, value in baseline_evaluation.items():\n",
        "            if key != \"field_accuracies\":\n",
        "                print(f\"{key}: {value}\")\n",
        "\n",
        "        print(f\"\\nResults saved to:\")\n",
        "        print(f\"  - Pipeline results: {pipeline_path}\")\n",
        "        print(f\"  - Evaluation JSON: {json_path}\")\n",
        "        print(f\"  - Evaluation CSV:  {csv_path}\")\n",
        "\n",
        "        return {\n",
        "            \"baseline_results\": baseline_results,\n",
        "            \"baseline_evaluation\": baseline_evaluation,\n",
        "            \"files_saved\": {\n",
        "                \"pipeline\": pipeline_path,\n",
        "                \"json\": json_path,\n",
        "                \"csv\": csv_path\n",
        "            }\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in async extraction: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return {\n",
        "            \"baseline_results\": [],\n",
        "            \"baseline_evaluation\": {\"completeness\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0},\n",
        "            \"files_saved\": None\n",
        "        }\n",
        "\n",
        "result = await run_async_extraction_and_evaluation( markdown_content=markdown_content, source_file=source_file, one_study_records=one_study_records, override=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No new records to add\n",
            "\n",
            "DSPy History Stats from /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv:\n",
            "==================================================\n",
            "Total calls: 4104\n",
            "Unique models: 3\n",
            "Model breakdown:\n",
            "  gemini/gemini-2.5-pro: 4016 calls\n",
            "  openai/gpt-5-mini-2025-08-07: 58 calls\n",
            "  openai/gpt-4o-mini: 30 calls\n",
            "Total cost: $88.7986\n",
            "Average cost per call: $0.0216\n",
            "Total tokens: 3,020,487\n",
            "Average tokens per call: 736.0\n",
            "Cache hit rate: 75.3%\n",
            "Date range: 2025-09-16T10:33:45.131530 to 2025-09-18T18:49:54.231071\n"
          ]
        }
      ],
      "source": [
        "#Log the history  \n",
        "log_history()\n",
        "\n",
        "#Check stats anytime\n",
        "show_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete history saved to: complete_lm_history_20250918_181204.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'complete_lm_history_20250918_181204.json'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import dspy\n",
        "from datetime import datetime\n",
        "\n",
        "def save_complete_history(lm, filename=None):\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"complete_lm_history_{timestamp}.json\"\n",
        "    \n",
        "    # Convert history to JSON-serializable format\n",
        "    complete_data = {\n",
        "        \"metadata\": {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"total_calls\": len(lm.history),\n",
        "            \"model_info\": str(type(lm).__name__),\n",
        "        },\n",
        "        \"history\": []\n",
        "    }\n",
        "    \n",
        "    for i, entry in enumerate(lm.history):\n",
        "        call_data = {\n",
        "            \"call_number\": i + 1,\n",
        "            \"entry_type\": str(type(entry).__name__),\n",
        "            \"raw_entry\": {}\n",
        "        }\n",
        "        \n",
        "        # Handle different types of entries\n",
        "        if hasattr(entry, '__dict__'):\n",
        "            # If it's an object, get all attributes\n",
        "            for key, value in entry.__dict__.items():\n",
        "                try:\n",
        "                    # Try to serialize the value\n",
        "                    json.dumps(value)\n",
        "                    call_data[\"raw_entry\"][key] = value\n",
        "                except (TypeError, ValueError):\n",
        "                    # If not serializable, convert to string\n",
        "                    call_data[\"raw_entry\"][key] = str(value)\n",
        "        elif isinstance(entry, dict):\n",
        "            # If it's already a dict, copy all keys\n",
        "            for key, value in entry.items():\n",
        "                try:\n",
        "                    json.dumps(value)\n",
        "                    call_data[\"raw_entry\"][key] = value\n",
        "                except (TypeError, ValueError):\n",
        "                    call_data[\"raw_entry\"][key] = str(value)\n",
        "        else:\n",
        "            # If it's something else, convert to string\n",
        "            call_data[\"raw_entry\"][\"content\"] = str(entry)\n",
        "        \n",
        "        complete_data[\"history\"].append(call_data)\n",
        "    \n",
        "    # Save to file\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(complete_data, f, indent=2, ensure_ascii=False, default=str)\n",
        "    \n",
        "    print(f\"Complete history saved to: {filename}\")\n",
        "    return filename\n",
        "\n",
        "# Usage\n",
        "save_complete_history(lm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Example Generation and Few-Shot Learning Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ No ground truth records found for 3287_Cooper, skipping...\n",
            "Total folders found: 51\n",
            "Examples created: 50\n",
            "Missed studies: 1\n",
            "  - 3287_Cooper (no_records)\n",
            "Raw Example object:\n",
            "Example({'markdown_content': '# **Dental Research Journal**\\n\\n# **Original Article**\\n\\n# **Comparison of anti‑inflammatory and analgesic effects of\\u200a Ginger powder and Ibuprofen in postsurgical pain model: A randomized, double‑blind, case–control clinical trial**\\n\\n#### **Farshid Rayati1 , Fatemeh Hajmanouchehri2 , Elnaz Najafi<sup>3</sup>**\\n\\n1 Department of Oral and Maxillofacial Surgery, Dental Caries Prevention Research Center, Qazvin University of Medical Sciences, 2 Department of Clinical and Anatomical Pathology, Qazvin University of Medical Sciences, Qazvin, 3 Department of Orthodontics, School of Dentistry, Islamic Azad University of Isfahan, Isfahan, Iran\\n\\n#### **ABSTRACT**\\n\\n**Background:** Ginger has been used as an herbal drug for a long time for the treatment of chronic inflammatory conditions.\\n\\n**Materials and Methods:** This randomized, double‑blind clinical trial was conducted on 67 healthy adults with at least one impacted lower third molar. Participants were randomly allocated into three groups: Ibuprofen, Ginger, and placebo. Evaluation of inflammation was done by measuring cheek swelling, mouth opening ability, serum C‑reactive protein (CRP) levels, and visual analog scale (for pain scoring). The number and the time of using rescue medication were recorded too.\\n\\n**Received:** September 2015 **Accepted:** August 2016\\n\\n**Address for correspondence:** Dr. Farshid Rayati, Department of Oral and Maxillofacial Surgery, Dental Caries Prevention Research Center, Qazvin University of Medical Sciences, Bahonar Blvd., Qazvin, Iran. E‑mail: frayati@qums.ac.ir\\n\\n**Results:** Sixty patients completed the study. In all three groups, there was a significant increase in the mean cheek swelling measures, compared with the baseline, until day 5. The reduction in mouth opening ability was significant in all three groups, compared with the baseline, until day 5. There was no significant difference between ibuprofenand ginger groups in pain scores in all follow‑up days. Number of required rescue medication on the day of surgery was significantly more in the placebo group. No significant or strong correlations were found between CRP levels and clinical findings. **Conclusion:** Within the limitations of this study, it can ban be concluded that gingerpowder is as effective as ibuprofenin the management of postsurgical sequelae. Furthermore, CRP levels alone are not suggested for the assessment of anti‑inflammatory effects of drugs.\\n\\n**Key Words:** C‑reactive protein, Ginger, Ibuprofen, surgery, third molar\\n\\n# **INTRODUCTION**\\n\\nGinger, the rhizome of *Zingiber officinale*, has been used as an herbal drug for a long time. In traditional Chinese and Indian medicine, gingerhas been used to treat a wide range of diseases including stomach ache, diarrhea, nausea, asthma, respiratory disorders, toothache, gingivitis, and arthritis. A number of studies have shown interest in gingerfor the treatment\\n\\n#### **Access this article online**\\n\\n**Website:** www.drj.ir www.drjjournal.net www.ncbi.nlm.nih.gov/pmc/journals/1480 of chronic inflammatory conditions. This interest can be traced to the discovery in the early 1970s that nonsteroidal anti‑inflammatory drugs (NSAIDs) insert their effects by inhibiting the biosynthesis of prostaglandins (PGs). Soon thereafter, ginger was found to contain constituents that inhibit PG synthesis\\n\\n**For reprints contact:** reprints@medknow.com\\n\\n**How to cite this article:** Rayati F, Hajmanouchehri F, Najafi E. Comparison of anti-inflammatory and analgesic effects of Ginger powder and Ibuprofen in postsurgical pain model: A randomized, double-blind, case–control clinical trial. Dent Res J 2017;14:1-7.\\n\\nThis is an open access article distributed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License, which allows others to remix, tweak, and build upon the work non-commercially, as long as the author is credited and the new creations are licensed under the identical terms.\\n\\ntoo. This finding provided a sound scientific rationale for its anti‑inflammatory effects. Subsequent studies revealed that some of the constituents of ginger have pharmacological properties similar to the novel class of dual-acting NSAIDs. Compounds in this class can inhibit arachidonic acid metabolism through both the cyclooxygenase (COX) and lipoxygenase (LOX) pathways and have notably fewer side effects than conventional NSAIDs.[1,2] Different animal studies revealed that orally prescribed dried ginger or ginger extract can reduce acute inflammation.[3-6] Several clinical studies support the value of ginger for the treatment of osteoarthritis, and in some cases, a significant reduction in knee pain was reported.[1,7-9] In some of these trials, it was resulted that Ginger relieved pain and swelling to varying degrees in patients with osteoarthritis, rheumatoid arthritis, and muscular pain without causing serious adverse effects even after long periods of use.[10] Ozgoli *et al.* tested ginger in primary dysmenorrhea in comparison with ibuprofen and mefenamic acid, and no significant differences were found between the study groups in relief, stability, or aggravation of symptoms.[11]\\n\\nIn this study, dental pain model is used because it is a widely employed, validated, and highly standardized acute pain model and is the most appropriate model to investigate the onset of analgesic action.[12] The model is widely accepted and has a proven record of assay sensitivity. Therefore, it is often used as the primary clinical pain model for the investigation of analgesic drugs.[13] Compounds with anti‑inflammatory properties provide better analgesia than centrally acting analgesics in this model.[12]\\n\\nThe common postoperative sequelae of surgical removal of impacted teeth are pain, trismus, and swelling with COX and PGs playing a central role.[13] The efficacy of ibuprofen in the treatment of postoperative dental pain has been demonstrated in several clinical trials. However, NSAIDs are contraindicated in patients with gastrointestinal ulcers, bleeding disorders, and renal dysfunctions.[13-17] Therefore, there is a need for an effective analgesic with a more favorable safety profile. In the literature, despite high anti‑inflammatory potential of ginger constituents, it was used mainly against chronic inflammatory conditions while its effect on acute inflammation was assessed in animal studies and rare clinical trials. Therefore, our aim was to investigate the ability of ginger powder to reduce postoperative sequelae after mandibular third molar surgery.\\n\\n# **MATERIALS AND METHODS**\\n\\nThe protocol of this randomized, double-blind, placebo-controlled study was approved by the Ethics Committee of the local institution in Qazvin. In the limited time of 12 months, all patients fulfilling the criteria of the study were entered. All the study protocols were explained to each patient, and an informed written consent was obtained from all volunteers.\\n\\n# **Patients**\\n\\nSixty-seven outpatients undergoing elective surgical removal of impacted mandibular third molars participated in the present study. All patients were of the American Society of Anesthesiologists class I, aged 18–35 of either sex, with at least high school graduation diploma educational degree and at least one impacted mandibular third molar. Reasons for exclusion from the study were known allergy to the study medications, pregnancy or lactating, history of peptic ulceration, history of corticosteroid use, history of any kind of inflammatory conditions or taking any medication since 1 month before surgery, duration of surgery more than 30 min, any infection, fever or suffering any kind of disease during the following days, any mouthwash (except normal saline) or applying ice pack use during the following days, failure to attend the follow-up, using any kind of medication other than prescribed in this study, mentally incapable of understanding or complying with the study protocol, or refusing to sign the informed consent.\\n\\nBaseline investigations including a panoramic view of the jaws and clinical evaluation of the third molars were done by a single oral and maxillofacial surgeon to\\u200a score the difficulty.[18]\\n\\n# **Study design**\\n\\nPatients fulfilling the criteria were randomly allocated into one of the three groups to receive one capsule of ginger containing 500 mg of ginger rhizome powder (Zintoma; Goldaru Co., Iran), one capsule of ibuprofen 400 mg (ibuprofen; Arya Co., Iran), or placebo. All medications were prepared by a pharmacist and packed in similar capsules and packages. All the packages were coded by the pharmacist. Operator, and other members of the team had no knowledge of the medications under each code. The placebo was a capsule containing starch. All medications were administered orally and 6 hourly. The first dose was administered immediately\\n\\nafter completion of surgery and before terminating of the anesthetic effect. Rescue medication in the form of acetaminophen (500 mg with at least 4 h intervals) was allowed when required after surgery for all the patients. Patients were encouraged not to use any rescue medication for the first 4 h postoperatively. The time and number of rescue medication each patient took was recorded by the patient in the prepared questioners. All patients received amoxicillin 500 mg 8 hourly for 1 week postoperatively to prevent infection of the surgical site.\\n\\nAll the surgeries were accomplished by a single maxillofacial surgeon. Surgery was carried out under routine local anesthesia (lidocaine 2% +1:80,000 epinephrine, inferior alveolar nerve block with long buccal nerve block). The surgical procedure consisted of a buccal incision started from ascending ramus to the mesial of second molar, mucoperiosteal flap elevation, buccal and distal bone removal, splitting and elevation of the impacted tooth, rinsing the socket by normal saline and interrupted simple suturing using 3/0 braided silk. The exact time at which surgery ended, duration of each operation and the quantity of the consumed local anesthetic cartridges were recorded. Written forms containing standard postoperative instructions were given to patients in addition to researchers\\' explanations. Patients were not allowed to use any kind of mouthwashes (except normal saline) or ice packs until the last follow‑up day. After surgery, it was explained for all patients how they have to use the medications and fill in the questionnaires.\\n\\nPostoperatively, parameters of cheek swelling, pain, amount of mouth opening, and serum high-sensitivity C‑reactive protein (hsCRP) concentration were measured. Cheek swelling was recorded by cheek thickness measurement using\\u200a standard calipers,[18] from the mucosal lingual aspect of the cheek opposite to the mid-portion of the crown of the mandibular first molar to the tangent of the skin of the cheek, before surgery (baseline) and on days 1, 3, and 5 postoperatively. To have similar and consistent amount of mouth opening in patients at the time of measuring the cheek thickness, we used a modified bite block in premolar area for all patients. With this bite block, patients had the minimum amount of mouth opening (4–5 mm), in which measuring the cheek thickness was possible.\\n\\nMouth opening ability was assessed by measuring the distance between the upper and lower central incisal edges at maximal mouth opening before surgery (baseline) and on days 1, 3, and 5 after surgery. Pain was assessed using a 100 mm visual analog scale (VAS) stretching from \"no pain\" (0 mm) to \"the worse pain I\\'ve ever had\" (100 mm) before surgery, at 1 h intervals in the first 12 h following the surgery and every 6 h until day 4 after surgery. Pain intensity measurement was made by the patient at home and in prepared questionnaires. To measure serum CRP concentrations, the first venous blood sample (4 ml) was collected immediately after surgery and before taking the medication and the second sample was collected 72 h after surgery (5 ml). Samples immediately delivered to the laboratory and centrifuged. The separated serums were assessed using sandwich ELISA technique to quantitatively determine CRP concentrations.\\n\\nAny adverse drug reaction during the study was recorded by patients or the investigator.\\n\\n# **Statistical analysis**\\n\\nStatistical analysis was performed using SPSS version 15(SPSS Inc. IBM Corporation). Repeated measure and ANOVA tests were used to assess the significance of changes of mean cheek swelling (mCS) and mean maximum mouth opening (mMMO). To analyze the VAS scores\\' variations, Mann–Whitney and ANOVA tests were used. To assess the changes in CRP amounts and the correlation between CRP levels and clinical symptoms, ANOVA test and Pearson correlation coefficient were used, respectively. Statistical significance was assumed at 0.05.\\n\\n# **RESULTS**\\n\\nOut off 67 participants entered into the study (26 men, 41 women), seven (two men, five women) were excluded due to two follow-up visits failure, one because blood sampling was not possible, two for catching cold in the follow-up days, one for not taking the drugs, and one for reporting heartburn on the second day after surgery. Hence, data of sixty patients were analyzed. There were no significant differences in demographic and baseline characteristics, operation time, and amount of consumed local anesthetic for the surgery [Table 1].\\n\\nParameters of mouth opening and cheek swelling were assessed three times in each follow-up visit, and the mean was used in analyses [Tables 2 and 3]. The mean amount of cheek swelling (mCS) and mean amount of mMMO were recorded in the follow-up\\n\\ndays (baseline, days 1, 3, and 5 postoperatively) and their changes were assessed in and between groups. In the intergroup assessment, the amount of mCS and mMMO of each drug in each follow-up day was compared to the baseline and to the first postoperative day (in which the maximum amount of mCS and minimum amount of mMMO were observed). In the intragroup assessment, the amount of mCS and mMMO changes of each drug in each follow-up day was compared with other drugs. Regarding mCS, the intergroup assessments demonstrated that in all three groups, there was a significant increase in the mCS compared with the baseline until day 5. In addition, in all three groups, no significant reduction in amounts of mCS was observed on days 3 and 5 compared with day 1. The intragroup assessment showed no significant differences of mCS changes in follow-up days between three groups.\\n\\nIn all follow-up days, no significant increase in the amount of mMMO was observed in follow-up days compared with the baseline in any of three groups. In addition, there was no significant increase in amounts\\n\\n# **Table 1: Demographic characteristics of the study** patients ( $n$ =60), duration of surgery and amount of local anesthetic used (mean±standard deviation)\\n\\n| <b>Demographic data</b>       | Ibuprofen Placebo Ginger |               |              | $\\\\boldsymbol{P}$ |\\n|-------------------------------|--------------------------|---------------|--------------|------------------|\\n| Gender                        |                          |               |              |                  |\\n| Women                         | 13                       | 10            | 13           | $NS^*$           |\\n| Men                           | 7                        | 10            | 7            |                  |\\n| Ratio                         | 1.8:01                   | 1:01          | 1.8:01       |                  |\\n| Age                           | $22 \\\\pm 4.1$             | $22 \\\\pm 3.1$  | $23 + 2.8$   | NS               |\\n| Duration of surgery           | $14 \\\\pm 5.3$             | $14 \\\\pm 5.09$ | $16 \\\\pm 5.8$ | NS               |\\n|                               | 2.07                     | 2.12          | 2.05         | NS               |\\n| Number of anesthetic carpules |                          |               |              |                  |\\n\\n\\\\*NS: No significant difference was found\\n\\n#### **Table 2: Mean of cheek swelling of patients** on the day of surgery and follow-up sessions (mean±standard deviation)\\n\\n| Treatment groups Day 0 (baseline) Day 1 |                | Dav 3                                        | Dav 5 |\\n|-----------------------------------------|----------------|----------------------------------------------|-------|\\n| lbuprofen                               | $31.5 \\\\pm 4.8$ | $37.8 \\\\pm 5$ $37 \\\\pm 4.7$ $34.7 \\\\pm 4.4$     |       |\\n| Placebo                                 | $30.9 \\\\pm 5.5$ | $36.4 \\\\pm 6.3$ $35.9 \\\\pm 5.8$ $33.8 \\\\pm 4.5$ |       |\\n| Ginger                                  | $30.7 \\\\pm 4.7$ | $35.4 \\\\pm 4.5$ $34.5 \\\\pm 4.2$ $32.6 \\\\pm 3.7$ |       |\\n|                                         |                |                                              |       |\\n\\n#### **Table 3: Mean of maximum mouth opening of** patients on the day of surgery and follow-up sessions (mean±standard deviation)\\n\\n| Treatment groups Day 0 (baseline) Day 1 Day 3 Day 5 |                |                                           |  |\\n|-----------------------------------------------------|----------------|-------------------------------------------|--|\\n| Ibuprofen                                           | $46.3 \\\\pm 7.5$ | $32 \\\\pm 10$ $32.5 \\\\pm 10$ $36.3 \\\\pm 11$   |  |\\n| Placebo                                             | $47.1 \\\\pm 8.8$ | $32.6 \\\\pm 12$ $34.8 \\\\pm 11$ $38.1 \\\\pm 12$ |  |\\n| Ginger                                              | $45.1 \\\\pm 8.1$ | $32.9 \\\\pm 10$ $32.5 \\\\pm 11$ $35.3 \\\\pm 10$ |  |\\n\\nof mMMO on days 3 and 5 compared with day 1. There was no significant difference between three groups and in any of the follow-up days in mMMO amounts.\\n\\nThere was no significant difference in CRP concentrations in the immediate postoperative samples among the groups. Blood samples collected 72 h postoperatively showed significant elevations in CRP levels. However, this difference was not significant between the groups. Correlations of CRP levels and severity of clinical symptoms (VAS, mCS and mMMO) between day 3 and baseline were assessed too. Results revealed no significant and strong correlations between these parameters.\\n\\nThere was no significant difference in presurgical pain intensity between groups [Table 4 and Figure 1]. In all groups, the maximum pain score was reported on the day of surgery (day  $0$ ). In this day, in ibuprofen and ginger groups, the mean pain score was in mild range  $(30-45)$ , and in placebo group, it was in moderate range (45–70). There was no significant difference between ibuprofen and ginger groups in reported pain scores of the day of surgery (day  $0$ ); however, in some of the postoperative hours, ginger and ibuprofen decreased pain intensity significantly more than placebo. None of the groups showed a significant reduction in pain intensity scores on day 1 in comparison with day 0. In both ibuprofen and ginger groups, the mean pain scores were reduced significantly from day 2 onward in comparison with placebo, but this amount was not significantly different between ibuprofen and ginger groups. The mean pain intensity scores of days 1, 2, 3, and 4 were not significantly different between three groups [Table 5].\\n\\nData regarding the use of rescue medication in all groups are presented in Table 6. The placebo group\\n\\n![](_page_3_Figure_15.jpeg)\\n\\nFigure 1: Median pain score (mm) of three study groups on the day of surgery (day 0).\\n\\nrequired acetaminophen significantly more than other groups on the day 0. In placebo group, 80% of patients took their first rescue medication in the first 2–4 h after surgery, but in other groups, only 35% of patients did.\\n\\nNo abnormal wound bleeding was observed in the follow-up sessions. Only two patients in Ginger group complained of their wound oozing 48 h after surgery. No adverse drug reactions that need any alteration in the treatment were reported.\\n\\n# **DISCUSSION**\\n\\nThe common postsurgical sequelae of third molar surgery are related to local inflammatory reactions with COX pathway and PGs playing an important role in it.[12] The efficacy of corticosteroids and NSAIDs which directly affect this inflammatory pathway has been evaluated in several studies.[14,16,17] In the present study, regarding the dual COX and LOX inhibitory\\n\\n**Table 4: Median pain score (mm) on the day of surgery (day 0) (median±standard error)**\\n\\n| Symptoms According to the | Treatment groups |          |          |  |\\n|---------------------------|------------------|----------|----------|--|\\n| drug used                 | Ibuprofen        | Placebo  | Ginger   |  |\\n| Before surgery            | 0                | 0        | 0        |  |\\n| After 1 h                 | 11.9±3.8         | 16.6±5   | 22.9±7.6 |  |\\n| After 2 h                 | 23.2±5.8         | 45.4±6.9 | 30.6±7.5 |  |\\n| After 3 h                 | 34.6±7.5         | 56±5.7   | 35.9±6.7 |  |\\n| After 4 h                 | 35.2±7.2         | 55±4.6   | 37.9±6.5 |  |\\n| After 5 h                 | 33.5±7.3         | 44.3±4.4 | 36.5±5.8 |  |\\n| After 6 h                 | 30.8±6.9         | 42.3±4   | 35±6.3   |  |\\n| After 7 h                 | 26.9±6.8         | 38±4.2   | 29.3±6.7 |  |\\n| After 8 h                 | 24.2±6.2         | 39.5±4.2 | 29.9±6.9 |  |\\n| After 9 h                 | 21±6.6           | 36.5±4.3 | 31.5±7.6 |  |\\n| After 10 h                | 15.4±5.5         | 31.4±4.7 | 30.5±7.6 |  |\\n| After 11 h                | 16.6±5.5         | 27.9±3.5 | 27.5±6.6 |  |\\n| After 12 h                | 19.5±6.4         | 24.1±3.1 | 24.6±6.3 |  |\\n|                           |                  |          |          |  |\\n\\n#### **Table 5: Mean pain score (mm), day 0 through day 4 (mean±standard deviation)**\\n\\n| Day 0    | Day 1    | Day 2  | Day 3    | Day 4   |\\n|----------|----------|--------|----------|---------|\\n| 24.4±5.3 | 17.2±5.3 | 12±3.7 | 8.4±2.8  | 9.7±3.1 |\\n| 38.1±3   | 18.4±2.3 | 10±2.7 | 6.5±2.5  | 3.5±1.8 |\\n| 31±6.1   | 19±5.8   | 16±5.6 | 15.1±5.2 | 13±4.3  |\\n|          |          |        |          |         |\\n\\nreaction of ginger, we tried to assess ginger\\'s ability to control the postoperative sequelae of this acute pain model.\\n\\nNo significant differences were observed in mean mouth opening ability and mCS between ibuprofen, ginger, and placebo groups. All patients were experienced their greatest level of pain on the day of surgery with a peak of 4 h after surgery which was in the range of previous studies\\' reports. On the surgery day and all postoperative follow‑up days, ginger was as effective as ibuprofen in reducing postoperative pain intensity. The total number of used rescue medications was not significantly different between groups; however, on the day of surgery, the placebo group took rescue medication two times more than the other groups.\\n\\nIbuprofen is the most commonly used drug for pain relief after oral surgery. In the previous studies, ibuprofen was not superior to placebo in reducing postoperative swelling but was significantly effective in reducing the pain on the day of surgery.[14] Our results about ibuprofen confirmed the earlier studies. It has been shown that ginger was as effective as ibuprofen and mefenamic acid in relieving menstrual pain.[11] Different studies have assessed the efficacy of ginger in reducing osteoarthritic pain and symptoms. Haghighi *et al.* indicated that ginger extract could be used as an alternative to ibuprofen and as a supplement drug in patients with osteoarthritis.[9] Bliddal *et al.* found that ibuprofen was significantly more effective than ginger and ginger was significantly more effective than placebo in relieving chronic pain and the same trend was found for acetaminophen consumption.[8] In a crossover study, Wigler *et al.* reported that in the 12 weeks period of the first phase (before crossover), ginger showed the placebo effect, but at the end of the second phase and after 24 weeks, the groups reached a statistically significant difference. They concluded that these results were due to delayed effect of ginger extract and lack of a washout period in the research.[7] Following reasons limit the exact comparison of our results with the previously mentioned studies: Chronic inflammatory process of assessed disease, a different form of prescribed ginger (extract vs. powder), duration\\n\\n#### **Table 6: Amount and time of used rescue medications**\\n\\n| Treatment | Number of patients     | Total number of used | Number of rescue          | Amount of time passed before         |\\n|-----------|------------------------|----------------------|---------------------------|--------------------------------------|\\n| group     | used rescue medication | rescue medication    | medication taken on day 0 | taking first rescue medication (min) |\\n| Ibuprofen | 21                     | 40                   | 17                        | 218                                  |\\n| Placebo   | 28                     | 53                   | 33                        | 204                                  |\\n| Ginger    | 22                     | 51                   | 18                        | 221                                  |\\n\\nof treatment, and difference in assessed clinical signs and symptoms. In our study, the difference between ibuprofen and ginger groups was not significant in any of the postoperative sequelae. Our results indicate that ginger was almost as effective as ibuprofen in relieving postoperative sequelae. In some of the studies which used third mandibular molar surgery pain model, only CRP concentration was assessed to indicate the anti‑inflammatory effect of different drugs and methods.[19,20] We found no strong or significant correlations between CRP levels and clinical symptoms in this study. Assessment of different ginger extracts and more specific inflammatory mediators besides clinical symptoms are our suggestions for further studies.\\n\\n# **CONCLUSION**\\n\\nWithin the limitations of this study, it can be concluded that ginger is as effective as ibuprofen in controlling postoperative sequelae, especially pain, and it can be an efficient substitute for this synthetic agents. Considering the standard deviation and interquartile range which indicated more data scattering in ginger group, however, it seems that ibuprofen, at least in some parts of the day of surgery, may be more efficient in pain control. Lack of significant correlations between CRP levels and severity of clinical symptoms makes using serum CRP concentrations as the only criteria for anti‑inflammatory effect assessment, inappropriate.\\n\\n# **Acknowledgments**\\n\\nThe authors wish to thank Dr. Mehran Pourghasemi for his valuable assistance in preparing the study drugs.\\n\\n# **Financial support and sponsorship**\\n\\nThis research was financially supported by the research deputy of Qazvin University of Medical Sciences.\\n\\n# **Conflicts of interest**\\n\\nThe authors of this manuscript declare that they have no conflicts of interest, real or perceived, financial or non‑financial in this article.\\n\\n# **REFERENCES**\\n\\n- 1. Grzanna R, Lindmark L, Frondoza CG. Ginger An herbal medicinal product with broad anti‑inflammatory actions. J Med Food 2005;8:125-32.\\n- 2. AliBH, BlundenG, TaniraMO, NemmarA. Some phytochemical, pharmacological and toxicological properties of ginger\\n\\n(*Zingiber officinale* Roscoe): A review of recent research. Food Chem Toxicol 2008;46:409-20.\\n\\n- 3. Chrubasik S, Pittler MH, Roufogalis BD. Zingiberis rhizoma: A comprehensive review on the ginger effect and efficacy profiles. Phytomedicine 2005;12:684-701.\\n- 4. Ojewole JA. Analgesic, antiinflammatory and hypoglycaemic effects of ethanol extract of *Zingiber officinale* (Roscoe) rhizomes (*Zingiberaceae*) in mice and rats. Phytother Res 2006;20:764-72.\\n- 5. Aimbire F, Penna SC, Rodrigues M, Rodrigues KC, Lopes‑Martins RA, Sertié JA. Effect of hydroalcoholic extract of *Zingiber officinalis* rhizomes on LPS-induced rat airway hyperreactivity and lung inflammation. Prostaglandins Leukot Essent Fatty Acids 2007;77:129-38.\\n- 6. FoudaAM, Berika MY. Evaluation of the effect of hydroalcoholic extract of *Zingiber officinale* rhizomes in rat collagen-induced arthritis. Basic Clin Pharmacol Toxicol 2009;104:262-71.\\n- 7. Wigler I, Grotto I, Caspi D, Yaron M. The effects of Zintona EC (a ginger extract) on symptomatic gonarthritis. Osteoarthritis Cartilage 2003;11:783-9.\\n- 8. BliddalH, RosetzskyA, SchlichtingP, WeidnerMS, AndersenLA, Ibfelt HH, *et al.* A randomized, placebo-controlled, cross-over study of ginger extracts and ibuprofen in osteoarthritis. Osteoarthritis Cartilage 2000;8:9-12.\\n- 9. Haghighi M, Khalvat A, Toliat T, Jallaei SH. Comparing the effects of ginger (*Zingiber officinale*) extract and ibuprofen on patients with osteoarthritis. Arch Iran Med 2005;8:267-71.\\n- 10. Abascal K, Yarnel E. Clinical uses of *Zingiber officinale* (ginger). J Altern Complement Med 2009;15:231-7.\\n- 11. Ozgoli G, Goli M, Moattar F. Comparison of effects of ginger, mefenamic acid, and Ibuprofen on pain in women with primary dysmenorrhea. J Altern Complement Med 2009;15:129-32.\\n- 12. Kleinert R, Lange C, Steup A, Black P, Goldberg J, Desjardins P. Single dose analgesic efficacy of tapentadol in postsurgical dental pain: The results of a randomized, double-blind, placebo-controlled study. Anesth Analg 2008;107:2048-55.\\n- 13. Daniels S, Reader S, Berry P, Goulder M. Onset of analgesia with sodium ibuprofen, ibuprofen acid incorporating poloxamer and acetaminophen –A single-dose, double-blind, placebo-controlled study in patients with post-operative dental pain. Eur J Clin Pharmacol 2009;65:343-53.\\n- 14. Chopra D, Rehan HS, Mehra P, Kakkar AK. A randomized, double‑blind, placebo‑controlled study comparing the efficacy and safety of paracetamol, serratiopeptidase, ibuprofen and betamethasone using the dental impaction pain model. Int J Oral Maxillofac Surg 2009;38:350-5.\\n- 15. Hupp RJ. Postoperative patient management. In: Hupp RJ, Eliss E 3rd, Tucker RM, editors. Contemporary Oral and Maxillofacial Surgery. Chicago: Mosby; 2008. p. 179.\\n- 16. Jung YS, Kim DK, Kim MK, Kim HJ, Cha IH, Lee EW. Onset of analgesia and analgesic efficacy of tramadol/acetaminophen and codeine/acetaminophen/ibuprofen in acute postoperative pain: A single-center, single-dose, randomized, active-controlled, parallel-group study in a dental surgery pain model. Clin Ther 2004;26:1037-45.\\n- 17. Litkowski LJ, Christensen SE, Adamson DN, Van Dyke T,\\n\\nHan SH, Newman KB. Analgesic efficacy and tolerability of oxycodone 5 mg/ibuprofen 400 mg compared with those of oxycodone 5 mg/acetaminophen 325 mg and hydrocodone 7.5 mg/acetaminophen 500 mg in patients with moderate to severe postoperative pain: A randomized, double-blind, placebo-controlled, single-dose, parallel-group study in a dental pain model. Clin Ther 2005;27:418-29.\\n\\n18. Marciani RD. Third molar removal: An overview of indications,\\n\\nimaging, evaluation, and assessment of risk. Orall Maxillofac Surg Clin North Am 2007;19:1-13.\\n\\n- 19. El-Sharrawy EA, El-Hakim IE, Sameeh E. Attenuation of C-reactive protein increases after exodontia by tramadol and ibuprofen. Anesth Prog 2006;53:78-82.\\n- 20. Freitas AC, Pinheiro AL, Miranda P, Thiers FA, Vieira AL. Assessment of anti‑inflammatory effect of 830 nm laser light using C-reactive protein levels. Braz Dent J 2001;12:187-90.', 'extracted_records': [{'Ref_ID': 1003, 'First_Author': 'Rayati', 'Trial_Name': '', 'Population': 2, 'Intervention_Code': 6, 'Intervention_Description': 'Ibuprofen 400 mg', 'Outcome_Type': 2, 'Outcome_Other_Specify': '', 'Follow_Up_Time': '4 hours', 'N_Analyzed': 20, 'Adverse_Effect_Specify': '', 'Adverse_Effects_All_Study': '', 'N_Events_Number': 7, 'N_Events_Percentage': 35, 'Comments': 'dose every 6 hours', 'filename': '1003_Rayati'}, {'Ref_ID': 1003, 'First_Author': 'Rayati', 'Trial_Name': '', 'Population': 2, 'Intervention_Code': 11, 'Intervention_Description': '', 'Outcome_Type': 2, 'Outcome_Other_Specify': '', 'Follow_Up_Time': '4 hours', 'N_Analyzed': 20, 'Adverse_Effect_Specify': '', 'Adverse_Effects_All_Study': '', 'N_Events_Number': 16, 'N_Events_Percentage': 80, 'Comments': '', 'filename': '1003_Rayati'}, {'Ref_ID': 1003, 'First_Author': 'Rayati', 'Trial_Name': '', 'Population': 2, 'Intervention_Code': 6, 'Intervention_Description': 'Ibuprofen 400 mg', 'Outcome_Type': 5, 'Outcome_Other_Specify': '', 'Follow_Up_Time': '4 days', 'N_Analyzed': 20, 'Adverse_Effect_Specify': '', 'Adverse_Effects_All_Study': 'Any adverse drug reaction during the study. No further description.', 'N_Events_Number': 0, 'N_Events_Percentage': 0, 'Comments': 'follow-up is 4 days PO; dose every 6 hours', 'filename': '1003_Rayati'}, {'Ref_ID': 1003, 'First_Author': 'Rayati', 'Trial_Name': '', 'Population': 2, 'Intervention_Code': 11, 'Intervention_Description': '', 'Outcome_Type': 5, 'Outcome_Other_Specify': '', 'Follow_Up_Time': '4 days ', 'N_Analyzed': 20, 'Adverse_Effect_Specify': '', 'Adverse_Effects_All_Study': 'Any adverse drug reaction during the study. No further description.', 'N_Events_Number': 0, 'N_Events_Percentage': 0, 'Comments': 'follow-up is 4 days PO', 'filename': '1003_Rayati'}]}) (input_keys={'markdown_content'})\n",
            "\n",
            "Accessing fields:\n",
            "Input (markdown_content): # **Dental Research Journal**\n",
            "\n",
            "# **Original Articl ...\n",
            "Expected output (extracted_records): {'Ref_ID': 1003, 'First_Author': 'Rayati', 'Trial_Name': '', 'Population': 2, 'Intervention_Code': 11, 'Intervention_Description': '', 'Outcome_Type': 2, 'Outcome_Other_Specify': '', 'Follow_Up_Time': '4 hours', 'N_Analyzed': 20, 'Adverse_Effect_Specify': '', 'Adverse_Effects_All_Study': '', 'N_Events_Number': 16, 'N_Events_Percentage': 80, 'Comments': '', 'filename': '1003_Rayati'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict\n",
        "import dspy\n",
        "\n",
        "def create_dspy_examples(markdown_content: str, one_study_records: List[Dict]) -> List[dspy.Example]:\n",
        "    \"\"\"\n",
        "    Create one dspy.Example per study, with markdown_content as input\n",
        "    and all structured records as the expected output.\n",
        "    \"\"\"\n",
        "    if not markdown_content or not one_study_records:\n",
        "        return []\n",
        "    \n",
        "    example = dspy.Example(\n",
        "        markdown_content=markdown_content,\n",
        "        extracted_records=one_study_records\n",
        "    ).with_inputs(\"markdown_content\")\n",
        "    \n",
        "    return [example]\n",
        "\n",
        "\n",
        "def create_examples_for_all_studies(md_dir: str, target_file: str) -> List[dspy.Example]:\n",
        "    \"\"\"\n",
        "    Loop through all study _md folders and build DSPy examples.\n",
        "    \n",
        "    Args:\n",
        "        md_dir: directory containing *_md study folders\n",
        "        target_file: path to dichotomous_outcomes.json\n",
        "    \n",
        "    Returns:\n",
        "        List of dspy.Example objects (one per study)\n",
        "    \"\"\"\n",
        "    # Load global target data once\n",
        "    with open(target_file, \"r\") as f:\n",
        "        target_data = json.load(f)\n",
        "\n",
        "    all_examples = []\n",
        "    missing = []\n",
        "\n",
        "    # Loop over each study folder\n",
        "    for folder in os.listdir(md_dir):\n",
        "        if not folder.endswith(\"_md\"):\n",
        "            continue\n",
        "        \n",
        "        study_id = folder.replace(\"_md\", \"\")  # e.g., \"3477_Dolci\"\n",
        "        source_file = os.path.join(md_dir, folder, f\"{folder}.json\")\n",
        "        \n",
        "        if not os.path.exists(source_file):\n",
        "            print(f\"⚠️ Missing source file for {folder}, skipping...\")\n",
        "            missing.append((study_id, \"no_json\"))\n",
        "            continue\n",
        "        \n",
        "        # Load source JSON and extract markdown\n",
        "        with open(source_file, \"r\") as f:\n",
        "            source_data = json.load(f)\n",
        "        markdown_content = source_data.get(\"marker\", {}).get(\"markdown\", \"\")\n",
        "        \n",
        "        # Get ground truth records for this study\n",
        "        one_study_records = [rec for rec in target_data if rec.get(\"filename\") == study_id]\n",
        "        \n",
        "        if not one_study_records:\n",
        "            print(f\"⚠️ No ground truth records found for {study_id}, skipping...\")\n",
        "            missing.append((study_id, \"no_records\"))\n",
        "            continue\n",
        "        \n",
        "        # Build examples for this study\n",
        "        examples = create_dspy_examples(markdown_content, one_study_records)\n",
        "        all_examples.extend(examples)\n",
        "\n",
        "    # Summary\n",
        "    total_folders = len([f for f in os.listdir(md_dir) if f.endswith(\"_md\")])\n",
        "\n",
        "    print(f\"Total folders found: {total_folders}\")\n",
        "    print(f\"Examples created: {len(all_examples)}\")\n",
        "    print(f\"Missed studies: {len(missing)}\")\n",
        "    if missing:\n",
        "        for sid, reason in missing:\n",
        "            print(f\"  - {sid} ({reason})\")\n",
        "\n",
        "    return all_examples\n",
        "\n",
        "\n",
        "# Usage\n",
        "md_dir = \"/nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds\"\n",
        "target_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/jsons/dichotomous_outcomes.json\"\n",
        "all_examples = create_examples_for_all_studies(md_dir, target_file)\n",
        "\n",
        "# Print the first example\n",
        "print(\"Raw Example object:\")\n",
        "print(all_examples[0])\n",
        "\n",
        "print(\"\\nAccessing fields:\")\n",
        "print(\"Input (markdown_content):\", all_examples[0].markdown_content[:50], \"...\")\n",
        "print(\"Expected output (extracted_records):\", all_examples[0].extracted_records[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. DSPy Optimizers Setup and Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 16 examples for training\n",
            "Using 8 examples for testing\n",
            "Starting optimization...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/16 [00:00<?, ?it/s]2025/09/17 17:45:10 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 12 outcomes for Piroxicam 20 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:14 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'markdown_content': '![](_page_0_Picture_1.jpeg)\\n\\nPatron: 3477-ADP;\\n\\nJournal Title: International journal of clinical pharmacology research ISSN: 0251-1649\\n\\nVolume: 14 Issue: 5 Month/Year: 1994Rages: 185-91\\n\\nArticle Author: Dolci G, Ripari M, Pacifici L, Umile A\\n\\n**Article Title:** Evaluation of piroxicam-betacyclodextrin, piroxicam, paracetamol and placebo in post-operative oral\\n\\nImprint:\\n\\nCall #:\\n\\nLocation:\\n\\nOdyssey\\n\\nCharge Maxcost: \\\\$15.00\\n\\n## Shipping Address:\\n\\nAmerican Dental Association Department of Library Services 211 East Chicago Avenue Chicago, IL 60611-2637\\n\\nFax: 312-440-2774 Phone: 312-440-2653 email: library@ada.org EMAIL: LIBRARY@ADA.ORG\\n\\nNOTES:\\n\\n# EVALUATION OF PIROXICAM- $\\\\beta$ -CYCLODEXTRIN, PIROXICAM, PARACETAMOL AND PLACEBO IN POST-OPERATIVE ORAL SURGERY PAIN\\n\\n### DOLCI G., RIPARI M., PACIFICI L., UMILE A.<sup>1</sup>\\n\\nOdontoiatric Clinic, \"La Sapienza\" University, Rome. 1) Medical Department, Chiesi Farmaceutici S.p.A., Parma, Italy.\\n\\n**Summary:** Two hundred ninety-eight patients with post-operative pain after the surgical removal of an impacted third molar were randomly assigned, on a double-blind basis, to receive a single oral dose of piroxicam 20 mg, or piroxicam- $\\\\beta$ -cyclodextrin equivalent to 20 mg piroxicam, or paracetamol 500 mg, or placebo. Using a semi-quantitative self-rating scale, patients rated their pain and its relief at 30-min intervals for the first 2 h, and then hourly for 4 h after treatment administration. All active medications were reported to be significantly superior to placebo. The three active drugs were comparable for the degree of analgesia up to the third hour, after which the effect of paracetamol decreased significantly as compared to piroxicam- $\\\\beta$ -cyclodextrin and piroxicam. Piroxicam- $\\\\beta$ -cyclodextrin and paracetamol were more rapid than piroxicam in inducing analgesia. The tolerability for the active drugs was comparable to that for placebo.\\n\\n### Introduction\\n\\nNonsteroidal anti-inflammatory drugs (NSAIDs) have potent analgesic and anti-inflammatory properties (1). Piroxicam is an anti-inflammatory, analgesic and antipyretic drug that is widely recognized as efficaceous (2). One of the disadvantages of piroxicam is its low water-solubility, which results in a slow absorption; plasma levels reach a peak value 2 to 4 h after oral administration (3).\\n\\nPiroxicam- $\\\\beta$ -cyclodextrin (PBCD) is the product of supermolecular microencapsulation between  $\\\\beta$ -cyclodextrin, a cyclic oligosaccharide, and piroxicam. In the solid state, the drug forming the inclusion complex is dispersed, molecule by molecule, into a carbohydrate matrix, forming a microcrystalline powder (4). The complexation of piroxicam with the carrier molecule,  $\\\\beta$ -cyclodextrin, enhances water-solubility which results in a more rapid absorption (5).\\n\\nSurgical removal of impacted third molar teeth often produces moderate to severe pain. As a result, most patients require post-operative analgesia (6). NSAIDs have been reported to reduce the incidence and severity of pain, inflammation and local swelling following dental extraction surgery (7).\\n\\nPain consequent on removal of impacted third molar teeth is one of the validated and frequently adopted pain models for the evaluation of analgesic effects of new compounds (8). This experimental model has therefore been chosen to verify the efficacy and rapidity of the analgesic effect of\\n\\nAddress for reprints: Dr Alberto Umile, Medical Department, Chiesi Farmaceutici S p.A., 26A Via Palermo, 43100 Parma, Italy\\n\\nPBCD in comparison with piroxicam itself and with paracetamol, a commonly used analgesic for this indication, and with placebo.\\n\\n### Material and methods\\n\\nThe study population was comprised of young healthy subjects (≥18 years) of both sexes. To be included, the patients must have had surgical removal of a single impacted third molar tooth resulting in acute post-surgical pain of at least moderate intensity. Patients were excluded from the study if they were pregnant, nursing or had taken any anti-inflammatory/analgesic therapy and/or psychotropic drugs during the 24 h before surgery. Individuals with a medical history of active gastrointestinal disturbances, significant liver, renal or haematological disease, non-controlled diabetes or acute infections, were excluded. Patients who had previously reacted to NSAIDs or salicylates also were excluded. Informed consent was obtained and patients were randomly assigned to one of the four following treatment groups:\\n\\n- (i) Piroxicam-β-cyclodextrin (Brexin<sup>R</sup>, Chiesi Farmaceutici, Italy: 191.2 mg tablets, equivalent to 20 mg of piroxicam;\\n- (*ii*) Piroxicam (Feldene<sup>R</sup>, Pfizer, Italy): 20 mg capsules;\\n- (*iii*) Paracetamol (Tachipirina<sup>R</sup>, Angelini, Italy): 500 mg tablets;\\n- (*iv*) Placebo: 3 presentations identical respectively to Brexin<sup>R</sup>, Feldene<sup>R</sup> and Tachipirina<sup>R</sup>.\\n\\nIn order to maintain the double-blind conditions, each patient was supplied with a bottle which contained 1 capsule and 2 tablets, one active and 2 placebo, for the active treatment groups, or 3 placebo for the placebo group. The one capsule and two tablets were concomitantly administered as a single dose with water when the patient experienced pain of at least moderate intensity.\\n\\nThe assessments were performed in the clinic for\\n\\nthe first 2 h after drug administration, after which patients completed a self-evaluation of pain at home, using a diary card, for an additional 2 h.\\n\\nPain intensity was recorded just before treatment administration and at 30 min, 1 h, 1 h 30 min, 2 h, 3 h and 4 h after. Pain relief was recorded at the same times post administration. Pain intensity was recorded as: 0 = none; 1 = mild; 2 = moderate; 3 = severe. Pain relief was recorded as: 4 =complete; 3 = a lot; 2 = some; 1 = a little; 0 =none. The overall patients\\' evaluation of the study treatment was expressed, at the end of the observation period, as: 0 = negative; 1 = poor; 2 = fair; 3 = good; 4 = very good.\\n\\nPatients were permitted to take a rescue analgesic if they received inadequate relief from the study treatment, but not before 1 h 30 min after treatment administration. No further pain assessments were made following administration of the rescue analgesic. The following parameters were used to evaluate analgesic efficacy: pain intensity difference (PID) by subtracting the pain intensity score at the assessment time from the baseline score; sum of the pain intensity difference (SPID) scores, pain relief scores (PAR); total pain relief (TOTPAR) score and overall patient\\'s evaluation.\\n\\nAdverse events were investigated by asking patients to report any unexpected experience they had after intake of the drugs.\\n\\nThe principle of \"intention-to-treat\" was used for the analysis in order to include the patients who took rescue analgesics. For these patients the values after administration of a rescue analgesic were the least favourable values for pain intensity (score = 3) and pain relief (score = 0).\\n\\nWithin-treatment comparisons for pain intensity were performed applying Friedman\\'s test and, if significant, by Nemenyi\\'s test comparing the baseline value versus the value at each assessment timepoint. One-way analysis of variance (ANOVA) was applied to PID and PAR. If differences between treatments were found to be significant. Duncan\\'s multiple comparison of means was used to identify the group that contributed to the significant difference. The sum of pain intensity difference (SPID) and total pain relief (TOTPAR) were analysed by means of the Kruskall-Wallis test and, if significant, by the Wilcoxon 2-sample test with the Bonferroni correction. The overall patient\\'s evaluation was analysed by the chi-square test.\\n\\n### Results\\n\\nEleven centres enrolled a total of 336 patients. Thirty-eight patients were excluded from the efficacy analysis: of these, 15 were lost to follow-up; 6 asked for a rescue analgesic before 1 h 30 min; 3 experienced an adverse event and did not complete the pain assessments; 14 because the baseline pain intensity was not at least moderate. Thus, a total of 298 patients (74 on PBCD, 76 on piroxicam, 72 on paracetamol and 76 on placebo) were evaluated for efficacy.\\n\\nNo significant differences were noted between treatments for the demographic data. the duration of operation (removal of III molar tooth) or the time from operation and the request for analgesia by the patient due to at least moderate pain (Table I).\\n\\nAt baseline, all treatment groups exhibited comparable pain intensity scores, the mean values ranging from 2.08 to 2.19. The pain intensity decreased steadily within each active treatment group, becoming significantly lower than baseline pain from the first hour onwards. For mean pain intensity difference (PID) scores, the drugs PBCD and paracetamol were significantly different from placebo at 30 min, while piroxicam was not significantly different from placebo (Table II and Fig. 1). From the first hour up to the fourth hour, results with all three active drug treatments were statistically different from placebo.\\n\\nAt 1 h, the drug PBCD was different from piroxicam, but not different from paracetamol. At 1.5, 2 and 3 h the active treatments were not significantly different, but at the last assessment timepoint\\n\\n| Table I  | Patient demographic data and baseline clinical |  |\\n|----------|------------------------------------------------|--|\\n| characte | istics                                         |  |\\n\\n|                                            | PBCD     | PIRX     | PRCT     | PLAC     |\\n|--------------------------------------------|----------|----------|----------|----------|\\n| Variables                                  | (n = 74) | (n = 76) | (n = 72) | (n = 76) |\\n| Age* (yr)                                  | 26.9     | 27 2     | 27 9     | 27 2     |\\n| (range)                                    | (18–41)  | (18-45)  | (18–49)  | (18–45)  |\\n| Sex                                        |          |          |          |          |\\n| M (%)                                      | 29 (39)  | 32 (42)  | 28 (39)  | 28 (37)  |\\n| F (%)                                      | 45 (61)  | 44 (58)  | 44 (61)  | 48 (63)  |\\n| Height* (cm)                               | 169.6    | 170 0    | 168 0    | 167.1    |\\n| Weight* (kg)                               | 63.2     | 64.6     | 63.2     | 62 0     |\\n| Duration of operation* (min)               | 34 8     | 33 7     | 36.3     | 33 6     |\\n| Time from operation<br>to treatment* (min) | 80.9     | 85.5     | 87 6     | 81.7     |\\n\\n\\\\* Means.\\n\\nPBCD = piroxicam-β-cyclodextrin; PIRX = piroxicam; PRC1 = paracetamol; PLAC = placebo.\\n\\n(4 hours) PBCD and piroxicam were different from paracetamol.\\n\\nPain relief (PAR) results showed the same pattern as was observed with the PID results; the drug PBCD was significantly different from piroxicam at 30 min and at 1 h, while paracetamol was significantly different from piroxicam at 30 min but not at 1 h (Table III). At 1.5 and 2 h the active drugs were not significantly different. At later timepoints, PBCD and piroxicam continued to provide analgesia whereas paracetamol gradually lost efficacy until it was statistically different from, less effective than, PBCD at 3 and 4 h, and than piroxicam at 4 h.\\n\\nExcept for the first assessment at 30 min, when piroxicam was not different from placebo, the three active drugs were statistically different from placebo at all timepoints. The sum of the pain intensity differences (SPID) results were also significantly different for all active drugs as compared to placebo,\\n\\n![](_page_4_Figure_1.jpeg)\\n\\nFig. 1 Mean scores of pain intensity difference (PID) PBCD = piroxicam-β-cyclodextrin; PIRX = piroxicam; PRCT = paracetamol; PLAC = placebo\\n\\n| Treatment |         |         | Ho     | ٦r     |        |        |\\n|-----------|---------|---------|--------|--------|--------|--------|\\n|           | 0.5     | 10      | 1.5    | 20     | 3.0    | 4 0    |\\n| PBCD      | 0.54 A  | 0 94 A  | 1.07 A | 1 14 A | 1.22 A | 1 23 A |\\n| PIRX      | 0 37 AB | 0.67 BC | 0.88 A | 1 12 A | 1.20 A | 1.28 A |\\n| PRCT      | 0 56 A  | 0.77 AC | 0.96 A | 0 93 A | 1.01 A | 0 92 B |\\n| PLAC      | 0.31 B  | 0.41 D  | 0 40 B | 0.40 B | 0.41 B | 0 49 C |\\n| p-value   | 0.01    | 0.001   | 0 001  | 0.001  | 0 001  | 0.001  |\\n\\nTable II Mean PID (pain intensity difference) scores and Duncan\\'s comparison\\\\*\\n\\n\\\\* To be read vertically: the same letter indicates absence of significant difference (p > 0.05)\\n\\nwhile there was no significant difference between the three active treatment groups. The same results were obtained with the total pain relief (TOTPAR) score (Table IV). The numbers of patients requesting a rescue analgesic at each timepoint for each treatment group were: 12 (16.2%) with PBCD, 8 (10.5%) with piroxicam, 15 (20.0%) with paracetamol, and 46\\n\\n| Treatment |        |         | H      | our    |         |        |\\n|-----------|--------|---------|--------|--------|---------|--------|\\n|           | 0.5    | 1.0     | 1.5    | 2.0    | 3.0     | 4 0    |\\n| PBCD      | 1 51 A | 2.01 A  | 2.22 A | 2.21 A | 2.34 A  | 2 34 A |\\n| PIRX      | 0.81 B | 1 58 B  | 1.93 A | 2.14 A | 2.25 AB | 2 42 A |\\n| PRCT      | 1.26 A | 1.78 AB | 1.96 A | 1.89 A | 1.83 B  | 1.75 B |\\n| PLAC      | 0.72 B | 0.96 C  | 0.95 B | 0.85 B | 0.91 C  | 0.97 C |\\n| p-value   | 0.001  | 0 001   | 0.001  | 0.001  | 0.001   | 0.001  |\\n\\nTable III Mean PAR (pain relief) scores and Duncan\\'s comparison\\\\*\\n\\n\\\\* To be read vertically: the same letter indicates absence of significant difference (p > 0.05).\\n\\n# Table IV Mean SPID scores and TOTPAR at 4 h and Wilcoxon 2-sample test comparisons\\\\*\\n\\n| Treatment | Mean SPID<br>4h | Mean TOTPAR<br>4h |\\n|-----------|-----------------|-------------------|\\n| PBCD      | 5.64 A          | 12.64 A           |\\n| PIRX      | 5.07 A          | 11.14 A           |\\n| PRCT      | 4.42 A          | 10 47 A           |\\n| PLAC      | 0 53 B          | 5 41 B            |\\n| p-value   | 0 0001          | 0.0001            |\\n\\n\\\\* To be read vertically: the same letter indicates absence of significant difference (p > 0.05).\\n\\n(58.2%) with placebo. The patient\\'s evaluation of treatment is reported in Table V; the active treatments were significantly different from placebo, favouring the active treatments. In the between-treatment comparison, PBCD was different from paracetamol (p < 0.05), while piroxicam vs paracetamol, and PBCD vs piroxicam, were not significantly different.\\n\\nAdverse events reported by the patients are summarized in Table VI. Four patients dropped out from the study because of adverse events: 2 with paracetamol (one for nausea and one for local swelling), one with PBCD (headache and nausea) and one with placebo (fever, nausea, and diarrhoea).\\n\\n### Discussion\\n\\nPiroxicam- $\\\\beta$ -cyclodextrin (PBCD) is a new NSAID compound which is the result of the microencapsulation of piroxicam, a well-established NSAID, with  $\\\\beta$ -cyclodextrin, a cyclic oligosaccharide which acts as an inert carrier. The complex dissociates in the gastrointestinal tract, releasing piroxicam, which can be absorbed more readily, and  $\\\\beta$ -cyclodextrin, which is metabolized into glucose monomers that enter the sugar metabolic pathway (9). Since piroxicam is absorbed more rapidly when complexed with  $\\\\beta$ -cyclodextrin, its peak plasma levels are reached within 1 h (median), compared to 2 or more hours for the standard piroxicam (4), with a potential clinical advantage of an earlier onset of therapeutic effect (10).\\n\\nThe main objective of our trial was to find out if a more rapid absorption of the active agent was associated with any therapeutic advantage. The sensitivity of this study was high, because the three active treatments were significantly different from placebo with respect to each of the efficacy parameters. A significant decrease of pain intensity with PBCD, piroxicam, and paracetamol was obtained 1 h after treatment administration and until the last assessment timepoint at 4 h.\\n\\nThe between-treatment comparisons for pain intensity difference and pain relief showed that\\n\\n| Table V | Overall patient\\'s evaluation of treatment |  |\\n|---------|-------------------------------------------|--|\\n|---------|-------------------------------------------|--|\\n\\n|      | Negative<br>n (%) | Poor<br>n (%) | Fair<br>n (%) | Good<br>n (%) | Very good<br>n (%) |\\n|------|-------------------|---------------|---------------|---------------|--------------------|\\n| PBCD | 3 (4 1)           | 12 (16 2)     | 22 (29 7)     | 18 (24.3)     | 19 (25 7)          |\\n| PIRX | 4 (5 3)           | 16 (21 3)     | 19 (25.3)     | 24 (32 0)     | 12 (16 0)          |\\n| PCRX | 3 (4.2)           | 25 (34 7)     | 17 (23 6)     | 22 (30 6)     | 5 (6 9)            |\\n| PLAC | 34 (44 7)         | 14 (18.4)     | 14 (18.4)     | 7 (9 2)       | 7 (9 2)            |\\n\\nTable VI Summary of adverse events (AEs) reported\\n\\n| Adverse events           | PBCD<br>(n = 79) | PIRX<br>(n = 80) | PRCT<br>(n = 80) | PLAC<br>(n = 82) | TOT<br>(n ≈ 321) |\\n|--------------------------|------------------|------------------|------------------|------------------|------------------|\\n| Cold sensation           | 1                |                  |                  | 1                | 2                |\\n| Fever                    | _                |                  | 1                | 1                | 2                |\\n| Gingival bleeding        | _                |                  | 1                | -                | 1                |\\n| Headache                 | 2                | -                | 1                | 2                | 5                |\\n| Local swelling           | 1                |                  | 1                | 1                | 3                |\\n| Diarrhoea                | _                | -                | 1                | 1                | 2                |\\n| Difficulty in swallowing | 1                | _                | -                | ·                | 1                |\\n| Nausea                   | 1                | 1                | 1                | 3                | 6                |\\n| Salivation               | -                | _                | _                | 1                | 1                |\\n| Stomach ache             | 1                | 3                | 1                | 2                | 7                |\\n| Vomiting                 | 1                | -                | -                |                  | 1                |\\n| No of patients with AEs  | 7                | 4                | 7                | 8                | 26               |\\n| No. of AEs               | 8                | 4                | 7                | 12               | 31               |\\n\\nPBCD and paracetamol were more rapid than piroxicam in producing pain relief, within 1 h after administration, while the two piroxicam formulations were comparable in efficacy from 1.5 h up to the 4th and last hour. The comparison between PBCD and paracetamol, the latter of which has only analgesic and no anti-inflammatory action, demonstrated that, while the two drugs were not significantly different at the early timepoints, the pain relief obtained with PBCD continued to increase progressively whereas paracetamol reached the maximum at 1.5 h and remained constant with a slight decrease toward the end of the assessment time period. Both PBCD and piroxicam were significantly different from paracetamol at the 4-h assessment. A possible explanation could be that, paracetamol, being a pure analgesic without any anti-inflammatory action. cannot resolve the local inflammation and oedema which contribute to the painful state following dental extraction. The NSAIDs instead, by blocking prostaglandin synthesis, have an effect on both the prostaglandin-mediated inflammation and oedema, and the hypersensitivity of nociceptor nerves which are also stimulated by prostaglandins (11).\\n\\nThere was a difference between PBCD and piroxicam with respect to the patient request frequency for rescue analgesia, but it is considered casual and of no clinical importance.\\n\\nThe tolerability of the three active drugs was good and the incidence of adverse events for each of them was not different from that of placebo.\\n\\nIn conclusion, the study demonstrated a faster onset of pain relief with PBCD as compared to piroxicam. The three active drugs were comparable for the degree of analgesia up to the third hour, after which the effect of paracetamol decreased significantly in comparison to PBCD and piroxicam.\\n\\n### Acknowledgements\\n\\nThe authors thank Ms. Angela Raineri for her secretarial support.\\n\\n#### List of study centres and investigators\\n\\n(1) Prof A BELTRAME, Prof. G FERRONATO and Dr G.L. BORGO, Maxillofacial Surgery Ward, Castelfranco Veneto Hospital, Castelfranco Veneto, Treviso\\n\\n(2) Prof. E. BERTELLI and Dr. A CAPUANO, Institute of Odontology and Stomatology, \"Le Scotte\" Hospital, Siena.\\n\\n(3) Prof G BOREA, Prof. P CAPUZZI and Dr. L. MONTEBUGNOLI, Odontology Clinic University of Bologna, Bologna\\n\\n(4) Dr G DAL SASSO and Dr A. AMICARELLI, Odontology and Stomatology and Maxiliofacial Surgery Ward, Atri Hospital, Atri -- Teramo.\\n\\n(5) Prof P GOTTE and Dr U CONSOLO, Odontology Institute, University of Verona, \"Borgo Roma\" Hospital, Verona\\n\\n(6) Prof P.E. MANGIANTE, Dr. C. EFTIMIADI and Dr. S. VALENTE, Chair of Odontology and Stomatology Surgery, \"S. Martino\\' Hospital, Genoa\\n\\n(7) Prof. R. MODICA and Dr. R. ROMAGNOLI, Odontology and\\n\\nStomatology Clinic, University of Turin \"Molinette\" Hospital, Turin\\n\\n(8) Prof P PIERLEONI and Dr. P TONELLI, Institute of Odontology and Stomatology, University of Florence, \"Careggi\" Hospital, Florence\\n\\n(9) Prof M QUARANTA and Prof A PIATTELLI, Odontology Clinic, Faculty of Medicine, University of Chieti, Chieti\\n\\n(10) Prof M RIPARI and Dr. L PACIFICI, Odontoiatric Clinic, \"La Sapienza\\' University, Rome.\\n\\n(11) Prof P SAPELLI and Dr. N BATTISTI Odontology Clinic, Brescia Hospital, Brescia\\n\\n### References\\n\\n(1) Dahl J.B., Kehlet H. Non-steroidal anti-inflammatory drugs rationale for use in severe postoperative pain. Br. J. Anaesth., **66**, 703, 1992.\\n\\n(2) Brodgen R.N. et al. Piroxicam a reappraisal of its pharmacology and therapeutic efficacy. Drugs, 28, 292, 1984\\n\\n(3) Wiseman E.H., Hobbs D.C. Review of pharmacokinetic studies with piroxicam, Am J. Med., **72** (Suppl. 2A), 9, 1982\\n\\n(4) Woodcock B G et al Supermolecular inclusion of piroxicam with β-cyclodextrin, pharmacokinetic profile in man Eur J. Rheum, Inflam., 12, 12, 1993.\\n\\n(5) Acerbi D Pharmacokinetic profile of piroxicam-β-cyclodextrin Drug Invest, **2** (Suppl. 4), 42, 1990.\\n\\n(6) Desjardins PJ Analgesic efficacy of piroxicam in postoperative dental pain Am. J Med., **84** (Suppl 5A), 35, 1988\\n\\n(7) Squires D J P., Masson E L. A double-blind comparison of ibuprofen, ASA-codeine-caffeine compound and placebo in the treatment of dental surgery pain J. Int. Med. Res., **9**, 257, 1981\\n\\n(8) Lokken P. et al Bilateral surgical removal of impacted lower third molar teeth as a model for drug evaluation, a test for ibuprofen Eur. J Clin Pharmacol , **8**, 209, 1975.\\n\\n(9) Szejtli J Cyclodextrins: properties and applications Drug Invest., **2** (Suppl 4), 11, 1990.\\n\\n(10) Tiengo M. Review of the analgesic effects of piroxicam-βcyclodextrin. Drug Invest, **2** (Suppl. 4), 61, 1990\\n\\n(11) Beaver WT Impact of non-narcotic oral analgesics on pain management Am J Med , 84 (Supp 5A), 3, 1988.', 'First_Author': 'Dolci', 'Population': 2, 'Intervention_Code': 8, 'Intervention_Description': 'Paracetamol 500 mg ', 'Outcome_Type': 2, 'Outcome_Other_Specify': '', 'Follow_Up_Time': '4 hours', 'N_Analyzed': 72, 'Adverse_Effect_Specify': '', 'Adverse_Effects_All_Study': '', 'N_Events_Number': 15, 'N_Events_Percentage': 20, 'Comments': 'single dose'}) (input_keys={'markdown_content'}) with <function medical_extraction_metric at 0x7f9a2185afc0> due to 'async_pipeline.metadata_extractor.extract_metadata.predict'.\n",
            "  6%|▋         | 1/16 [00:03<00:54,  3.66s/it]2025/09/17 17:45:14 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 12 outcomes for Piroxicam 20 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▎        | 2/16 [00:07<00:50,  3.63s/it]2025/09/17 17:45:18 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 14 outcomes for Paracetamol 500 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 3/16 [00:10<00:46,  3.60s/it]2025/09/17 17:45:21 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 14 outcomes for Paracetamol 500 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 4/16 [00:14<00:43,  3.64s/it]2025/09/17 17:45:25 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 14 outcomes for Paracetamol 500 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 5/16 [00:18<00:39,  3.63s/it]\n",
            "2025/09/17 17:45:29 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:29 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
            "Optimization completed successfully!\n",
            "\n",
            "Testing on 8 examples...\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 18 outcomes for Placebo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:32 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:32 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 1: Score = 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:36 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:36 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 2: Score = 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 14 outcomes for Paracetamol 500 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:39 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:39 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 3: Score = 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 18 outcomes for Placebo\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:43 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:43 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 4: Score = 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:46 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:47 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 5: Score = 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 18 outcomes for Placebo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:50 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 6: Score = 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:50 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 18 outcomes for Placebo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:54 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:54 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 7: Score = 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Found 14 outcomes for Paracetamol 500 mg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 17:45:57 WARNING dspy.primitives.module: Calling module.forward(...) on SyncPipelineWrapper directly is discouraged. Please use module(...) instead.\n",
            "2025/09/17 17:45:57 WARNING dspy.primitives.module: Calling module.forward(...) on AsyncMedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records extracted: 54\n",
            "Test 8: Score = 1.00\n",
            "\n",
            "Average test score: 1.00\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Dolci', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Processing intervention: Piroxicam 20 mg\n",
            "Processing intervention: Paracetamol 500 mg\n",
            "Processing intervention: Placebo\n",
            "Found 14 outcomes for Paracetamol 500 mg\n",
            "Found 12 outcomes for Piroxicam 20 mg\n",
            "Found 18 outcomes for Placebo\n",
            "Found 10 outcomes for Piroxicam-β-cyclodextrin equivalent to 20 mg of piroxicam\n",
            "Total records extracted: 54\n",
            "Extracted 54 records\n"
          ]
        }
      ],
      "source": [
        "# # Use with DSPy optimizer\n",
        "# optimizer = BootstrapFewShot(metric=medical_extraction_metric)\n",
        "\n",
        "\n",
        "# 3. Run the optimization\n",
        "def run_optimization(examples, test_size=0.3):\n",
        "    \"\"\"\n",
        "    Run the complete optimization process.\n",
        "    \n",
        "    Args:\n",
        "        examples: List of dspy.Example objects from your create_dspy_examples()\n",
        "        test_size: Fraction to use for testing (rest used for training)\n",
        "    \n",
        "    Returns:\n",
        "        compiled_pipeline: Optimized pipeline\n",
        "    \"\"\"\n",
        "    \n",
        "    # Split examples into train/test\n",
        "    split_idx = int(len(examples) * (1 - test_size))\n",
        "    trainset = examples[:split_idx]\n",
        "    testset = examples[split_idx:]\n",
        "    \n",
        "    print(f\"Using {len(trainset)} examples for training\")\n",
        "    print(f\"Using {len(testset)} examples for testing\")\n",
        "    \n",
        "    if len(trainset) == 0:\n",
        "        print(\"Warning: No training examples! Using all examples for training.\")\n",
        "        trainset = examples\n",
        "        testset = examples[:1]  # Use first example for testing\n",
        "    \n",
        "    # Create optimizer and pipeline\n",
        "    optimizer = create_optimizer()\n",
        "    sync_pipeline = SyncPipelineWrapper()\n",
        "    \n",
        "    print(\"Starting optimization...\")\n",
        "    \n",
        "    try:\n",
        "        # This is where the magic happens\n",
        "        compiled_pipeline = optimizer.compile(\n",
        "            sync_pipeline,\n",
        "            trainset=trainset\n",
        "        )\n",
        "        compiled_pipeline.save(\"dspy_optimized_pipeline.json\")\n",
        "\n",
        "        \n",
        "        print(\"Optimization completed successfully!\")\n",
        "        \n",
        "        # Test the compiled pipeline on test set\n",
        "        if testset:\n",
        "            print(f\"\\nTesting on {len(testset)} examples...\")\n",
        "            total_score = 0\n",
        "            \n",
        "            for i, example in enumerate(testset):\n",
        "                try:\n",
        "                    result = compiled_pipeline.forward(example.markdown_content)\n",
        "                    score = medical_extraction_metric(example, result)\n",
        "                    total_score += score\n",
        "                    print(f\"Test {i+1}: Score = {score:.2f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Test {i+1}: Error = {e}\")\n",
        "            \n",
        "            avg_score = total_score / len(testset)\n",
        "            print(f\"\\nAverage test score: {avg_score:.2f}\")\n",
        "        \n",
        "        return compiled_pipeline\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Optimization failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# 4. Quick runner function\n",
        "def quick_optimize(examples):\n",
        "    \"\"\"Simple one-line optimization.\"\"\"\n",
        "    return run_optimization(examples)\n",
        "\n",
        "\n",
        "\n",
        "# Now run optimization:\n",
        "compiled_pipeline = quick_optimize(examples)\n",
        "\n",
        "# Use the optimized pipeline:\n",
        "if compiled_pipeline:\n",
        "    result = compiled_pipeline(markdown_content)\n",
        "    print(f\"Extracted {len(result.extracted_records)} records\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Batch processing wrapper for efficient concurrent execution\n",
        "# class AsyncBatchProcessor:\n",
        "#     \"\"\"Handles batch processing of multiple operations with concurrency control.\"\"\"\n",
        "    \n",
        "#     def __init__(self, max_concurrent: int = 5):\n",
        "#         self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "    \n",
        "#     async def process_interventions_batch(self, intervention_extractor: AsyncInterventionExtractor, \n",
        "#                                         markdown_contents: List[str]) -> List[List[Dict[str, Any]]]:\n",
        "#         \"\"\"Process multiple markdown contents concurrently for interventions.\"\"\"\n",
        "        \n",
        "#         async def _extract_with_semaphore(content: str):\n",
        "#             async with self.semaphore:\n",
        "#                 return await intervention_extractor.forward(content)\n",
        "        \n",
        "#         tasks = [_extract_with_semaphore(content) for content in markdown_contents]\n",
        "#         return await asyncio.gather(*tasks)\n",
        "    \n",
        "#     async def process_outcomes_batch(self, outcome_extractor: AsyncOutcomeExtractor,\n",
        "#                                    markdown_content: str, \n",
        "#                                    intervention_descriptions: List[str]) -> List[List[Dict[str, Any]]]:\n",
        "#         \"\"\"Process multiple interventions concurrently for outcomes.\"\"\"\n",
        "        \n",
        "#         async def _extract_with_semaphore(intervention_desc: str):\n",
        "#             async with self.semaphore:\n",
        "#                 return await outcome_extractor.forward(markdown_content, intervention_desc)\n",
        "        \n",
        "#         tasks = [_extract_with_semaphore(desc) for desc in intervention_descriptions]\n",
        "#         return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "\n",
        "# class AsyncBatchPipeline:\n",
        "#     \"\"\"Batch processor for handling multiple files concurrently.\"\"\"\n",
        "    \n",
        "#     def __init__(self, max_concurrent_files: int = 3, max_concurrent_per_file: int = 5):\n",
        "#         self.file_semaphore = asyncio.Semaphore(max_concurrent_files)\n",
        "#         self.max_concurrent_per_file = max_concurrent_per_file\n",
        "    \n",
        "#     async def process_single_file(self, file_path: str, markdown_content: str, \n",
        "#                                 output_dir: str = None, override: bool = False):\n",
        "#         \"\"\"Process a single file with semaphore control.\"\"\"\n",
        "#         async with self.file_semaphore:\n",
        "#             pipeline = AsyncMedicalDataExtractionPipeline(self.max_concurrent_per_file)\n",
        "#             print(f\"Processing file: {Path(file_path).name}\")\n",
        "#             return await pipeline.run_and_save(markdown_content, file_path, output_dir, override)\n",
        "    \n",
        "#     async def process_files_batch(self, file_data: List[Dict], output_dir: str = None, \n",
        "#                                 override: bool = False):\n",
        "#         \"\"\"Process multiple files concurrently.\n",
        "        \n",
        "#         Args:\n",
        "#             file_data: List of dicts with 'file_path' and 'markdown_content' keys\n",
        "#             output_dir: Output directory for results\n",
        "#             override: Whether to overwrite existing files\n",
        "#         \"\"\"\n",
        "#         print(f\"Starting batch processing of {len(file_data)} files...\")\n",
        "        \n",
        "#         tasks = [\n",
        "#             self.process_single_file(\n",
        "#                 item['file_path'], \n",
        "#                 item['markdown_content'], \n",
        "#                 output_dir, \n",
        "#                 override\n",
        "#             ) \n",
        "#             for item in file_data\n",
        "#         ]\n",
        "        \n",
        "#         results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "        \n",
        "#         # Count successful vs failed\n",
        "#         successful = sum(1 for r in results if not isinstance(r, Exception))\n",
        "#         failed = len(results) - successful\n",
        "        \n",
        "#         print(f\"Batch processing complete: {successful} successful, {failed} failed\")\n",
        "#         return results\n",
        "\n",
        "    \n",
        "# class AsyncBatchEvaluator:\n",
        "#     \"\"\"Batch evaluator for processing multiple files concurrently.\"\"\"\n",
        "    \n",
        "#     def __init__(self, max_concurrent_files: int = 3, max_concurrent_per_file: int = 10):\n",
        "#         self.file_semaphore = asyncio.Semaphore(max_concurrent_files)\n",
        "#         self.evaluator = AsyncMedicalExtractionEvaluator(max_concurrent=max_concurrent_per_file)\n",
        "    \n",
        "#     async def evaluate_single_file(self, extracted_records: List[Dict], ground_truth: List[Dict], \n",
        "#                                  source_file: str, save_csv: bool = True, csv_dir: str = \"evaluation_results\"):\n",
        "#         \"\"\"Evaluate a single file with semaphore control.\"\"\"\n",
        "#         async with self.file_semaphore:\n",
        "#             print(f\"Evaluating file: {source_file}\")\n",
        "            \n",
        "#             results = await self.evaluator.evaluate(extracted_records, ground_truth)\n",
        "            \n",
        "#             if save_csv:\n",
        "#                 await self.evaluator.save_evaluation_to_csv(\n",
        "#                     extracted_records, ground_truth, source_file, csv_dir\n",
        "#                 )\n",
        "            \n",
        "#             return {\n",
        "#                 'source_file': source_file,\n",
        "#                 'results': results\n",
        "#             }\n",
        "    \n",
        "#     async def evaluate_files_batch(self, file_data: List[Dict], save_csv: bool = True, \n",
        "#                                  csv_dir: str = \"evaluation_results\"):\n",
        "#         \"\"\"Evaluate multiple files concurrently.\n",
        "        \n",
        "#         Args:\n",
        "#             file_data: List of dicts with 'extracted_records', 'ground_truth', 'source_file' keys\n",
        "#         \"\"\"\n",
        "#         print(f\"Starting batch evaluation of {len(file_data)} files...\")\n",
        "        \n",
        "#         tasks = [\n",
        "#             self.evaluate_single_file(\n",
        "#                 item['extracted_records'],\n",
        "#                 item['ground_truth'], \n",
        "#                 item['source_file'],\n",
        "#                 save_csv,\n",
        "#                 csv_dir\n",
        "#             )\n",
        "#             for item in file_data\n",
        "#         ]\n",
        "        \n",
        "#         results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "        \n",
        "#         successful = sum(1 for r in results if not isinstance(r, Exception))\n",
        "#         failed = len(results) - successful\n",
        "        \n",
        "#         print(f\"Batch evaluation complete: {successful} successful, {failed} failed\")\n",
        "#         return results\n",
        "\n",
        "# print(\"Async medical extraction evaluator defined successfully\")\n",
        "\n",
        "\n",
        "# Batch processing function\n",
        "# async def run_batch_extraction_and_evaluation(file_data: List[Dict], \n",
        "#                                              max_concurrent_files: int = 3,\n",
        "#                                              override: bool = False):\n",
        "#     \"\"\"Run batch processing for multiple files.\n",
        "    \n",
        "#     Args:\n",
        "#         file_data: List of dicts with 'markdown_content', 'source_file', 'ground_truth' keys\n",
        "#         max_concurrent_files: Number of files to process simultaneously\n",
        "#         override: Whether to overwrite existing files\n",
        "#     \"\"\"\n",
        "    \n",
        "#     print(f\"Starting async batch processing of {len(file_data)} files...\")\n",
        "#     print(\"=\" * 70)\n",
        "    \n",
        "#     # Initialize batch processors\n",
        "#     batch_pipeline = AsyncBatchPipeline(max_concurrent_files, max_concurrent_per_file=5)\n",
        "#     batch_evaluator = AsyncBatchEvaluator(max_concurrent_files, max_concurrent_per_file=10)\n",
        "    \n",
        "#     start_time = datetime.now()\n",
        "    \n",
        "#     try:\n",
        "#         # Prepare pipeline data\n",
        "#         pipeline_data = [\n",
        "#             {\n",
        "#                 'file_path': item['source_file'],\n",
        "#                 'markdown_content': item['markdown_content']\n",
        "#             }\n",
        "#             for item in file_data\n",
        "#         ]\n",
        "        \n",
        "#         # Prepare evaluation data  \n",
        "#         evaluation_data = [\n",
        "#             {\n",
        "#                 'extracted_records': [],  # Will be filled after extraction\n",
        "#                 'ground_truth': item['ground_truth'],\n",
        "#                 'source_file': item['source_file']\n",
        "#             }\n",
        "#             for item in file_data\n",
        "#         ]\n",
        "        \n",
        "#         # Run extractions first\n",
        "#         print(\"Phase 1: Running extractions...\")\n",
        "#         extraction_results = await batch_pipeline.process_files_batch(\n",
        "#             pipeline_data, output_dir=\"extraction_results\", override=override\n",
        "#         )\n",
        "        \n",
        "#         # Load extracted results for evaluation\n",
        "#         for i, result in enumerate(extraction_results):\n",
        "#             if not isinstance(result, Exception) and result:\n",
        "#                 # Load the extracted records from the result\n",
        "#                 if hasattr(result, 'extracted_records'):\n",
        "#                     evaluation_data[i]['extracted_records'] = result.extracted_records\n",
        "        \n",
        "#         # Run evaluations\n",
        "#         print(\"\\nPhase 2: Running evaluations...\")\n",
        "#         evaluation_results = await batch_evaluator.evaluate_files_batch(\n",
        "#             evaluation_data, save_csv=True, csv_dir=\"evaluation_results\"\n",
        "#         )\n",
        "        \n",
        "#         end_time = datetime.now()\n",
        "#         processing_time = (end_time - start_time).total_seconds()\n",
        "        \n",
        "#         # Summary\n",
        "#         successful_extractions = sum(1 for r in extraction_results if not isinstance(r, Exception))\n",
        "#         successful_evaluations = sum(1 for r in evaluation_results if not isinstance(r, Exception))\n",
        "        \n",
        "#         print(\"\\n\" + \"=\" * 70)\n",
        "#         print(\"BATCH PROCESSING SUMMARY\")\n",
        "#         print(\"=\" * 70)\n",
        "#         print(f\"Total files: {len(file_data)}\")\n",
        "#         print(f\"Successful extractions: {successful_extractions}\")\n",
        "#         print(f\"Successful evaluations: {successful_evaluations}\")\n",
        "#         print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
        "#         print(f\"Average time per file: {processing_time/len(file_data):.2f} seconds\")\n",
        "        \n",
        "#         return {\n",
        "#             'extraction_results': extraction_results,\n",
        "#             'evaluation_results': evaluation_results,\n",
        "#             'summary': {\n",
        "#                 'total_files': len(file_data),\n",
        "#                 'successful_extractions': successful_extractions,\n",
        "#                 'successful_evaluations': successful_evaluations,\n",
        "#                 'processing_time': processing_time\n",
        "#             }\n",
        "#         }\n",
        "        \n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in batch processing: {e}\")\n",
        "#         traceback.print_exc()\n",
        "#         return None\n",
        "\n",
        "\n",
        "\n",
        "# # Usage example for batch processing:\n",
        "# \"\"\"\n",
        "# batch_data = [\n",
        "#     {\n",
        "#         'markdown_content': content1,\n",
        "#         'source_file': 'study1.json',\n",
        "#         'ground_truth': gt_records1\n",
        "#     },\n",
        "#     {\n",
        "#         'markdown_content': content2, \n",
        "#         'source_file': 'study2.json',\n",
        "#         'ground_truth': gt_records2\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# batch_results = await run_batch_extraction_and_evaluation(\n",
        "#     batch_data, max_concurrent_files=3, override=False\n",
        "# )\n",
        "# \"\"\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "topics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
