{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSPy 3.0.3 Medical Data Extraction Pipeline\n",
        "\n",
        "This notebook demonstrates a comprehensive data extraction pipeline using DSPy 3.0.3 to extract structured dichotomous outcomes from medical research papers in markdown format.\n",
        "\n",
        "## Objective\n",
        "Extract structured data from medical research markdown  into the target format matching `dichotomous_outcomes.json`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy version: 3.0.3\n"
          ]
        }
      ],
      "source": [
        "import dspy\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "import aiofiles\n",
        "import traceback\n",
        "\n",
        "import tiktoken\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "import hashlib\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import diskcache as dc\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Print DSPy version\n",
        "print(f\"DSPy version: {dspy.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure DSPy Language Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language model configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Set your API key (uncomment and add your key)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "\n",
        "# Configure DSPy with OpenAI GPT-4o-mini for cost efficiency\n",
        "lm = dspy.LM('gemini/gemini-2.5-pro', max_tokens=20000, temperature=1.0)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"Language model configured successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New log file will be created: dspy_history.csv\n",
            "DSPy History Logger for Notebooks Ready!\n",
            "Usage:\n",
            "  set_log_file('my_file.csv')  # Set custom log file\n",
            "  log_history()                # Log current DSPy history\n",
            "  show_stats()                 # Show summary statistics\n",
            "  view_recent(5)               # View recent 5 calls\n",
            "  clear_cache()                # Clear processed cache\n",
            "  export_full_history()        # Export complete history to JSON\n",
            "Loaded 945 existing records from /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\n"
          ]
        }
      ],
      "source": [
        "# Global variables to track processed calls\n",
        "_processed_hashes = set()\n",
        "_csv_path = \"dspy_history.csv\"\n",
        "\n",
        "def set_log_file(csv_path: str):\n",
        "    \"\"\"Set the CSV file path for logging.\"\"\"\n",
        "    global _csv_path, _processed_hashes\n",
        "    _csv_path = csv_path\n",
        "    \n",
        "    # Load existing hashes from CSV if it exists\n",
        "    if Path(csv_path).exists():\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if 'call_hash' in df.columns:\n",
        "                _processed_hashes = set(df['call_hash'].tolist())\n",
        "                print(f\"Loaded {len(_processed_hashes)} existing records from {csv_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load existing CSV: {e}\")\n",
        "    else:\n",
        "        print(f\"New log file will be created: {csv_path}\")\n",
        "\n",
        "def log_history():\n",
        "    \"\"\"Log current DSPy history to CSV. Call this after running DSPy operations.\"\"\"\n",
        "    global _processed_hashes, _csv_path\n",
        "    \n",
        "    # Get LM from dspy settings\n",
        "    try:\n",
        "        lm = dspy.settings.lm\n",
        "    except:\n",
        "        print(\"Error: No LM found in dspy.settings\")\n",
        "        return 0\n",
        "    \n",
        "    if not hasattr(lm, 'history') or not lm.history:\n",
        "        print(\"No history found in language model\")\n",
        "        return 0\n",
        "    \n",
        "    new_records = []\n",
        "    \n",
        "    for call_data in lm.history:\n",
        "        # Generate unique hash\n",
        "        hash_content = {\n",
        "            'messages': call_data.get('messages', []),\n",
        "            'timestamp': call_data.get('timestamp', ''),\n",
        "            'uuid': call_data.get('uuid', ''),\n",
        "        }\n",
        "        call_hash = hashlib.md5(json.dumps(hash_content, sort_keys=True, default=str).encode()).hexdigest()\n",
        "        \n",
        "        # Skip if already processed\n",
        "        if call_hash in _processed_hashes:\n",
        "            continue\n",
        "        \n",
        "        # Extract call info\n",
        "        messages = call_data.get('messages', [])\n",
        "        system_msg = next((m.get('content', '') for m in messages if m.get('role') == 'system'), '')\n",
        "        user_msg = next((m.get('content', '') for m in messages if m.get('role') == 'user'), '')\n",
        "        \n",
        "        # Extract response\n",
        "        response_obj = call_data.get('response', {})\n",
        "        assistant_response = \"\"\n",
        "        if hasattr(response_obj, 'choices') and response_obj.choices:\n",
        "            assistant_response = response_obj.choices[0].message.content\n",
        "        \n",
        "        # Extract usage\n",
        "        usage = call_data.get('usage', {})\n",
        "        if isinstance(usage, dict):\n",
        "            prompt_tokens = usage.get('prompt_tokens', 0)\n",
        "            completion_tokens = usage.get('completion_tokens', 0) \n",
        "            total_tokens = usage.get('total_tokens', 0)\n",
        "        else:\n",
        "            prompt_tokens = completion_tokens = total_tokens = 0\n",
        "        \n",
        "        record = {\n",
        "            'call_hash': call_hash,\n",
        "            'timestamp': call_data.get('timestamp', datetime.now().isoformat()),\n",
        "            'uuid': call_data.get('uuid', ''),\n",
        "            'model': call_data.get('model', ''),\n",
        "            'cost': call_data.get('cost', 0.0),\n",
        "            'prompt_tokens': prompt_tokens,\n",
        "            'completion_tokens': completion_tokens,\n",
        "            'total_tokens': total_tokens,\n",
        "            'system_msg_length': len(system_msg),\n",
        "            'user_msg_preview': user_msg[:200] if user_msg else '',\n",
        "            'response_preview': assistant_response[:200] if assistant_response else '',\n",
        "            'cache_hit': getattr(response_obj, 'cache_hit', False) if response_obj else False,\n",
        "            'logged_at': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        new_records.append(record)\n",
        "        _processed_hashes.add(call_hash)\n",
        "    \n",
        "    if not new_records:\n",
        "        print(\"No new records to add\")\n",
        "        return 0\n",
        "    \n",
        "    # Save to CSV\n",
        "    new_df = pd.DataFrame(new_records)\n",
        "    \n",
        "    if Path(_csv_path).exists():\n",
        "        new_df.to_csv(_csv_path, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        Path(_csv_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "        new_df.to_csv(_csv_path, index=False)\n",
        "    \n",
        "    print(f\"Added {len(new_records)} new records to {_csv_path}\")\n",
        "    return len(new_records)\n",
        "\n",
        "def show_stats():\n",
        "    \"\"\"Show statistics from the logged history.\"\"\"\n",
        "    global _csv_path\n",
        "    \n",
        "    if not Path(_csv_path).exists():\n",
        "        print(\"No history file found\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(_csv_path)\n",
        "        \n",
        "        print(f\"\\nDSPy History Stats from {_csv_path}:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Total calls: {len(df)}\")\n",
        "        \n",
        "        if 'model' in df.columns:\n",
        "            print(f\"Unique models: {df['model'].nunique()}\")\n",
        "            print(\"Model breakdown:\")\n",
        "            for model, count in df['model'].value_counts().head().items():\n",
        "                print(f\"  {model}: {count} calls\")\n",
        "        \n",
        "        if 'cost' in df.columns:\n",
        "            total_cost = df['cost'].sum()\n",
        "            avg_cost = df['cost'].mean()\n",
        "            print(f\"Total cost: ${total_cost:.4f}\")\n",
        "            print(f\"Average cost per call: ${avg_cost:.4f}\")\n",
        "        \n",
        "        if 'total_tokens' in df.columns:\n",
        "            total_tokens = df['total_tokens'].sum()\n",
        "            avg_tokens = df['total_tokens'].mean()\n",
        "            print(f\"Total tokens: {total_tokens:,}\")\n",
        "            print(f\"Average tokens per call: {avg_tokens:.1f}\")\n",
        "        \n",
        "        if 'cache_hit' in df.columns:\n",
        "            cache_rate = df['cache_hit'].mean() * 100\n",
        "            print(f\"Cache hit rate: {cache_rate:.1f}%\")\n",
        "        \n",
        "        if 'timestamp' in df.columns:\n",
        "            print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading history: {e}\")\n",
        "\n",
        "def view_recent(n=5):\n",
        "    \"\"\"View the most recent n logged calls.\"\"\"\n",
        "    global _csv_path\n",
        "    \n",
        "    if not Path(_csv_path).exists():\n",
        "        print(\"No history file found\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(_csv_path)\n",
        "        recent = df.tail(n)\n",
        "        \n",
        "        print(f\"\\nMost Recent {n} DSPy Calls:\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        for _, row in recent.iterrows():\n",
        "            print(f\"Time: {row['timestamp']}\")\n",
        "            print(f\"Model: {row['model']}\")\n",
        "            print(f\"Tokens: {row['total_tokens']} | Cost: ${row['cost']:.4f}\")\n",
        "            print(f\"User: {row['user_msg_preview'][:100]}...\")\n",
        "            print(f\"Response: {row['response_preview'][:100]}...\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading history: {e}\")\n",
        "\n",
        "def clear_cache():\n",
        "    \"\"\"Clear the processed hashes cache (will reprocess all history next time).\"\"\"\n",
        "    global _processed_hashes\n",
        "    _processed_hashes.clear()\n",
        "    print(\"Cleared processed hashes cache\")\n",
        "\n",
        "def export_full_history(output_file: str = \"full_dspy_history.json\"):\n",
        "    \"\"\"Export complete DSPy history with full messages to JSON.\"\"\"\n",
        "    try:\n",
        "        lm = dspy.settings.lm\n",
        "        if hasattr(lm, 'history') and lm.history:\n",
        "            with open(output_file, 'w') as f:\n",
        "                json.dump(lm.history, f, indent=2, default=str)\n",
        "            print(f\"Exported full history to {output_file}\")\n",
        "        else:\n",
        "            print(\"No history found to export\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting history: {e}\")\n",
        "\n",
        "# Initialize with default file\n",
        "set_log_file(\"dspy_history.csv\")\n",
        "\n",
        "print(\"DSPy History Logger for Notebooks Ready!\")\n",
        "print(\"Usage:\")\n",
        "print(\"  set_log_file('my_file.csv')  # Set custom log file\")\n",
        "print(\"  log_history()                # Log current DSPy history\") \n",
        "print(\"  show_stats()                 # Show summary statistics\")\n",
        "print(\"  view_recent(5)               # View recent 5 calls\")\n",
        "print(\"  clear_cache()                # Clear processed cache\")\n",
        "print(\"  export_full_history()        # Export complete history to JSON\")\n",
        "\n",
        "# Cell 1: Set your log file\n",
        "set_log_file(\"/nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_json_parse(json_string, fallback=None):\n",
        "    \"\"\"Robust JSON parser with multiple recovery strategies.\"\"\"\n",
        "    if fallback is None:\n",
        "        fallback = {}\n",
        "    \n",
        "    if not json_string or not isinstance(json_string, str):\n",
        "        return fallback\n",
        "    \n",
        "    # Clean markdown fences first\n",
        "    import re\n",
        "    json_string = re.sub(r\"```[a-zA-Z]*\\n?\", \"\", json_string).replace(\"```\", \"\")\n",
        "    json_string = json_string.strip()\n",
        "    \n",
        "    # Strategy 1: Direct parsing\n",
        "    try:\n",
        "        result = json.loads(json_string)\n",
        "        if isinstance(result, str) and result.strip().startswith((\"{\", \"[\")):\n",
        "            return safe_json_parse(result, fallback)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    \n",
        "    # Strategy 2: Clean common issues and handle nested single quotes\n",
        "    try:\n",
        "        cleaned = json_string.strip()\n",
        "        cleaned = cleaned.replace('\\n', '\\\\n').replace('\\r', '\\\\r').replace('\\t', '\\\\t')\n",
        "        cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n",
        "        \n",
        "        if cleaned.startswith(\"'\") or \"': '\" in cleaned or \"': {'\" in cleaned:\n",
        "            cleaned = cleaned.replace(\"'\", '\"')\n",
        "            cleaned = cleaned.replace('\"\"', '\"')\n",
        "        else:\n",
        "            cleaned = re.sub(r\"'([^']*)':\", r'\"\\1\":', cleaned)\n",
        "            cleaned = re.sub(r\":\\s*'([^']*)'\", r': \"\\1\"', cleaned)\n",
        "        \n",
        "        result = safe_json_parse(cleaned)\n",
        "        if isinstance(result, str) and result.strip().startswith((\"{\", \"[\")):\n",
        "            return safe_json_parse(result, fallback)\n",
        "        return result\n",
        "    except (json.JSONDecodeError, AttributeError):\n",
        "        pass\n",
        "    \n",
        "    # Strategy 3: Extract key-value pairs manually\n",
        "    try:\n",
        "        data = {}\n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*(\\d+(?:\\.\\d+)?)', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = float(value) if '.' in value else int(value)\n",
        "        \n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*\"([^\"]*)\"', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = value\n",
        "        \n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*(true|false)', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = value == 'true'\n",
        "        \n",
        "        if data:\n",
        "            return data\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return fallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['id', 'pdf_path', 'unique_filename', 'marker', 'status', 'processing_timestamp'])\n",
            "Markdown content length: 41730 characters\n",
            "Token count: 9347\n",
            "Target data contains 1691 records\n"
          ]
        }
      ],
      "source": [
        "# Load source file\n",
        "source_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2216_Moller_md/2216_Moller_md.json\"\n",
        "target_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/jsons/dichotomous_outcomes.json\"\n",
        "\n",
        "with open(source_file, 'r') as f:\n",
        "    source_data = json.load(f)\n",
        "\n",
        "with open(target_file, 'r') as f:\n",
        "    target_data = json.load(f)\n",
        "\n",
        "print(source_data.keys())\n",
        "\n",
        "# Extract markdown content\n",
        "markdown_content = source_data['marker']['markdown']\n",
        "\n",
        "# Use OpenAI tokenizer (cl100k_base is the same one GPT-4/4o/5 use)\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "tokens = encoding.encode(markdown_content)\n",
        "\n",
        "print(f\"Markdown content length: {len(markdown_content)} characters\")\n",
        "print(f\"Token count: {len(tokens)}\")\n",
        "print(f\"Target data contains {len(target_data)} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 60 records in target data\n",
            "\n",
            "Example target record structure:\n",
            "Ref_ID: 2216\n",
            "First_Author: Moller\n",
            "Trial_Name: \n",
            "Population: 2\n",
            "Intervention_Code: 8\n",
            "Intervention_Description: Acetaminophen Effervescent 1000mg\n",
            "Outcome_Type: 2\n",
            "Outcome_Other_Specify: \n",
            "Follow_Up_Time: 4 hours\n",
            "N_Analyzed: 60\n",
            "Adverse_Effect_Specify: \n",
            "Adverse_Effects_All_Study: \n",
            "N_Events_Number: 51\n",
            "N_Events_Percentage: 85\n",
            "Comments: \n",
            "filename: 2216_Moller\n"
          ]
        }
      ],
      "source": [
        "# Filter target data for  study to understand expected output\n",
        "one_study_records = [record for record in target_data if record.get('filename') == '2216_Moller']\n",
        "print(f\"Found {len(one_study_records)} records in target data\")\n",
        "\n",
        "# Show example record structure\n",
        "if one_study_records:\n",
        "    print(\"\\nExample target record structure:\")\n",
        "    for key, value in one_study_records[0].items():\n",
        "        print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DSPy Signature Definitions\n",
        "\n",
        "We'll define specialized signatures for each extraction task:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExtractStudyMetadata(dspy.Signature):\n",
        "    \"\"\"Extract basic study metadata from medical research paper markdown.\n",
        "    \n",
        "    This extracts core identifying information about the dental pain management study.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "\n",
        "    first_author: str = dspy.OutputField(\n",
        "        desc=\"Last name of the first author (e.g., 'Cooper'). Extract only the surname.\"\n",
        "    )\n",
        "    \n",
        "    population_code: str = dspy.OutputField(\n",
        "        desc=\"Numeric code representing the study population type. Codes: 1=simple tooth extraction, 2=surgical tooth extraction (third molar/wisdom teeth), 3=surgical tooth extraction (other teeth), 4=pulpitis or its complications. Can be multiple codes separated by commas (e.g., '2, 3')\"\n",
        "    )\n",
        "    \n",
        "\n",
        "\n",
        "class ExtractInterventions(dspy.Signature):\n",
        "    \"\"\"Extract intervention details from medical research paper markdown.\n",
        "    \n",
        "    This extracts information about pain management interventions used in dental studies.\n",
        "    Focus on medication types, dosages, and participant counts.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    \n",
        "    interventions_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string containing list of interventions. Each intervention object must have:\n",
        "        - intervention_code (integer): Numeric code 1-11 where:\n",
        "          1=Ibuprofen 200-400mg + Acetaminophen 500-1000mg\n",
        "          2=Oxycodone 5mg or Codeine 60mg  \n",
        "          3=Acetaminophen 650mg + Oxycodone 10mg\n",
        "          4=Ibuprofen 200mg + Hydrocodone 5mg\n",
        "          5=Hydrocodone 5mg + Acetaminophen 300-325mg\n",
        "          6=Ibuprofen 400mg (fast acting or acid)\n",
        "          7=Tramadol 37.5mg + Acetaminophen 325mg\n",
        "          8=Acetaminophen 500-1000mg\n",
        "          9=Acetaminophen 600-650mg + Codeine 60mg\n",
        "          10=Naproxen 400-440mg\n",
        "          11=Placebo/NA (If its not mentioned as a placebo, then it is NA)\n",
        "          #12=OTHER\n",
        "        - intervention_description (string): Full description with medication name and exact dose (e.g., \"Ibuprofen 400mg\", \"Naproxen sodium 440mg\")\n",
        "        - n_analyzed (integer): Number of participants analyzed for this intervention group\n",
        "        \n",
        "        Example: [{\"intervention_code\": 6, \"intervention_description\": \"Ibuprofen 400mg\", \"n_analyzed\": 40}]\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractAllOutcomes(dspy.Signature):\n",
        "    \"\"\"Extract ALL outcomes from medical research paper for systematic review.\n",
        "    \n",
        "    This implements COMPLETE DATA CAPTURE methodology - extract every data point\n",
        "    including rescue analgesia, adverse events, and other outcomes at all time points.\n",
        "    Focus on dichotomous outcomes from ALL data sources: main text, figures, tables,\n",
        "    and supplementary materials. Include zero-event outcomes (0/N patients).\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper including supplementary materials\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention to extract outcomes for (e.g., 'Ibuprofen 400mg', 'Placebo')\")\n",
        "    \n",
        "    all_outcomes_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string containing list of ALL outcomes for the specified intervention. Each outcome object must have:\n",
        "        \n",
        "        MANDATORY FIELDS FOR ALL OUTCOMES:\n",
        "        - outcome_type (integer): Outcome type code where:\n",
        "          1=Rescue analgesia at 6 hours\n",
        "          2=Rescue analgesia at 4 hours  \n",
        "          4=Rescue analgesia for pulpitis population\n",
        "          5=Adverse effects (nausea, vomiting, drowsiness, dizziness, headache, etc.)\n",
        "          6=Other outcomes (pain relief, time to onset, etc.)\n",
        "        - follow_up_time (string): Exact time point when outcome was measured (e.g., \"6 hours\", \"24hrs\", \"4 hours\", \"7 days\")\n",
        "        - n_analyzed (integer): Number of participants analyzed for this specific outcome\n",
        "        - n_events_number (integer): Number of patients who experienced this outcome\n",
        "        - n_events_percentage (float): Percentage of patients who experienced this outcome (e.g., 17.5, 0.6, 2.4, 0.0)\n",
        "        \n",
        "        CONDITIONAL FIELDS:\n",
        "        - adverse_effect_specify (string): Specific adverse effect name if outcome_type=5 (e.g., \"Drowsiness (sleepy, tired)\", \"Paraesthesia oral\", \"Vomiting\"). Use \"NA\" if outcome_type≠5\n",
        "        - other_outcome_specify (string): Detailed description if outcome_type=6 (e.g., \"Time to meaningful pain relief\", \"Pain intensity difference\"). Use \"NA\" if outcome_type≠6\n",
        "        - adverse_effects_all_study (string): List of all adverse effects if not reported per study arm, or \"NA\" if reported per arm\n",
        "        \n",
        "        DOCUMENTATION FIELDS:\n",
        "        - extraction_notes (string): Technical documentation including data source (\"From Table 2\", \"From Figure 5\", \"From Supplementary Table 3\"), extraction method (\"Direct from table\", \"Interpreted from Kaplan-Meier curve\"), and population used (\"Per-protocol population\", \"Safety population\", \"ITT population\")\n",
        "        - comments (string): Study-specific information including single vs multiple dose design, surgical techniques mentioned, methodological features, dropout rates, calculation details\n",
        "        \n",
        "        EXTRACTION REQUIREMENTS:\n",
        "        - Extract EVERY outcome reported, including zero-event outcomes (0/N)\n",
        "        - Create separate entries for each time point assessment\n",
        "        - Include outcomes from ALL data sources (main text, figures, supplements)\n",
        "        - Use appropriate analysis populations (efficacy vs safety)\n",
        "        - Document any calculations or interpretations performed\n",
        "        \n",
        "        Example: [\n",
        "          {\"outcome_type\": 1, \"follow_up_time\": \"6 hours\", \"n_analyzed\": 40, \"n_events_number\": 15, \"n_events_percentage\": 37.5, \"adverse_effect_specify\": \"NA\", \"other_outcome_specify\": \"NA\", \"adverse_effects_all_study\": \"NA\", \"extraction_notes\": \"From Table 3, per-protocol population\", \"comments\": \"single dose study with overnight monitoring\"},\n",
        "          {\"outcome_type\": 5, \"follow_up_time\": \"24 hours\", \"n_analyzed\": 40, \"n_events_number\": 7, \"n_events_percentage\": 17.5, \"adverse_effect_specify\": \"Drowsiness (sleepy, tired)\", \"other_outcome_specify\": \"NA\", \"adverse_effects_all_study\": \"NA\", \"extraction_notes\": \"From safety table, safety population\", \"comments\": \"mild to moderate severity\"}\n",
        "        ]\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class StructureComprehensiveOutcome(dspy.Signature):\n",
        "    \"\"\"Structure extracted data into the final comprehensive dichotomous outcome format.\n",
        "    \n",
        "    This combines study metadata, intervention details, and any outcome data (rescue analgesia,\n",
        "    adverse events, or other outcomes) into the standardized format used for systematic review\n",
        "    and meta-analysis. Each record represents one outcome for one intervention in one study.\n",
        "    \"\"\"\n",
        "    \n",
        "    study_metadata_json: str = dspy.InputField(desc=\"Study metadata as JSON string with first_author,  population_code\")\n",
        "    intervention_json: str = dspy.InputField(desc=\"Single intervention details as JSON string with intervention_code, intervention_description, n_analyzed\")\n",
        "    outcome_json: str = dspy.InputField(desc=\"Single outcome details as JSON string with all outcome fields including outcome_type, follow_up_time, n_events_number, etc.\")\n",
        "    \n",
        "    structured_record_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"Complete structured record as JSON string with exactly these fields:\n",
        "        - First_Author (string): First author last name (e.g., \"Cooper\")\n",
        "        - Population (integer): Population code (1-4)\n",
        "        - Intervention_Code (integer): Intervention code (1-11)\n",
        "        - Intervention_Description (string): Full intervention description with dose\n",
        "        - Outcome_Type (integer): Outcome type (1=rescue analgesia 6h, 2=rescue analgesia 4h, 4=rescue analgesia pulpitis, 5=adverse effects, 6=other)\n",
        "        - Outcome_Other_Specify (string): Detailed outcome description for type 6, or empty string for other types\n",
        "        - Follow_Up_Time (string): Time point (e.g., \"24hrs\", \"6 hours\")\n",
        "        - N_Analyzed (integer): Number of participants analyzed\n",
        "        - Adverse_Effect_Specify (string): Specific adverse effect name for type 5, or empty string for other types\n",
        "        - Adverse_Effects_All_Study (string): All study adverse effects if not reported per arm, or empty string\n",
        "        - N_Events_Number (integer): Number of patients with this outcome\n",
        "        - N_Events_Percentage (float): Percentage of patients with this outcome\n",
        "        - Comments (string): Study-specific methodology, design notes, and extraction details\n",
        "        \n",
        "        FIELD MAPPING RULES:\n",
        "        - For outcome_type 1,2,4 (rescue analgesia): Adverse_Effect_Specify=\"\" and Outcome_Other_Specify=\"\"\n",
        "        - For outcome_type 5 (adverse effects): Outcome_Other_Specify=\"\" and Adverse_Effect_Specify=specific adverse event name\n",
        "        - For outcome_type 6 (other outcomes): Adverse_Effect_Specify=\"\" and Outcome_Other_Specify=detailed outcome description\n",
        "        - Always include extraction methodology and data source information in Comments\n",
        "        - Ensure mathematical validation: (N_Events_Number/N_Analyzed)*100 = N_Events_Percentage\n",
        "        - Use appropriate analysis populations (efficacy vs safety) based on outcome type\n",
        "        \n",
        "        Example: {\"First_Author\": \"Cooper\",  \"Population\": 2, \"Intervention_Code\": 10, \"Intervention_Description\": \"Naproxen sodium 440mg\", \"Outcome_Type\": 5, \"Outcome_Other_Specify\": \"\", \"Follow_Up_Time\": \"24hrs\", \"N_Analyzed\": 166, \"Adverse_Effect_Specify\": \"Paraesthesia oral\", \"Adverse_Effects_All_Study\": \"\", \"N_Events_Number\": 1, \"N_Events_Percentage\": 0.6, \"Comments\": \"extracted from supplementary table 3, safety population, single dose study\"}\"\"\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DSPy Module Implementation\n",
        "\n",
        "Now we'll create DSPy modules that use these signatures with reasoning patterns:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async DSPy modules defined successfully\n"
          ]
        }
      ],
      "source": [
        "class AsyncStudyMetadataExtractor(dspy.Module):\n",
        "    \"\"\"Async module to extract study metadata using chain of thought reasoning.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_metadata = dspy.ChainOfThought(ExtractStudyMetadata)\n",
        "    \n",
        "    async def __call__(self, markdown_content: str) -> Dict[str, Any]:\n",
        "        \"\"\"Async call method that runs DSPy call in thread pool.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _extract():\n",
        "            return self.extract_metadata(markdown_content=markdown_content)\n",
        "        \n",
        "        # Run DSPy call in thread pool to avoid blocking event loop\n",
        "        result = await loop.run_in_executor(None, _extract)\n",
        "        \n",
        "        return {\n",
        "            \"first_author\": result.first_author,\n",
        "            \"population_code\": result.population_code\n",
        "        }\n",
        "    \n",
        "    def forward_sync(self, markdown_content: str) -> Dict[str, Any]:\n",
        "        \"\"\"Fallback sync method for backwards compatibility.\"\"\"\n",
        "        result = self.extract_metadata(markdown_content=markdown_content)\n",
        "        return {\n",
        "            \"first_author\": result.first_author,\n",
        "            \"population_code\": result.population_code\n",
        "        }\n",
        "\n",
        "\n",
        "class AsyncInterventionExtractor(dspy.Module):\n",
        "    \"\"\"Async module to extract intervention details.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_interventions = dspy.ChainOfThought(ExtractInterventions)\n",
        "    \n",
        "    async def __call__(self, markdown_content: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Async call method with error handling.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _extract():\n",
        "            return self.extract_interventions(markdown_content=markdown_content)\n",
        "        \n",
        "        try:\n",
        "            result = await loop.run_in_executor(None, _extract)\n",
        "            return safe_json_parse(result.interventions_json)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing interventions JSON: {e}, returning empty list\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error in intervention extraction: {e}, returning empty list\")\n",
        "            return []\n",
        "    \n",
        "    def forward_sync(self, markdown_content: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Fallback sync method.\"\"\"\n",
        "        result = self.extract_interventions(markdown_content=markdown_content)\n",
        "        try:\n",
        "            return safe_json_parse(result.interventions_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing interventions JSON, returning empty list\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class AsyncOutcomeExtractor(dspy.Module):\n",
        "    \"\"\"Async module to extract all outcomes for a specific intervention.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_all_outcomes = dspy.ChainOfThought(ExtractAllOutcomes)\n",
        "    \n",
        "    async def __call__(self, markdown_content: str, intervention_description: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Async call method with robust error handling.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _extract():\n",
        "            return self.extract_all_outcomes(\n",
        "                markdown_content=markdown_content,\n",
        "                intervention_description=intervention_description\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            result = await loop.run_in_executor(None, _extract)\n",
        "            return safe_json_parse(result.all_outcomes_json)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing outcomes JSON for '{intervention_description}': {e}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error in outcome extraction for '{intervention_description}': {e}\")\n",
        "            return []\n",
        "    \n",
        "    def forward_sync(self, markdown_content: str, intervention_description: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Fallback sync method.\"\"\"\n",
        "        result = self.extract_all_outcomes(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.all_outcomes_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing outcomes JSON, returning empty list\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class AsyncDataStructurer(dspy.Module):\n",
        "    \"\"\"Async module to structure data into final format.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.structure_data = dspy.ChainOfThought(StructureComprehensiveOutcome)\n",
        "    \n",
        "    async def __call__(self, study_metadata: Dict, intervention: Dict, outcome: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Async call method with comprehensive error handling.\"\"\"\n",
        "        loop = asyncio.get_running_loop()\n",
        "        \n",
        "        def _structure():\n",
        "            return self.structure_data(\n",
        "                study_metadata_json=json.dumps(study_metadata),\n",
        "                intervention_json=json.dumps(intervention),\n",
        "                outcome_json=json.dumps(outcome)\n",
        "            )\n",
        "        \n",
        "        try:\n",
        "            result = await loop.run_in_executor(None, _structure)\n",
        "            return safe_json_parse(result.structured_record_json)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing structured record JSON: {e}, using fallback\")\n",
        "            return self._create_fallback_record(study_metadata, intervention, outcome)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in data structuring: {e}, using fallback\")\n",
        "            return self._create_fallback_record(study_metadata, intervention, outcome)\n",
        "    \n",
        "    def _create_fallback_record(self, study_metadata: Dict, intervention: Dict, outcome: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Create fallback structured record when DSPy fails.\"\"\"\n",
        "        return {\n",
        "            \"First_Author\": study_metadata.get(\"first_author\", \"\"),\n",
        "            \"Population\": study_metadata.get(\"population_code\", \"\"),\n",
        "            \"Intervention_Code\": intervention.get(\"intervention_code\", \"\"),\n",
        "            \"Intervention_Description\": intervention.get(\"intervention_description\", \"\"),\n",
        "            \"Outcome_Type\": outcome.get(\"outcome_type\", 5),\n",
        "            \"Outcome_Other_Specify\": outcome.get(\"other_outcome_specify\", \"\"),\n",
        "            \"Follow_Up_Time\": outcome.get(\"follow_up_time\", \"\"),\n",
        "            \"N_Analyzed\": intervention.get(\"n_analyzed\", \"\"),\n",
        "            \"Adverse_Effect_Specify\": outcome.get(\"adverse_effect_specify\", \"\"),\n",
        "            \"Adverse_Effects_All_Study\": outcome.get(\"adverse_effects_all_study\", \"\"),\n",
        "            \"N_Events_Number\": outcome.get(\"n_events_number\", \"\"),\n",
        "            \"N_Events_Percentage\": outcome.get(\"n_events_percentage\", \"\"),\n",
        "            \"Comments\": f\"{outcome.get('extraction_notes', '')} {outcome.get('comments', '')}\".strip(),\n",
        "        }\n",
        "    \n",
        "    def forward_sync(self, study_metadata: Dict, intervention: Dict, outcome: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Fallback sync method.\"\"\"\n",
        "        result = self.structure_data(\n",
        "            study_metadata_json=json.dumps(study_metadata),\n",
        "            intervention_json=json.dumps(intervention),\n",
        "            outcome_json=json.dumps(outcome)\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.structured_record_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing structured record JSON, returning basic structure\")\n",
        "            return self._create_fallback_record(study_metadata, intervention, outcome)\n",
        "\n",
        "\n",
        "# Batch processing wrapper for efficient concurrent execution\n",
        "class AsyncBatchProcessor:\n",
        "    \"\"\"Handles batch processing of multiple operations with concurrency control.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_concurrent: int = 5):\n",
        "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "    \n",
        "    async def process_interventions_batch(self, intervention_extractor: AsyncInterventionExtractor, \n",
        "                                        markdown_contents: List[str]) -> List[List[Dict[str, Any]]]:\n",
        "        \"\"\"Process multiple markdown contents concurrently for interventions.\"\"\"\n",
        "        \n",
        "        async def _extract_with_semaphore(content: str):\n",
        "            async with self.semaphore:\n",
        "                return await intervention_extractor.forward(content)\n",
        "        \n",
        "        tasks = [_extract_with_semaphore(content) for content in markdown_contents]\n",
        "        return await asyncio.gather(*tasks)\n",
        "    \n",
        "    async def process_outcomes_batch(self, outcome_extractor: AsyncOutcomeExtractor,\n",
        "                                   markdown_content: str, \n",
        "                                   intervention_descriptions: List[str]) -> List[List[Dict[str, Any]]]:\n",
        "        \"\"\"Process multiple interventions concurrently for outcomes.\"\"\"\n",
        "        \n",
        "        async def _extract_with_semaphore(intervention_desc: str):\n",
        "            async with self.semaphore:\n",
        "                return await outcome_extractor.forward(markdown_content, intervention_desc)\n",
        "        \n",
        "        tasks = [_extract_with_semaphore(desc) for desc in intervention_descriptions]\n",
        "        return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "# Factory function to create all async modules\n",
        "def create_async_modules(max_concurrent: int = 5) -> Dict[str, Any]:\n",
        "    \"\"\"Factory function to create all async modules with shared configuration.\"\"\"\n",
        "    return {\n",
        "        'metadata_extractor': AsyncStudyMetadataExtractor(),\n",
        "        'intervention_extractor': AsyncInterventionExtractor(),\n",
        "        'outcome_extractor': AsyncOutcomeExtractor(),\n",
        "        'data_structurer': AsyncDataStructurer(),\n",
        "        'batch_processor': AsyncBatchProcessor(max_concurrent=max_concurrent)\n",
        "    }\n",
        "\n",
        "print(\"Async DSPy modules defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Complete Extraction Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async extraction pipeline with batch processing defined successfully\n"
          ]
        }
      ],
      "source": [
        "class AsyncMedicalDataExtractionPipeline(dspy.Module):\n",
        "    \"\"\"Complete async pipeline for extracting structured data from medical research papers.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_concurrent: int = 5):\n",
        "        super().__init__()\n",
        "        self.metadata_extractor = AsyncStudyMetadataExtractor()\n",
        "        self.intervention_extractor = AsyncInterventionExtractor()\n",
        "        self.outcome_extractor = AsyncOutcomeExtractor()\n",
        "        self.data_structurer = AsyncDataStructurer()\n",
        "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "    \n",
        "    async def forward(self, markdown_content: str):\n",
        "        \"\"\"Extract all structured records from markdown content asynchronously.\"\"\"\n",
        "        \n",
        "        # Step 1 & 2: Extract metadata and interventions concurrently\n",
        "        print(\"Extracting metadata and interventions concurrently...\")\n",
        "        \n",
        "        metadata_task = self.metadata_extractor(markdown_content)\n",
        "        interventions_task = self.intervention_extractor(markdown_content)\n",
        "        \n",
        "        study_metadata, interventions = await asyncio.gather(metadata_task, interventions_task)\n",
        "        \n",
        "        print(f\"Study metadata: {study_metadata}\")\n",
        "        print(f\"Found {len(interventions)} interventions\")\n",
        "        \n",
        "        # Step 3: Process all interventions concurrently\n",
        "        all_records = []\n",
        "        \n",
        "        if interventions:\n",
        "            outcome_tasks = []\n",
        "            for intervention in interventions:\n",
        "                task = self._process_intervention_outcomes(\n",
        "                    markdown_content, study_metadata, intervention\n",
        "                )\n",
        "                outcome_tasks.append(task)\n",
        "            \n",
        "            # Gather all intervention results\n",
        "            intervention_results = await asyncio.gather(*outcome_tasks)\n",
        "            \n",
        "            # Flatten results\n",
        "            for records in intervention_results:\n",
        "                all_records.extend(records)\n",
        "        \n",
        "        print(f\"Total records extracted: {len(all_records)}\")\n",
        "        return dspy.Prediction(extracted_records=all_records)\n",
        "    \n",
        "    async def _process_intervention_outcomes(self, markdown_content: str, \n",
        "                                           study_metadata: Dict, intervention: Dict) -> List[Dict]:\n",
        "        \"\"\"Process outcomes for a single intervention with semaphore control.\"\"\"\n",
        "        async with self.semaphore:\n",
        "            intervention_desc = intervention.get('intervention_description', '')\n",
        "            print(f\"Processing intervention: {intervention_desc}\")\n",
        "            \n",
        "            outcomes = await self.outcome_extractor(markdown_content, intervention_desc)\n",
        "            print(f\"Found {len(outcomes)} outcomes for {intervention_desc}\")\n",
        "            \n",
        "            # Structure all outcomes for this intervention concurrently\n",
        "            if outcomes:\n",
        "                structure_tasks = [\n",
        "                    self.data_structurer(study_metadata, intervention, outcome)\n",
        "                    for outcome in outcomes\n",
        "                ]\n",
        "                structured_records = await asyncio.gather(*structure_tasks)\n",
        "                return structured_records\n",
        "            \n",
        "            return []\n",
        "    \n",
        "    def _generate_output_filename(self, source_file_path: str) -> str:\n",
        "        \"\"\"Generate output filename from source filename.\"\"\"\n",
        "        source_path = Path(source_file_path)\n",
        "        source_name = source_path.stem\n",
        "        \n",
        "        if source_name.endswith('_md'):\n",
        "            output_name = source_name[:-3] + '_do'\n",
        "        else:\n",
        "            output_name = source_name + '_do'\n",
        "        \n",
        "        return output_name + '.json'\n",
        "    \n",
        "    async def save_extracted_results(self, extracted_records: List[Dict], \n",
        "                                   source_file_path: str, \n",
        "                                   output_dir: str = None, \n",
        "                                   override: bool = False) -> str:\n",
        "        \"\"\"Save extracted results to JSON file asynchronously.\"\"\"\n",
        "        try:\n",
        "            output_filename = self._generate_output_filename(source_file_path)\n",
        "            \n",
        "            if output_dir is None:\n",
        "                output_dir = Path(source_file_path).parent\n",
        "            else:\n",
        "                output_dir = Path(output_dir)\n",
        "            \n",
        "            output_dir.mkdir(parents=True, exist_ok=True)\n",
        "            output_path = output_dir / output_filename\n",
        "            \n",
        "            if output_path.exists() and not override:\n",
        "                print(f\"Output file already exists: {output_path}\")\n",
        "                print(\"Use override=True to overwrite, or file will be skipped\")\n",
        "                return None\n",
        "            \n",
        "            save_data = {\n",
        "                \"metadata\": {\n",
        "                    \"source_file\": str(source_file_path),\n",
        "                    \"extraction_timestamp\": datetime.now().isoformat(),\n",
        "                    \"total_records\": len(extracted_records),\n",
        "                    \"pipeline_version\": \"DSPy_Async_1.0\"\n",
        "                },\n",
        "                \"extracted_records\": extracted_records\n",
        "            }\n",
        "            \n",
        "            async with aiofiles.open(output_path, 'w', encoding='utf-8') as f:\n",
        "                await f.write(json.dumps(save_data, indent=2, ensure_ascii=False))\n",
        "            \n",
        "            print(f\"Successfully saved {len(extracted_records)} records to: {output_path}\")\n",
        "            return str(output_path)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results: {e}\")\n",
        "            return None\n",
        "    \n",
        "    async def run_and_save(self, markdown_content: str, source_file_path: str, \n",
        "                          output_dir: str = None, override: bool = False):\n",
        "        \"\"\"Run pipeline and save results asynchronously.\"\"\"\n",
        "        prediction = await self.forward(markdown_content)\n",
        "        await self.save_extracted_results(\n",
        "            prediction.extracted_records, source_file_path, output_dir, override\n",
        "        )\n",
        "        return prediction\n",
        "\n",
        "class AsyncBatchPipeline:\n",
        "    \"\"\"Batch processor for handling multiple files concurrently.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_concurrent_files: int = 3, max_concurrent_per_file: int = 5):\n",
        "        self.file_semaphore = asyncio.Semaphore(max_concurrent_files)\n",
        "        self.max_concurrent_per_file = max_concurrent_per_file\n",
        "    \n",
        "    async def process_single_file(self, file_path: str, markdown_content: str, \n",
        "                                output_dir: str = None, override: bool = False):\n",
        "        \"\"\"Process a single file with semaphore control.\"\"\"\n",
        "        async with self.file_semaphore:\n",
        "            pipeline = AsyncMedicalDataExtractionPipeline(self.max_concurrent_per_file)\n",
        "            print(f\"Processing file: {Path(file_path).name}\")\n",
        "            return await pipeline.run_and_save(markdown_content, file_path, output_dir, override)\n",
        "    \n",
        "    async def process_files_batch(self, file_data: List[Dict], output_dir: str = None, \n",
        "                                override: bool = False):\n",
        "        \"\"\"Process multiple files concurrently.\n",
        "        \n",
        "        Args:\n",
        "            file_data: List of dicts with 'file_path' and 'markdown_content' keys\n",
        "            output_dir: Output directory for results\n",
        "            override: Whether to overwrite existing files\n",
        "        \"\"\"\n",
        "        print(f\"Starting batch processing of {len(file_data)} files...\")\n",
        "        \n",
        "        tasks = [\n",
        "            self.process_single_file(\n",
        "                item['file_path'], \n",
        "                item['markdown_content'], \n",
        "                output_dir, \n",
        "                override\n",
        "            ) \n",
        "            for item in file_data\n",
        "        ]\n",
        "        \n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "        \n",
        "        # Count successful vs failed\n",
        "        successful = sum(1 for r in results if not isinstance(r, Exception))\n",
        "        failed = len(results) - successful\n",
        "        \n",
        "        print(f\"Batch processing complete: {successful} successful, {failed} failed\")\n",
        "        return results\n",
        "\n",
        "print(\"Async extraction pipeline with batch processing defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluation Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The 4 Core Outcomes in Classification\n",
        "\n",
        "When evaluating a system’s predictions against the **ground truth**, each result falls into one of four categories:\n",
        "\n",
        "### 1. **True Positive (TP)**\n",
        "- System says **“Yes”**\n",
        "- Ground truth is **“Yes”**\n",
        "- ✅ Correct detection  \n",
        "- **Example:** System extracts `First_Author = Cooper`, and ground truth really has `Cooper`.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **False Positive (FP)**\n",
        "- System says **“Yes”**\n",
        "- Ground truth is **“No”**\n",
        "- ❌ Wrong detection (system “hallucinated”)  \n",
        "- **Example:** System extracts `First_Author = Jones`, but ground truth has `Smith`.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **True Negative (TN)**\n",
        "- System says **“No”**\n",
        "- Ground truth is **“No”**\n",
        "- ✅ Correct rejection  \n",
        "- **Example:** Ground truth has no `Adverse_Effect_Specify`, and system also leaves it empty.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **False Negative (FN)**\n",
        "- System says **“No”**\n",
        "- Ground truth is **“Yes”**\n",
        "- ❌ Missed detection (system failed to extract)  \n",
        "- **Example:** Ground truth has `Trial_Name = MOLAR`, but system extracts nothing (or extracts wrong value).\n",
        "\n",
        "\n",
        "\n",
        "### In `MedicalExtractionEvaluator` Context\n",
        "\n",
        "- **TP (True Positive)** → A field value was extracted **and** it matched the ground truth.  \n",
        "- **FP (False Positive)** → A field value was extracted, but it was **wrong** (mismatch) or **extra** (system filled something that shouldn’t exist).  \n",
        "- **FN (False Negative)** → A ground-truth field existed, but the system didn’t produce it (missing record or missing field).  \n",
        "- **TN (True Negative)** → Neither system nor ground truth had a value for a field.  \n",
        "\n",
        "**Note:** TNs are **not explicitly tracked** in the evaluator, because in information extraction tasks the number of “true negatives” is usually very large and not informative. This is common in IR/NLP evaluation — most focus only on TP, FP, FN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async medical extraction evaluator defined successfully\n"
          ]
        }
      ],
      "source": [
        "class AsyncMedicalExtractionEvaluator:\n",
        "    \"\"\"Async evaluator for medical data extraction with semantic matching and caching.\"\"\"\n",
        "    \n",
        "    def __init__(self, use_semantic=True, semantic_threshold=0.8, max_concurrent=10):\n",
        "        self.required_fields = [\n",
        "            'First_Author', 'Population', 'Intervention_Code', 'Intervention_Description', \n",
        "            'Outcome_Type', 'Follow_Up_Time', 'N_Analyzed', 'Adverse_Effect_Specify',\n",
        "            'N_Events_Number', 'N_Events_Percentage', 'Comments'\n",
        "        ]\n",
        "        \n",
        "        self.use_semantic = use_semantic\n",
        "        self.semantic_threshold = semantic_threshold\n",
        "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
        "        \n",
        "        # Caches\n",
        "        self._matching_cache = {}\n",
        "        self._embedding_cache = {}\n",
        "        \n",
        "        if self.use_semantic:\n",
        "            self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            self.semantic_fields = ['Intervention_Description', 'Adverse_Effect_Specify', 'Follow_Up_Time']\n",
        "            self.exact_fields = ['First_Author', 'Population', 'Intervention_Code', 'Outcome_Type', \n",
        "                               'N_Analyzed', 'N_Events_Number', 'N_Events_Percentage']\n",
        "    \n",
        "    async def _get_embedding(self, text: str):\n",
        "        \"\"\"Get embedding for text with async caching.\"\"\"\n",
        "        if text in self._embedding_cache:\n",
        "            return self._embedding_cache[text]\n",
        "        \n",
        "        # Run embedding generation in thread pool\n",
        "        loop = asyncio.get_running_loop()\n",
        "        embedding = await loop.run_in_executor(None, self.semantic_model.encode, text)\n",
        "        \n",
        "        self._embedding_cache[text] = embedding\n",
        "        return embedding\n",
        "    \n",
        "    async def semantic_similarity(self, text1: str, text2: str) -> float:\n",
        "        \"\"\"Calculate semantic similarity asynchronously.\"\"\"\n",
        "        if not self.use_semantic or not text1.strip() or not text2.strip():\n",
        "            return 1.0 if text1.strip() == text2.strip() else 0.0\n",
        "        \n",
        "        # Get embeddings concurrently\n",
        "        embedding1_task = self._get_embedding(text1)\n",
        "        embedding2_task = self._get_embedding(text2)\n",
        "        \n",
        "        embedding1, embedding2 = await asyncio.gather(embedding1_task, embedding2_task)\n",
        "        \n",
        "        # Calculate similarity in thread pool\n",
        "        loop = asyncio.get_running_loop()\n",
        "        similarity = await loop.run_in_executor(\n",
        "            None, lambda: cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "        )\n",
        "        \n",
        "        return float(similarity)\n",
        "    \n",
        "    async def field_match_score(self, extracted_value: Any, ground_truth_value: Any, field_name: str) -> float:\n",
        "        \"\"\"Calculate field-level match score asynchronously.\"\"\"\n",
        "        ext_val = str(extracted_value).strip() if extracted_value is not None else \"\"\n",
        "        gt_val = str(ground_truth_value).strip() if ground_truth_value is not None else \"\"\n",
        "        \n",
        "        if not self.use_semantic or field_name in self.exact_fields:\n",
        "            return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "        \n",
        "        if field_name in self.semantic_fields:\n",
        "            if not ext_val and not gt_val:\n",
        "                return 1.0\n",
        "            if not ext_val or not gt_val:\n",
        "                return 0.0\n",
        "            \n",
        "            similarity = await self.semantic_similarity(ext_val, gt_val)\n",
        "            return 1.0 if similarity >= self.semantic_threshold else 0.0\n",
        "        \n",
        "        return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "    \n",
        "    async def calculate_record_similarity(self, extracted_record: Dict, ground_truth_record: Dict) -> float:\n",
        "        \"\"\"Calculate similarity between two records asynchronously.\"\"\"\n",
        "        async with self.semaphore:\n",
        "            # Gather all field comparisons concurrently\n",
        "            field_tasks = []\n",
        "            for field in self.required_fields:\n",
        "                if field in extracted_record and field in ground_truth_record:\n",
        "                    task = self.field_match_score(\n",
        "                        extracted_record[field], \n",
        "                        ground_truth_record[field], \n",
        "                        field\n",
        "                    )\n",
        "                    field_tasks.append(task)\n",
        "            \n",
        "            if not field_tasks:\n",
        "                return 0.0\n",
        "            \n",
        "            match_scores = await asyncio.gather(*field_tasks)\n",
        "            return sum(match_scores) / len(match_scores)\n",
        "    \n",
        "    async def _compute_similarity_matrix(self, extracted_records: List[Dict], ground_truth_records: List[Dict]):\n",
        "        \"\"\"Compute similarity matrix asynchronously.\"\"\"\n",
        "        n_extracted = len(extracted_records)\n",
        "        n_ground_truth = len(ground_truth_records)\n",
        "        \n",
        "        # Create all similarity computation tasks\n",
        "        tasks = []\n",
        "        for i in range(n_extracted):\n",
        "            for j in range(n_ground_truth):\n",
        "                task = self.calculate_record_similarity(extracted_records[i], ground_truth_records[j])\n",
        "                tasks.append((i, j, task))\n",
        "        \n",
        "        # Execute all similarity computations concurrently\n",
        "        results = await asyncio.gather(*[task for _, _, task in tasks])\n",
        "        \n",
        "        # Build similarity matrix\n",
        "        similarity_matrix = np.zeros((n_extracted, n_ground_truth))\n",
        "        for idx, (i, j, _) in enumerate(tasks):\n",
        "            similarity_matrix[i][j] = results[idx]\n",
        "        \n",
        "        return similarity_matrix\n",
        "    \n",
        "    async def hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "        \"\"\"Compute Hungarian matching asynchronously with caching.\"\"\"\n",
        "        cache_key = f\"{len(extracted_records)}_{len(ground_truth_records)}_{hash(str(extracted_records) + str(ground_truth_records))}\"\n",
        "        \n",
        "        if cache_key in self._matching_cache:\n",
        "            return self._matching_cache[cache_key]\n",
        "        \n",
        "        if not extracted_records or not ground_truth_records:\n",
        "            return []\n",
        "        \n",
        "        # Compute similarity matrix asynchronously\n",
        "        similarity_matrix = await self._compute_similarity_matrix(extracted_records, ground_truth_records)\n",
        "        \n",
        "        # Apply Hungarian algorithm in thread pool\n",
        "        loop = asyncio.get_running_loop()\n",
        "        cost_matrix = 1.0 - similarity_matrix\n",
        "        \n",
        "        # Pad matrix to square if needed\n",
        "        n_extracted, n_ground_truth = similarity_matrix.shape\n",
        "        max_size = max(n_extracted, n_ground_truth)\n",
        "        if max_size > max(n_extracted, n_ground_truth):\n",
        "            padded_cost = np.ones((max_size, max_size))\n",
        "            padded_cost[:n_extracted, :n_ground_truth] = cost_matrix\n",
        "            cost_matrix = padded_cost\n",
        "        \n",
        "        row_indices, col_indices = await loop.run_in_executor(None, linear_sum_assignment, cost_matrix)\n",
        "        \n",
        "        # Extract valid matches\n",
        "        matches = []\n",
        "        for i, j in zip(row_indices, col_indices):\n",
        "            if i < n_extracted and j < n_ground_truth:\n",
        "                similarity = similarity_matrix[i][j]\n",
        "                if similarity > 0.0:\n",
        "                    matches.append((i, j, similarity))\n",
        "        \n",
        "        # Cache results\n",
        "        self._matching_cache[cache_key] = matches\n",
        "        return matches\n",
        "    \n",
        "    async def evaluate_record_metrics(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "        \"\"\"Calculate record-level metrics asynchronously.\"\"\"\n",
        "        matches = await self.hungarian_matching(extracted_records, ground_truth)\n",
        "        valid_matches = [match for match in matches if match[2] >= 0.5]\n",
        "        \n",
        "        true_positives = len(valid_matches)\n",
        "        false_positives = len(extracted_records) - true_positives\n",
        "        false_negatives = len(ground_truth) - true_positives\n",
        "        \n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        \n",
        "        return {\n",
        "            'precision': precision, 'recall': recall, 'f1': f1,\n",
        "            'TP': true_positives, 'FP': false_positives, 'FN': false_negatives\n",
        "        }\n",
        "    \n",
        "    def evaluate_completeness(self, extracted_records: List[Dict]) -> float:\n",
        "        \"\"\"Evaluate field completeness (synchronous).\"\"\"\n",
        "        if not extracted_records:\n",
        "            return 0.0\n",
        "        \n",
        "        total_fields = len(self.required_fields) * len(extracted_records)\n",
        "        filled_fields = sum(\n",
        "            1 for record in extracted_records \n",
        "            for field in self.required_fields \n",
        "            if field in record and record[field] is not None and str(record[field]).strip()\n",
        "        )\n",
        "        \n",
        "        return filled_fields / total_fields if total_fields > 0 else 0.0\n",
        "    \n",
        "    async def evaluate_accuracy(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate extraction accuracy asynchronously.\"\"\"\n",
        "        if not extracted_records or not ground_truth:\n",
        "            return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        \n",
        "        record_metrics = await self.evaluate_record_metrics(extracted_records, ground_truth)\n",
        "        \n",
        "        return {\n",
        "            **record_metrics,\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records)\n",
        "        }\n",
        "    \n",
        "    async def evaluate(self, extracted_records: List[Dict], ground_truth: List[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Complete evaluation asynchronously.\"\"\"\n",
        "        results = {\n",
        "            \"num_extracted\": len(extracted_records),\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records),\n",
        "            \"semantic_enabled\": self.use_semantic,\n",
        "            \"semantic_threshold\": self.semantic_threshold if self.use_semantic else None\n",
        "        }\n",
        "        \n",
        "        if ground_truth:\n",
        "            accuracy_results = await self.evaluate_accuracy(extracted_records, ground_truth)\n",
        "            results.update(accuracy_results)\n",
        "            results[\"num_ground_truth\"] = len(ground_truth)\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    async def save_evaluation_to_csv(self, baseline_results: List[Dict], ground_truth: List[Dict], \n",
        "                                   source_file: str, csv_dir: str = \"/nlp/data/karthik9/Sprint1/Dental/Data/csvs\", \n",
        "                                   override: bool = False):\n",
        "        \"\"\"Save evaluation results to CSV asynchronously.\"\"\"\n",
        "        Path(csv_dir).mkdir(parents=True, exist_ok=True)\n",
        "        csv_path = Path(csv_dir) / \"do_evaluation_results.csv\"\n",
        "        \n",
        "        # Get matching results\n",
        "        matches = await self.hungarian_matching(baseline_results, ground_truth)\n",
        "        \n",
        "        # Prepare data rows\n",
        "        rows = []\n",
        "        matched_gt_indices = set()\n",
        "        matched_ext_indices = set()\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        \n",
        "        # Add matched pairs (TP)\n",
        "        for ext_idx, gt_idx, score in matches:\n",
        "            if score >= 0.5:\n",
        "                matched_gt_indices.add(gt_idx)\n",
        "                matched_ext_indices.add(ext_idx)\n",
        "                \n",
        "                for data_type, record_list, idx in [\n",
        "                    ('ground_truth', ground_truth, gt_idx),\n",
        "                    ('extracted', baseline_results, ext_idx)\n",
        "                ]:\n",
        "                    row = record_list[idx].copy()\n",
        "                    row.update({\n",
        "                        'data_type': data_type, 'source_file': source_file,\n",
        "                        'match_score': score, 'pair_id': f\"{source_file}_{gt_idx}\",\n",
        "                        'classification': 'TP', 'timestamp': timestamp\n",
        "                    })\n",
        "                    rows.append(row)\n",
        "        \n",
        "        # Add unmatched ground truth (FN)\n",
        "        for gt_idx, gt_record in enumerate(ground_truth):\n",
        "            if gt_idx not in matched_gt_indices:\n",
        "                row = gt_record.copy()\n",
        "                row.update({\n",
        "                    'data_type': 'ground_truth', 'source_file': source_file,\n",
        "                    'match_score': 0.0, 'pair_id': f\"{source_file}_{gt_idx}_missing\",\n",
        "                    'classification': 'FN', 'timestamp': timestamp\n",
        "                })\n",
        "                rows.append(row)\n",
        "        \n",
        "        # Add unmatched extractions (FP)\n",
        "        for ext_idx, ext_record in enumerate(baseline_results):\n",
        "            if ext_idx not in matched_ext_indices:\n",
        "                row = ext_record.copy()\n",
        "                row.update({\n",
        "                    'data_type': 'extracted', 'source_file': source_file,\n",
        "                    'match_score': 0.0, 'pair_id': f\"{source_file}_fp_{ext_idx}\",\n",
        "                    'classification': 'FP', 'timestamp': timestamp\n",
        "                })\n",
        "                rows.append(row)\n",
        "        \n",
        "        # Save to CSV asynchronously\n",
        "        new_df = pd.DataFrame(rows)\n",
        "        \n",
        "        if not new_df.empty:\n",
        "            print(\"Length of new_df\",len(new_df))\n",
        "            if csv_path.exists() and not override:\n",
        "                # Load existing data asynchronously\n",
        "                async with aiofiles.open(csv_path, 'r') as f:\n",
        "                    content = await f.read()\n",
        "                existing_df = pd.read_csv(pd.io.common.StringIO(content))\n",
        "                print(\"Length of existing_df\",len(existing_df))\n",
        "                \n",
        "                if override:\n",
        "                    existing_df = existing_df[existing_df['source_file'] != source_file]\n",
        "                final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "                print(\"Length of final_df\",len(final_df))\n",
        "            else:\n",
        "                final_df = new_df\n",
        "            \n",
        "            # Save asynchronously\n",
        "            csv_content = final_df.to_csv(index=False)\n",
        "            async with aiofiles.open(csv_path, 'w') as f:\n",
        "                await f.write(csv_content)\n",
        "            \n",
        "            print(f\"Results saved to: {csv_path}\")\n",
        "            print(f\"Added {len(new_df)} rows for file: {source_file}\")\n",
        "            print(f\"Total rows in CSV: {len(final_df)}\")\n",
        "        \n",
        "        return str(csv_path)\n",
        "    \n",
        "    async def save_evaluation_to_json(self, evaluation_results: Dict, source_file: str, json_path: str = \"/nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\"):\n",
        "        \"\"\"Save evaluation results to JSON file asynchronously.\"\"\"\n",
        "        new_entry = {\n",
        "            \"source_file\": source_file,\n",
        "            \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            **{k: v for k, v in evaluation_results.items() if k != 'field_accuracies'}\n",
        "        }\n",
        "        \n",
        "        # Ensure directory exists\n",
        "        json_path_obj = Path(json_path)\n",
        "        json_path_obj.parent.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Load existing data or create empty list\n",
        "        data = []\n",
        "        if json_path_obj.exists():\n",
        "            async with aiofiles.open(json_path, 'r') as f:\n",
        "                content = await f.read()\n",
        "                data = safe_json_parse(content)\n",
        "        \n",
        "        # Check if source_file already exists and replace/append\n",
        "        existing_index = next((i for i, entry in enumerate(data) if entry.get('source_file') == source_file), None)\n",
        "        \n",
        "        if existing_index is not None:\n",
        "            data[existing_index] = new_entry\n",
        "            print(f\"Updated existing results for {source_file}\")\n",
        "        else:\n",
        "            data.append(new_entry)\n",
        "            print(f\"Added new results for {source_file}\")\n",
        "        \n",
        "        # Save asynchronously\n",
        "        async with aiofiles.open(json_path, 'w') as f:\n",
        "            await f.write(json.dumps(data, indent=2))\n",
        "        \n",
        "        print(f\"Results saved to: {json_path}\")\n",
        "        return json_path\n",
        "\n",
        "\n",
        "class AsyncBatchEvaluator:\n",
        "    \"\"\"Batch evaluator for processing multiple files concurrently.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_concurrent_files: int = 3, max_concurrent_per_file: int = 10):\n",
        "        self.file_semaphore = asyncio.Semaphore(max_concurrent_files)\n",
        "        self.evaluator = AsyncMedicalExtractionEvaluator(max_concurrent=max_concurrent_per_file)\n",
        "    \n",
        "    async def evaluate_single_file(self, extracted_records: List[Dict], ground_truth: List[Dict], \n",
        "                                 source_file: str, save_csv: bool = True, csv_dir: str = \"evaluation_results\"):\n",
        "        \"\"\"Evaluate a single file with semaphore control.\"\"\"\n",
        "        async with self.file_semaphore:\n",
        "            print(f\"Evaluating file: {source_file}\")\n",
        "            \n",
        "            results = await self.evaluator.evaluate(extracted_records, ground_truth)\n",
        "            \n",
        "            if save_csv:\n",
        "                await self.evaluator.save_evaluation_to_csv(\n",
        "                    extracted_records, ground_truth, source_file, csv_dir\n",
        "                )\n",
        "            \n",
        "            return {\n",
        "                'source_file': source_file,\n",
        "                'results': results\n",
        "            }\n",
        "    \n",
        "    async def evaluate_files_batch(self, file_data: List[Dict], save_csv: bool = True, \n",
        "                                 csv_dir: str = \"evaluation_results\"):\n",
        "        \"\"\"Evaluate multiple files concurrently.\n",
        "        \n",
        "        Args:\n",
        "            file_data: List of dicts with 'extracted_records', 'ground_truth', 'source_file' keys\n",
        "        \"\"\"\n",
        "        print(f\"Starting batch evaluation of {len(file_data)} files...\")\n",
        "        \n",
        "        tasks = [\n",
        "            self.evaluate_single_file(\n",
        "                item['extracted_records'],\n",
        "                item['ground_truth'], \n",
        "                item['source_file'],\n",
        "                save_csv,\n",
        "                csv_dir\n",
        "            )\n",
        "            for item in file_data\n",
        "        ]\n",
        "        \n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "        \n",
        "        successful = sum(1 for r in results if not isinstance(r, Exception))\n",
        "        failed = len(results) - successful\n",
        "        \n",
        "        print(f\"Batch evaluation complete: {successful} successful, {failed} failed\")\n",
        "        return results\n",
        "\n",
        "print(\"Async medical extraction evaluator defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Initial Baseline Extraction Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running async baseline extraction...\n",
            "==================================================\n",
            "Extracting metadata and interventions concurrently...\n",
            "Study metadata: {'first_author': 'Møller', 'population_code': '2'}\n",
            "Found 4 interventions\n",
            "Processing intervention: Effervescent Acetaminophen 1000 mg\n",
            "Processing intervention: Tablet Acetaminophen 1000 mg\n",
            "Processing intervention: Effervescent Placebo\n",
            "Processing intervention: Tablet Placebo\n",
            "Found 21 outcomes for Effervescent Placebo\n",
            "Found 21 outcomes for Tablet Placebo\n",
            "Found 21 outcomes for Tablet Acetaminophen 1000 mg\n",
            "Found 18 outcomes for Effervescent Acetaminophen 1000 mg\n",
            "Total records extracted: 81\n",
            "\n",
            "Baseline extraction completed. Extracted 81 records.\n",
            "\n",
            "First extracted record:\n",
            "------------------------------\n",
            "First_Author: Møller\n",
            "Population: 2\n",
            "Intervention_Code: 8\n",
            "Intervention_Description: Effervescent Acetaminophen 1000 mg\n",
            "Outcome_Type: 2\n",
            "...\n",
            "\n",
            "==================================================\n",
            "RUNNING EVALUATION AND SAVING RESULTS...\n",
            "==================================================\n",
            "Length of new_df 141\n",
            "Updated existing results for /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2216_Moller_md/2216_Moller_md.json\n",
            "Successfully saved 81 records to: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2216_Moller_md/2216_Moller_do.json\n",
            "Length of existing_df 1202\n",
            "Length of final_df 1343\n",
            "Results saved to: /nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\n",
            "Results saved to: /nlp/data/karthik9/Sprint1/Dental/Data/csvs/do_evaluation_results.csv\n",
            "Added 141 rows for file: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2216_Moller_md/2216_Moller_md.json\n",
            "Total rows in CSV: 1343\n",
            "\n",
            "==================================================\n",
            "BASELINE EVALUATION RESULTS:\n",
            "==================================================\n",
            "num_extracted: 81\n",
            "completeness: 0.9764309764309764\n",
            "semantic_enabled: True\n",
            "semantic_threshold: 0.8\n",
            "precision: 0.7407407407407407\n",
            "recall: 1.0\n",
            "f1: 0.851063829787234\n",
            "TP: 60\n",
            "FP: 21\n",
            "FN: 0\n",
            "num_ground_truth: 60\n",
            "\n",
            "Results saved to:\n",
            "  - Pipeline results: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2216_Moller_md/2216_Moller_do.json\n",
            "  - Evaluation JSON: /nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\n",
            "  - Evaluation CSV: /nlp/data/karthik9/Sprint1/Dental/Data/csvs/do_evaluation_results.csv\n",
            "Async main execution pipeline defined successfully\n"
          ]
        }
      ],
      "source": [
        "async def run_async_extraction_and_evaluation(markdown_content: str, source_file: str, \n",
        "                                             one_study_records: List[Dict], \n",
        "                                             override: bool = False):\n",
        "    \"\"\"Run the complete async extraction and evaluation pipeline.\"\"\"\n",
        "    \n",
        "    print(\"Running async baseline extraction...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Initialize async pipeline and evaluator\n",
        "        async_pipeline = AsyncMedicalDataExtractionPipeline(max_concurrent=5)\n",
        "        async_evaluator = AsyncMedicalExtractionEvaluator(use_semantic=True, max_concurrent=10)\n",
        "        \n",
        "        # Run extraction and save concurrently\n",
        "        extraction_task = async_pipeline(markdown_content)\n",
        "        \n",
        "        baseline_prediction = await extraction_task\n",
        "        baseline_results = baseline_prediction.extracted_records if hasattr(baseline_prediction, 'extracted_records') else []\n",
        "        \n",
        "        print(f\"\\nBaseline extraction completed. Extracted {len(baseline_results)} records.\")\n",
        "        \n",
        "        if baseline_results:\n",
        "            print(\"\\nFirst extracted record:\")\n",
        "            print(\"-\" * 30)\n",
        "            for key, value in list(baseline_results[0].items())[:5]:  # Show first 5 fields\n",
        "                print(f\"{key}: {value}\")\n",
        "            print(\"...\")\n",
        "        \n",
        "        # Run evaluation and file saves concurrently\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"RUNNING EVALUATION AND SAVING RESULTS...\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # Run evaluation, JSON save, CSV save, and pipeline save concurrently\n",
        "        evaluation_task = async_evaluator.evaluate(baseline_results, one_study_records)\n",
        "        pipeline_save_task = async_pipeline.save_extracted_results(\n",
        "            baseline_results, source_file, override=override\n",
        "        )\n",
        "        \n",
        "        # Wait for evaluation to complete first\n",
        "        baseline_evaluation = await evaluation_task\n",
        "        \n",
        "        # Then save results concurrently\n",
        "        json_save_task = async_evaluator.save_evaluation_to_json(\n",
        "            baseline_evaluation, source_file, \"/nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\"\n",
        "        )\n",
        "        csv_save_task = async_evaluator.save_evaluation_to_csv(\n",
        "            baseline_results, one_study_records, source_file, \n",
        "            override=override\n",
        "        )\n",
        "        \n",
        "        # Wait for all saves to complete\n",
        "        pipeline_path, json_path, csv_path = await asyncio.gather(\n",
        "            pipeline_save_task, json_save_task, csv_save_task\n",
        "        )\n",
        "        \n",
        "        # Print evaluation results\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"BASELINE EVALUATION RESULTS:\")\n",
        "        print(\"=\" * 50)\n",
        "        for key, value in baseline_evaluation.items():\n",
        "            if key != 'field_accuracies':\n",
        "                print(f\"{key}: {value}\")\n",
        "        \n",
        "        print(f\"\\nResults saved to:\")\n",
        "        print(f\"  - Pipeline results: {pipeline_path}\")\n",
        "        print(f\"  - Evaluation JSON: {json_path}\")\n",
        "        print(f\"  - Evaluation CSV: {csv_path}\")\n",
        "        \n",
        "        return {\n",
        "            'baseline_results': baseline_results,\n",
        "            'baseline_evaluation': baseline_evaluation,\n",
        "            'files_saved': {\n",
        "                'pipeline': pipeline_path,\n",
        "                'json': json_path,\n",
        "                'csv': csv_path\n",
        "            }\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error in async extraction: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return {\n",
        "            'baseline_results': [],\n",
        "            'baseline_evaluation': {\"completeness\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0},\n",
        "            'files_saved': None\n",
        "        }\n",
        "\n",
        "# Batch processing function\n",
        "async def run_batch_extraction_and_evaluation(file_data: List[Dict], \n",
        "                                             max_concurrent_files: int = 3,\n",
        "                                             override: bool = False):\n",
        "    \"\"\"Run batch processing for multiple files.\n",
        "    \n",
        "    Args:\n",
        "        file_data: List of dicts with 'markdown_content', 'source_file', 'ground_truth' keys\n",
        "        max_concurrent_files: Number of files to process simultaneously\n",
        "        override: Whether to overwrite existing files\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"Starting async batch processing of {len(file_data)} files...\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Initialize batch processors\n",
        "    batch_pipeline = AsyncBatchPipeline(max_concurrent_files, max_concurrent_per_file=5)\n",
        "    batch_evaluator = AsyncBatchEvaluator(max_concurrent_files, max_concurrent_per_file=10)\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    try:\n",
        "        # Prepare pipeline data\n",
        "        pipeline_data = [\n",
        "            {\n",
        "                'file_path': item['source_file'],\n",
        "                'markdown_content': item['markdown_content']\n",
        "            }\n",
        "            for item in file_data\n",
        "        ]\n",
        "        \n",
        "        # Prepare evaluation data  \n",
        "        evaluation_data = [\n",
        "            {\n",
        "                'extracted_records': [],  # Will be filled after extraction\n",
        "                'ground_truth': item['ground_truth'],\n",
        "                'source_file': item['source_file']\n",
        "            }\n",
        "            for item in file_data\n",
        "        ]\n",
        "        \n",
        "        # Run extractions first\n",
        "        print(\"Phase 1: Running extractions...\")\n",
        "        extraction_results = await batch_pipeline.process_files_batch(\n",
        "            pipeline_data, output_dir=\"extraction_results\", override=override\n",
        "        )\n",
        "        \n",
        "        # Load extracted results for evaluation\n",
        "        for i, result in enumerate(extraction_results):\n",
        "            if not isinstance(result, Exception) and result:\n",
        "                # Load the extracted records from the result\n",
        "                if hasattr(result, 'extracted_records'):\n",
        "                    evaluation_data[i]['extracted_records'] = result.extracted_records\n",
        "        \n",
        "        # Run evaluations\n",
        "        print(\"\\nPhase 2: Running evaluations...\")\n",
        "        evaluation_results = await batch_evaluator.evaluate_files_batch(\n",
        "            evaluation_data, save_csv=True, csv_dir=\"evaluation_results\"\n",
        "        )\n",
        "        \n",
        "        end_time = datetime.now()\n",
        "        processing_time = (end_time - start_time).total_seconds()\n",
        "        \n",
        "        # Summary\n",
        "        successful_extractions = sum(1 for r in extraction_results if not isinstance(r, Exception))\n",
        "        successful_evaluations = sum(1 for r in evaluation_results if not isinstance(r, Exception))\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"BATCH PROCESSING SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Total files: {len(file_data)}\")\n",
        "        print(f\"Successful extractions: {successful_extractions}\")\n",
        "        print(f\"Successful evaluations: {successful_evaluations}\")\n",
        "        print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
        "        print(f\"Average time per file: {processing_time/len(file_data):.2f} seconds\")\n",
        "        \n",
        "        return {\n",
        "            'extraction_results': extraction_results,\n",
        "            'evaluation_results': evaluation_results,\n",
        "            'summary': {\n",
        "                'total_files': len(file_data),\n",
        "                'successful_extractions': successful_extractions,\n",
        "                'successful_evaluations': successful_evaluations,\n",
        "                'processing_time': processing_time\n",
        "            }\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error in batch processing: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Usage example for single file:\n",
        "\n",
        "result = await run_async_extraction_and_evaluation(\n",
        "    markdown_content=markdown_content,\n",
        "    source_file=source_file, \n",
        "    one_study_records=one_study_records,\n",
        "    override=False\n",
        ")\n",
        "\n",
        "\n",
        "# Usage example for batch processing:\n",
        "\"\"\"\n",
        "batch_data = [\n",
        "    {\n",
        "        'markdown_content': content1,\n",
        "        'source_file': 'study1.json',\n",
        "        'ground_truth': gt_records1\n",
        "    },\n",
        "    {\n",
        "        'markdown_content': content2, \n",
        "        'source_file': 'study2.json',\n",
        "        'ground_truth': gt_records2\n",
        "    }\n",
        "]\n",
        "\n",
        "batch_results = await run_batch_extraction_and_evaluation(\n",
        "    batch_data, max_concurrent_files=3, override=False\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "print(\"Async main execution pipeline defined successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No new records to add\n",
            "\n",
            "DSPy History Stats from /nlp/data/karthik9/Sprint1/Dental/Data/csvs/extraction_history.csv:\n",
            "==================================================\n",
            "Total calls: 1032\n",
            "Unique models: 1\n",
            "Model breakdown:\n",
            "  gemini/gemini-2.5-pro: 1032 calls\n",
            "Total cost: $25.3676\n",
            "Average cost per call: $0.0246\n",
            "Total tokens: 597,764\n",
            "Average tokens per call: 579.2\n",
            "Cache hit rate: 85.5%\n",
            "Date range: 2025-09-16T10:33:45.131530 to 2025-09-16T12:51:13.055651\n"
          ]
        }
      ],
      "source": [
        "#Log the history  \n",
        "log_history()\n",
        "\n",
        "#Check stats anytime\n",
        "show_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Example Generation and Few-Shot Learning Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating examples for study: Moller\n",
            "Population code: 2\n",
            "Found 4 interventions:\n",
            "  - Acetaminophen Effervescent 1000mg: 15 outcomes\n",
            "  - Acetaminophen Tablet 1000mg: 15 outcomes\n",
            "  - Effervescent Placebo: 15 outcomes\n",
            "  - Tablet Placebo: 15 outcomes\n",
            "✓ Created 3 structure examples\n",
            "\n",
            "TOTAL EXAMPLES CREATED: 9\n",
            "\n",
            "Example METADATA:\n",
            "  Input: markdown_content (length: 41730)\n",
            "  Output: first_author='Moller', population_code='2'\n",
            "\n",
            "Example INTERVENTIONS:\n",
            "  Input: markdown_content (length: 41730)\n",
            "  Output: 4 interventions\n",
            "    1. Acetaminophen Effervescent 1000mg (n=60)\n",
            "    2. Acetaminophen Tablet 1000mg (n=60)\n",
            "    3. Effervescent Placebo (n=62)\n",
            "    4. Tablet Placebo (n=60)\n",
            "\n",
            "Example OUTCOMES:\n",
            "  Input: intervention='Acetaminophen Effervescent 1000mg'\n",
            "  Output: 15 outcomes\n",
            "    1. Type 2, 4 hours: 51/60 (85.0%)\n",
            "    2. Type 5, 7 days: 11/60 (18.33333333%)\n",
            "    ... and 13 more\n",
            "\n",
            "Example STRUCTURE:\n",
            "  Input: study metadata + intervention + outcome\n",
            "  Output: Moller - Acetaminophen Effervescent 1000mg - Type 2\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def create_training_examples_from_records(one_study_records, markdown_content):\n",
        "    \"\"\"\n",
        "    Create proper DSPy training examples from existing study records.\n",
        "    This creates examples for each signature: metadata, interventions, and outcomes.\n",
        "    \"\"\"\n",
        "    \n",
        "    if not one_study_records:\n",
        "        print(\"No study records provided!\")\n",
        "        return []\n",
        "    \n",
        "    # Get basic study info from first record\n",
        "    first_record = one_study_records[0]\n",
        "    first_author = first_record['First_Author']\n",
        "    population_code = str(first_record['Population'])\n",
        "    \n",
        "    print(f\"Creating examples for study: {first_author}\")\n",
        "    print(f\"Population code: {population_code}\")\n",
        "    \n",
        "    # Group records by intervention\n",
        "    interventions_data = defaultdict(list)\n",
        "    for record in one_study_records:\n",
        "        intervention_key = record['Intervention_Description']\n",
        "        interventions_data[intervention_key].append(record)\n",
        "    \n",
        "    print(f\"Found {len(interventions_data)} interventions:\")\n",
        "    for intervention, records in interventions_data.items():\n",
        "        print(f\"  - {intervention}: {len(records)} outcomes\")\n",
        "    \n",
        "    # Create training examples\n",
        "    training_examples = []\n",
        "    \n",
        "    # 1. METADATA EXTRACTION EXAMPLE\n",
        "    metadata_example = dspy.Example(\n",
        "        markdown_content=markdown_content,\n",
        "        first_author=first_author,\n",
        "        population_code=population_code\n",
        "    ).with_inputs(\"markdown_content\")\n",
        "    \n",
        "    training_examples.append((\"metadata\", metadata_example))\n",
        "    \n",
        "    # 2. INTERVENTIONS EXTRACTION EXAMPLE\n",
        "    # Create list of unique interventions with their participant counts\n",
        "    interventions_list = []\n",
        "    for intervention_desc, records in interventions_data.items():\n",
        "        # Get intervention code and participant count from first record of each intervention\n",
        "        first_record_for_intervention = records[0]\n",
        "        intervention_info = {\n",
        "            \"intervention_code\": first_record_for_intervention['Intervention_Code'],\n",
        "            \"intervention_description\": intervention_desc,\n",
        "            \"n_analyzed\": first_record_for_intervention['N_Analyzed']\n",
        "        }\n",
        "        interventions_list.append(intervention_info)\n",
        "    \n",
        "    interventions_example = dspy.Example(\n",
        "        markdown_content=markdown_content,\n",
        "        interventions_json=json.dumps(interventions_list, indent=2)\n",
        "    ).with_inputs(\"markdown_content\")\n",
        "    \n",
        "    training_examples.append((\"interventions\", interventions_example))\n",
        "    \n",
        "    # 3. OUTCOMES EXTRACTION EXAMPLES\n",
        "    # Create one example for each intervention\n",
        "    for intervention_desc, records in interventions_data.items():\n",
        "        \n",
        "        # Convert records to the expected outcome format\n",
        "        outcomes_list = []\n",
        "        for record in records:\n",
        "            outcome_info = {\n",
        "                \"outcome_type\": record['Outcome_Type'],\n",
        "                \"follow_up_time\": record['Follow_Up_Time'],\n",
        "                \"n_analyzed\": record['N_Analyzed'],\n",
        "                \"n_events_number\": record['N_Events_Number'],\n",
        "                \"n_events_percentage\": float(record['N_Events_Percentage']),\n",
        "                \"adverse_effect_specify\": record['Adverse_Effect_Specify'] if record['Adverse_Effect_Specify'] else \"NA\",\n",
        "                \"other_outcome_specify\": record['Outcome_Other_Specify'] if record['Outcome_Other_Specify'] else \"NA\",\n",
        "                \"adverse_effects_all_study\": record['Adverse_Effects_All_Study'] if record['Adverse_Effects_All_Study'] else \"NA\",\n",
        "                \"extraction_notes\": f\"From study data for {intervention_desc}\",\n",
        "                \"comments\": record['Comments']\n",
        "            }\n",
        "            outcomes_list.append(outcome_info)\n",
        "        \n",
        "        outcomes_example = dspy.Example(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_desc,\n",
        "            all_outcomes_json=json.dumps(outcomes_list, indent=2)\n",
        "        ).with_inputs(\"markdown_content\", \"intervention_description\")\n",
        "        \n",
        "        training_examples.append((\"outcomes\", outcomes_example))\n",
        "    \n",
        "    # 4. STRUCTURED RECORD EXAMPLES\n",
        "    # Create examples for the final structuring step\n",
        "    for record in one_study_records[:3]:  # Just use first 3 as examples\n",
        "        \n",
        "        # Create the input data\n",
        "        study_metadata = {\n",
        "            \"first_author\": record['First_Author'],\n",
        "            \"population_code\": record['Population']\n",
        "        }\n",
        "        \n",
        "        intervention_data = {\n",
        "            \"intervention_code\": record['Intervention_Code'],\n",
        "            \"intervention_description\": record['Intervention_Description'],\n",
        "            \"n_analyzed\": record['N_Analyzed']\n",
        "        }\n",
        "        \n",
        "        outcome_data = {\n",
        "            \"outcome_type\": record['Outcome_Type'],\n",
        "            \"follow_up_time\": record['Follow_Up_Time'],\n",
        "            \"n_analyzed\": record['N_Analyzed'],\n",
        "            \"n_events_number\": record['N_Events_Number'],\n",
        "            \"n_events_percentage\": float(record['N_Events_Percentage']),\n",
        "            \"adverse_effect_specify\": record['Adverse_Effect_Specify'] if record['Adverse_Effect_Specify'] else \"NA\",\n",
        "            \"other_outcome_specify\": record['Outcome_Other_Specify'] if record['Outcome_Other_Specify'] else \"NA\",\n",
        "            \"adverse_effects_all_study\": record['Adverse_Effects_All_Study'] if record['Adverse_Effects_All_Study'] else \"NA\",\n",
        "            \"extraction_notes\": f\"From study data\",\n",
        "            \"comments\": record['Comments']\n",
        "        }\n",
        "        \n",
        "        # Create expected output\n",
        "        expected_output = {\n",
        "            \"First_Author\": record['First_Author'],\n",
        "            \"Population\": record['Population'],\n",
        "            \"Intervention_Code\": record['Intervention_Code'],\n",
        "            \"Intervention_Description\": record['Intervention_Description'],\n",
        "            \"Outcome_Type\": record['Outcome_Type'],\n",
        "            \"Outcome_Other_Specify\": record['Outcome_Other_Specify'],\n",
        "            \"Follow_Up_Time\": record['Follow_Up_Time'],\n",
        "            \"N_Analyzed\": record['N_Analyzed'],\n",
        "            \"Adverse_Effect_Specify\": record['Adverse_Effect_Specify'],\n",
        "            \"Adverse_Effects_All_Study\": record['Adverse_Effects_All_Study'],\n",
        "            \"N_Events_Number\": record['N_Events_Number'],\n",
        "            \"N_Events_Percentage\": float(record['N_Events_Percentage']),\n",
        "            \"Comments\": record['Comments']\n",
        "        }\n",
        "        \n",
        "        structure_example = dspy.Example(\n",
        "            study_metadata_json=json.dumps(study_metadata),\n",
        "            intervention_json=json.dumps(intervention_data),\n",
        "            outcome_json=json.dumps(outcome_data),\n",
        "            structured_record_json=json.dumps(expected_output, indent=2)\n",
        "        ).with_inputs(\"study_metadata_json\", \"intervention_json\", \"outcome_json\")\n",
        "        \n",
        "        training_examples.append((\"structure\", structure_example))\n",
        "    \n",
        "    print(f\"✓ Created 3 structure examples\")\n",
        "    \n",
        "    # Print summary and examples\n",
        "    print(f\"\\nTOTAL EXAMPLES CREATED: {len(training_examples)}\")\n",
        "    \n",
        "    # Show example of each type\n",
        "    example_types = [\"metadata\", \"interventions\", \"outcomes\", \"structure\"]\n",
        "    for ex_type in example_types:\n",
        "        example = next((ex for ex_type_found, ex in training_examples if ex_type_found == ex_type), None)\n",
        "        if example:\n",
        "            print(f\"\\nExample {ex_type.upper()}:\")\n",
        "            if ex_type == \"metadata\":\n",
        "                print(f\"  Input: markdown_content (length: {len(example.markdown_content)})\")\n",
        "                print(f\"  Output: first_author='{example.first_author}', population_code='{example.population_code}'\")\n",
        "            elif ex_type == \"interventions\":\n",
        "                interventions_data = safe_json_parse(example.interventions_json)\n",
        "                print(f\"  Input: markdown_content (length: {len(example.markdown_content)})\")\n",
        "                print(f\"  Output: {len(interventions_data)} interventions\")\n",
        "                for i, intervention in enumerate(interventions_data):\n",
        "                    print(f\"    {i+1}. {intervention['intervention_description']} (n={intervention['n_analyzed']})\")\n",
        "            elif ex_type == \"outcomes\":\n",
        "                outcomes_data = safe_json_parse(example.all_outcomes_json)\n",
        "                print(f\"  Input: intervention='{example.intervention_description}'\")\n",
        "                print(f\"  Output: {len(outcomes_data)} outcomes\")\n",
        "                for i, outcome in enumerate(outcomes_data[:2]):  # Show first 2\n",
        "                    print(f\"    {i+1}. Type {outcome['outcome_type']}, {outcome['follow_up_time']}: {outcome['n_events_number']}/{outcome['n_analyzed']} ({outcome['n_events_percentage']}%)\")\n",
        "                if len(outcomes_data) > 2:\n",
        "                    print(f\"    ... and {len(outcomes_data) - 2} more\")\n",
        "            elif ex_type == \"structure\":\n",
        "                output_data = safe_json_parse(example.structured_record_json)\n",
        "                print(f\"  Input: study metadata + intervention + outcome\")\n",
        "                print(f\"  Output: {output_data['First_Author']} - {output_data['Intervention_Description']} - Type {output_data['Outcome_Type']}\")\n",
        "    \n",
        "    return training_examples\n",
        "\n",
        "# Usage:\n",
        "training_examples = create_training_examples_from_records(one_study_records, markdown_content)\n",
        "# metadata_examples = [ex for ex_type, ex in training_examples if ex_type == 'metadata']\n",
        "# intervention_examples = [ex for ex_type, ex in training_examples if ex_type == 'interventions']\n",
        "outcome_examples = [ex for ex_type, ex in training_examples if ex_type == 'outcomes']\n",
        "# structure_examples = [ex for ex_type, ex in training_examples if ex_type == 'structure']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dspy.primitives.example.Example"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dspy.Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. DSPy Optimizers Setup and Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up BootstrapFewShot optimizer...\n",
            "Setting up LabeledFewShot optimizer...\n",
            "Optimizers initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Setup optimizers\n",
        "from dspy.teleprompt import BootstrapFewShot, LabeledFewShot\n",
        "\n",
        "# Define metric for optimization\n",
        "def medical_extraction_metric(example, prediction, trace=None):\n",
        "    \"\"\"Custom metric for medical extraction quality.\"\"\"\n",
        "    try:\n",
        "        # Check if key fields are extracted correctly\n",
        "        score = 0.0\n",
        "        total_fields = 4  # ref_id, first_author, trial_name, population_code\n",
        "        \n",
        "        if hasattr(prediction, 'ref_id') and prediction.ref_id == example.ref_id:\n",
        "            score += 1\n",
        "        if hasattr(prediction, 'first_author') and prediction.first_author.lower() == example.first_author.lower():\n",
        "            score += 1\n",
        "        if hasattr(prediction, 'trial_name'):\n",
        "            score += 1  # Trial name can be flexible\n",
        "        if hasattr(prediction, 'population_code') and prediction.population_code == example.population_code:\n",
        "            score += 1\n",
        "        \n",
        "        return score / total_fields\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# Initialize optimizers\n",
        "if training_examples:\n",
        "    print(\"Setting up BootstrapFewShot optimizer...\")\n",
        "    bootstrap_optimizer = BootstrapFewShot(\n",
        "        metric=medical_extraction_metric,\n",
        "        max_bootstrapped_demos=3,\n",
        "        max_labeled_demos=2\n",
        "    )\n",
        "    \n",
        "    print(\"Setting up LabeledFewShot optimizer...\")\n",
        "    labeled_optimizer = LabeledFewShot(k=2)\n",
        "    \n",
        "    print(\"Optimizers initialized successfully\")\n",
        "else:\n",
        "    print(\"No training examples available for optimization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing StudyMetadataExtractor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:20<00:00, 20.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 0 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Optimization completed successfully\n",
            "\\nOptimized metadata extraction result:\n",
            "{'ref_id': '1655257', 'first_author': 'Cooper', 'trial_name': 'NR', 'population_code': '2'}\n"
          ]
        }
      ],
      "source": [
        "# Optimize the metadata extractor\n",
        "if training_examples:\n",
        "    try:\n",
        "        print(\"Optimizing StudyMetadataExtractor...\")\n",
        "        \n",
        "        # Compile with BootstrapFewShot\n",
        "        optimized_metadata_extractor = bootstrap_optimizer.compile(\n",
        "            StudyMetadataExtractor(),\n",
        "            trainset=[metadata_example]  # Use metadata example\n",
        "        )\n",
        "        \n",
        "        print(\"Optimization completed successfully\")\n",
        "        \n",
        "        # Test optimized extractor\n",
        "        test_result = optimized_metadata_extractor(markdown_content[:2000])\n",
        "        print(\"\\\\nOptimized metadata extraction result:\")\n",
        "        print(test_result)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Optimization failed: {e}\")\n",
        "        print(\"Using baseline extractor\")\n",
        "        optimized_metadata_extractor = StudyMetadataExtractor()\n",
        "else:\n",
        "    print(\"Using baseline extractor (no training data)\")\n",
        "    optimized_metadata_extractor = StudyMetadataExtractor()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Optimized Pipeline and Final Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized pipeline initialized with baseline components\n"
          ]
        }
      ],
      "source": [
        "# Create optimized pipeline\n",
        "class OptimizedMedicalDataExtractionPipeline(dspy.Module):\n",
        "    \"\"\"Optimized version of the extraction pipeline.\"\"\"\n",
        "    \n",
        "    def __init__(self, optimized_metadata_extractor=None):\n",
        "        super().__init__()\n",
        "        self.metadata_extractor = optimized_metadata_extractor or StudyMetadataExtractor()\n",
        "        self.intervention_extractor = InterventionExtractor()\n",
        "        self.outcome_extractor = OutcomeExtractor()\n",
        "        self.data_structurer = DataStructurer()\n",
        "    \n",
        "    def forward(self, markdown_content: str):\n",
        "        \"\"\"Extract all structured records from markdown content.\"\"\"\n",
        "        \n",
        "        print(\"=== OPTIMIZED EXTRACTION PIPELINE ===\")\n",
        "        \n",
        "        # Step 1: Extract study metadata\n",
        "        print(\"Extracting study metadata...\")\n",
        "        study_metadata = self.metadata_extractor(markdown_content)\n",
        "        print(f\"Study metadata: {study_metadata}\")\n",
        "        \n",
        "        # Step 2: Extract interventions\n",
        "        print(\"Extracting interventions...\")\n",
        "        interventions = self.intervention_extractor(markdown_content)\n",
        "        print(f\"Found {len(interventions)} interventions\")\n",
        "        \n",
        "        # Step 3: For each intervention, extract outcomes and structure data\n",
        "        all_records = []\n",
        "        \n",
        "        for i, intervention in enumerate(interventions):\n",
        "            print(f\"Processing intervention {i+1}: {intervention.get('intervention_description', 'Unknown')}\")\n",
        "            \n",
        "            outcomes = self.outcome_extractor(\n",
        "                markdown_content, \n",
        "                intervention.get('intervention_description', '')\n",
        "            )\n",
        "            \n",
        "            print(f\"Found {len(outcomes)} outcomes for this intervention\")\n",
        "            \n",
        "            for j, outcome in enumerate(outcomes):\n",
        "                outcome_description = outcome.get('adverse_effect_specify', outcome.get('other_outcome_specify', 'Unknown'))\n",
        "                #print(f\"  Structuring outcome {j+1}: {outcome_description}\")\n",
        "                \n",
        "                structured_record = self.data_structurer(\n",
        "                    study_metadata, \n",
        "                    intervention, \n",
        "                    outcome\n",
        "                )\n",
        "                all_records.append(structured_record)\n",
        "        \n",
        "        print(f\"Total records extracted: {len(all_records)}\")\n",
        "        \n",
        "        # Return a dspy.Prediction object instead of a raw list\n",
        "        return dspy.Prediction(extracted_records=all_records)\n",
        "\n",
        "\n",
        "# Initialize optimized pipeline\n",
        "try:\n",
        "    optimized_pipeline = OptimizedMedicalDataExtractionPipeline(optimized_metadata_extractor)\n",
        "    print(\"Optimized pipeline initialized\")\n",
        "except:\n",
        "    optimized_pipeline = OptimizedMedicalDataExtractionPipeline()\n",
        "    print(\"Optimized pipeline initialized with baseline components\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Performance Comparison and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PERFORMANCE COMPARISON:\n",
            "==================================================\n",
            "          Metric  Baseline  Optimized  Ground Truth\n",
            "    Completeness  0.941558   0.941558           1.0\n",
            "Overall Accuracy  0.292208   0.292208           1.0\n",
            "     Num Records 11.000000  11.000000          45.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n📊 SUMMARY:\n",
            "Ground Truth Records: 45\n",
            "Baseline Extracted: 11\n",
            "Optimized Extracted: 11\n",
            "Baseline Completeness: 94.16%\n",
            "Optimized Completeness: 94.16%\n"
          ]
        }
      ],
      "source": [
        "# Compare baseline vs optimized performance\n",
        "try:\n",
        "    baseline_completeness = baseline_evaluation.get('completeness', 0.0)\n",
        "    baseline_accuracy = baseline_evaluation.get('overall_accuracy', 0.0)\n",
        "    baseline_count = len(baseline_results) if 'baseline_results' in locals() else 0\n",
        "except:\n",
        "    baseline_completeness = 0.0\n",
        "    baseline_accuracy = 0.0\n",
        "    baseline_count = 0\n",
        "\n",
        "try:\n",
        "    optimized_completeness = optimized_evaluation.get('completeness', 0.0)\n",
        "    optimized_accuracy = optimized_evaluation.get('overall_accuracy', 0.0)\n",
        "    optimized_count = len(optimized_results) if 'optimized_results' in locals() else 0\n",
        "except:\n",
        "    optimized_completeness = 0.0\n",
        "    optimized_accuracy = 0.0\n",
        "    optimized_count = 0\n",
        "\n",
        "comparison_data = {\n",
        "    'Metric': ['Completeness', 'Overall Accuracy', 'Num Records'],\n",
        "    'Baseline': [baseline_completeness, baseline_accuracy, baseline_count],\n",
        "    'Optimized': [optimized_completeness, optimized_accuracy, optimized_count],\n",
        "    'Ground Truth': [1.0, 1.0, len(one_study_records)]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"PERFORMANCE COMPARISON:\")\n",
        "print(\"=\" * 50)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Performance metrics comparison\n",
        "metrics_data = comparison_df[comparison_df['Metric'].isin(['Completeness', 'Overall Accuracy'])]\n",
        "x = range(len(metrics_data))\n",
        "width = 0.25\n",
        "\n",
        "axes[0].bar([i - width for i in x], metrics_data['Baseline'], width, label='Baseline', alpha=0.8, color='lightblue')\n",
        "axes[0].bar(x, metrics_data['Optimized'], width, label='Optimized', alpha=0.8, color='orange')\n",
        "axes[0].bar([i + width for i in x], metrics_data['Ground Truth'], width, label='Ground Truth', alpha=0.8, color='green')\n",
        "\n",
        "axes[0].set_xlabel('Metrics')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Performance Comparison')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(metrics_data['Metric'])\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1.1)\n",
        "\n",
        "# Record count comparison\n",
        "record_data = ['Baseline', 'Optimized', 'Ground Truth']\n",
        "record_counts = [baseline_count, optimized_count, len(one_study_records)]\n",
        "\n",
        "bars = axes[1].bar(record_data, record_counts, alpha=0.8, color=['lightblue', 'orange', 'green'])\n",
        "axes[1].set_xlabel('Method')\n",
        "axes[1].set_ylabel('Number of Records')\n",
        "axes[1].set_title('Record Count Comparison')\n",
        "\n",
        "for i, v in enumerate(record_counts):\n",
        "    axes[1].text(i, v + 0.1, str(v), ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\\\n📊 SUMMARY:\")\n",
        "print(f\"Ground Truth Records: {len(one_study_records)}\")\n",
        "print(f\"Baseline Extracted: {baseline_count}\")\n",
        "print(f\"Optimized Extracted: {optimized_count}\")\n",
        "print(f\"Baseline Completeness: {baseline_completeness:.2%}\")\n",
        "print(f\"Optimized Completeness: {optimized_completeness:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save Results and Export Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save extracted results\n",
        "output_dir = Path(\"/nlp/data/karthik9/Sprint1/Dental/dspy_output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save baseline results\n",
        "if 'baseline_results' in locals() and baseline_results:\n",
        "    with open(output_dir / \"baseline_extracted_records.json\", 'w') as f:\n",
        "        json.dump(baseline_results, f, indent=2)\n",
        "    print(\"✅ Saved baseline results\")\n",
        "\n",
        "# Save optimized results\n",
        "if 'optimized_results' in locals() and optimized_results:\n",
        "    with open(output_dir / \"optimized_extracted_records.json\", 'w') as f:\n",
        "        json.dump(optimized_results, f, indent=2)\n",
        "    print(\"✅ Saved optimized results\")\n",
        "\n",
        "# Save evaluation results\n",
        "evaluation_summary = {\n",
        "    \"baseline_evaluation\": baseline_evaluation if 'baseline_evaluation' in locals() else {},\n",
        "    \"optimized_evaluation\": optimized_evaluation if 'optimized_evaluation' in locals() else {},\n",
        "    \"ground_truth_count\": len(one_study_records),\n",
        "    \"comparison_summary\": comparison_data if 'comparison_data' in locals() else {}\n",
        "}\n",
        "\n",
        "with open(output_dir / \"/nlp/data/karthik9/Sprint1/Dental/Data/ev_jsons/do_evaluation_results.json\", 'w') as f:\n",
        "    json.dump(evaluation_summary, f, indent=2)\n",
        "\n",
        "# Save ground truth for reference\n",
        "with open(output_dir / \"ground_truth_1.json\", 'w') as f:\n",
        "    json.dump(one_study_records, f, indent=2)\n",
        "\n",
        "print(f\"\\\\n📁 Results saved to {output_dir}\")\n",
        "print(\"\\\\nFiles created:\")\n",
        "for file in output_dir.glob(\"*\"):\n",
        "    print(f\"  - {file.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Production Pipeline Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_medical_data(markdown_content: str, use_optimized: bool = True) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Production function for extracting medical data from markdown.\n",
        "    \n",
        "    Args:\n",
        "        markdown_content: Full markdown content of medical research paper\n",
        "        use_optimized: Whether to use optimized pipeline (default: True)\n",
        "    \n",
        "    Returns:\n",
        "        List of structured records matching dichotomous_outcomes.json format\n",
        "    \"\"\"\n",
        "    pipeline = optimized_pipeline if (use_optimized and 'optimized_pipeline' in locals()) else extraction_pipeline\n",
        "    \n",
        "    try:\n",
        "        prediction = pipeline(markdown_content)\n",
        "        # Extract the actual records from the DSPy Prediction object\n",
        "        return prediction.extracted_records if hasattr(prediction, 'extracted_records') else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error in extraction: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def batch_extract_medical_data(json_files: List[str], output_file: str) -> None:\n",
        "    \"\"\"Batch extraction from multiple JSON files.\n",
        "    \n",
        "    Args:\n",
        "        json_files: List of paths to JSON files with markdown content\n",
        "        output_file: Path to save combined results\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    \n",
        "    for file_path in json_files:\n",
        "        print(f\"Processing {file_path}...\")\n",
        "        \n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = safe_json_parse(f)\n",
        "            \n",
        "            markdown_content = data.get('marker', {}).get('markdown', '')\n",
        "            \n",
        "            if markdown_content:\n",
        "                results = extract_medical_data(markdown_content)\n",
        "                all_results.extend(results)\n",
        "                print(f\"  Extracted {len(results)} records\")\n",
        "            else:\n",
        "                print(f\"  No markdown content found\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing {file_path}: {e}\")\n",
        "    \n",
        "    # Save combined results\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    \n",
        "    print(f\"\\\\nBatch extraction completed. Total records: {len(all_results)}\")\n",
        "    print(f\"Results saved to: {output_file}\")\n",
        "\n",
        "\n",
        "def quick_test_extraction(file_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"Quick test function for a single file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = safe_json_parse(f)\n",
        "        \n",
        "        markdown_content = data.get('marker', {}).get('markdown', '')\n",
        "        \n",
        "        if not markdown_content:\n",
        "            return {\"error\": \"No markdown content found\"}\n",
        "        \n",
        "        results = extract_medical_data(markdown_content)\n",
        "        evaluation = evaluator.evaluate(results)\n",
        "        \n",
        "        return {\n",
        "            \"file_path\": file_path,\n",
        "            \"extracted_records\": len(results),\n",
        "            \"completeness\": evaluation.get(\"completeness\", 0.0),\n",
        "            \"sample_record\": results[0] if results else None\n",
        "        }\n",
        "    \n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "print(\"Production functions defined:\")\n",
        "print(\"  - extract_medical_data(markdown_content, use_optimized=True)\")\n",
        "print(\"  - batch_extract_medical_data(json_files, output_file)\")\n",
        "print(\"  - quick_test_extraction(file_path)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Final Summary and Usage Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"🎉 DSPy 3.0.3 Medical Data Extraction Pipeline - COMPLETE! 🎉\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\\\n📊 PIPELINE SUMMARY:\")\n",
        "print(f\"  • Framework: DSPy 3.0.3 with ChainOfThought reasoning\")\n",
        "print(f\"  • Source Data: Medical research markdown (One Specific study)\")\n",
        "print(f\"  • Target Format: Dichotomous outcomes JSON structure\")\n",
        "print(f\"  • Ground Truth Records: {len(one_study_records)}\")\n",
        "\n",
        "print(\"\\\\n🔧 COMPONENTS IMPLEMENTED:\")\n",
        "print(\"  ✅ DSPy Signatures for medical data extraction\")\n",
        "print(\"  ✅ Modular pipeline with error handling\")\n",
        "print(\"  ✅ Baseline and optimized pipelines\")\n",
        "print(\"  ✅ Comprehensive evaluation framework\")\n",
        "print(\"  ✅ BootstrapFewShot optimizer\")\n",
        "print(\"  ✅ Performance visualization\")\n",
        "print(\"  ✅ Production-ready functions\")\n",
        "print(\"  ✅ Batch processing capabilities\")\n",
        "\n",
        "print(\"\\\\n🎯 KEY FEATURES:\")\n",
        "print(\"  • Structured extraction from medical research markdown\")\n",
        "print(\"  • Multi-intervention and multi-outcome support\")\n",
        "print(\"  • DSPy 3.0.3 optimization with rollout_id support\")\n",
        "print(\"  • JSON output with validation\")\n",
        "print(\"  • Comprehensive error handling\")\n",
        "\n",
        "print(\"\\\\n📁 OUTPUT FILES LOCATION:\")\n",
        "print(f\"  {output_dir}\")\n",
        "\n",
        "print(\"\\\\n🚀 USAGE EXAMPLES:\")\n",
        "print(\"\\\\n1. Extract from single markdown content:\")\n",
        "print(\"   results = extract_medical_data(markdown_content)\")\n",
        "\n",
        "print(\"\\\\n2. Batch process multiple files:\")\n",
        "print(\"   file_list = ['file1.json', 'file2.json']\")\n",
        "print(\"   batch_extract_medical_data(file_list, 'output.json')\")\n",
        "\n",
        "print(\"\\\\n3. Quick test a single file:\")\n",
        "print(\"   test_result = quick_test_extraction('/path/to/file.json')\")\n",
        "\n",
        "print(\"\\\\n🔄 NEXT STEPS:\")\n",
        "print(\"  1. Add your OpenAI API key to run the extraction\")\n",
        "print(\"  2. Test on additional medical papers\")\n",
        "print(\"  3. Fine-tune with more training examples\")\n",
        "print(\"  4. Scale to batch processing\")\n",
        "print(\"  5. Deploy as production service\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"Ready for production use! Add your API key and run the cells above.\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "topics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
