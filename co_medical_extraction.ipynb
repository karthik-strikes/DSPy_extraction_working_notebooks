{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSPy 3.0.3 Medical Data Extraction Pipeline\n",
        "\n",
        "This notebook demonstrates a comprehensive data extraction pipeline using DSPy 3.0.3 to extract structured dichotomous outcomes from medical research papers in markdown format.\n",
        "\n",
        "## Objective\n",
        "Extract structured data from medical research markdown  into the target format matching `dichotomous_outcomes.json`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dspy-ai==3.0.3 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (3.0.3)\n",
            "Requirement already satisfied: openai in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (1.102.0)\n",
            "Requirement already satisfied: pandas in /lcars/home/k/karthik9/.local/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (2.2.5)\n",
            "Requirement already satisfied: scikit-learn in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: sentence-transformers in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (4.0.2)\n",
            "Requirement already satisfied: dspy>=3.0.3 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy-ai==3.0.3) (3.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /lcars/home/k/karthik9/.local/lib/python3.11/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /lcars/home/k/karthik9/.local/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /lcars/home/k/karthik9/.local/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /lcars/home/k/karthik9/.local/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from sentence-transformers) (4.48.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from sentence-transformers) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from sentence-transformers) (0.31.1)\n",
            "Requirement already satisfied: idna>=2.8 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: backoff>=2.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (2.2.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (2024.11.6)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (3.10.18)\n",
            "Requirement already satisfied: requests>=2.31.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (2.32.3)\n",
            "Requirement already satisfied: optuna>=3.4.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (4.4.0)\n",
            "Requirement already satisfied: magicattr>=0.1.6 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (0.1.6)\n",
            "Requirement already satisfied: litellm>=1.64.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (1.75.5.post1)\n",
            "Requirement already satisfied: diskcache>=5.6.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (5.6.3)\n",
            "Requirement already satisfied: json-repair>=0.30.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (0.49.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (9.1.2)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (0.0.8)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (3.1.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (14.0.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from dspy>=3.0.3->dspy-ai==3.0.3) (3.5.0)\n",
            "Requirement already satisfied: gepa==0.0.7 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from gepa[dspy]==0.0.7->dspy>=3.0.3->dspy-ai==3.0.3) (0.0.7)\n",
            "Requirement already satisfied: certifi in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from triton==3.3.0->torch>=1.11.0->sentence-transformers) (80.9.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (3.11.18)\n",
            "Requirement already satisfied: click in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (8.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (8.7.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (4.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (1.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai==3.0.3) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai==3.0.3) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai==3.0.3) (2.0.41)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from requests>=2.31.0->dspy>=3.0.3->dspy-ai==3.0.3) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from requests>=2.31.0->dspy>=3.0.3->dspy-ai==3.0.3) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from rich>=13.7.1->dspy>=3.0.3->dspy-ai==3.0.3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /lcars/home/k/karthik9/.local/lib/python3.11/site-packages (from rich>=13.7.1->dspy>=3.0.3->dspy-ai==3.0.3) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (1.20.0)\n",
            "Requirement already satisfied: Mako in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.3->dspy-ai==3.0.3) (1.3.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (3.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai==3.0.3) (0.27.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.3->dspy-ai==3.0.3) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.3->dspy-ai==3.0.3) (3.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install DSPy 3.0.3 if not already installed\n",
        "%pip install dspy-ai==3.0.3 openai pandas numpy scikit-learn matplotlib seaborn sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy version: 3.0.3\n"
          ]
        }
      ],
      "source": [
        "import dspy\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "import tiktoken\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "import hashlib\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import diskcache as dc\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Print DSPy version\n",
        "print(f\"DSPy version: {dspy.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure DSPy Language Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language model configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Set your API key (uncomment and add your key)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "\n",
        "# Configure DSPy with OpenAI GPT-4o-mini for cost efficiency\n",
        "lm = dspy.LM('gemini/gemini-2.5-pro', max_tokens=20000, temperature=1.0)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"Language model configured successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Markdown content length: 45025 characters\n",
            "Token count: 11849\n",
            "Target data contains 723 records\n"
          ]
        }
      ],
      "source": [
        "# Load source file\n",
        "source_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2518_Kellstein_md/2518_Kellstein_md.json\"\n",
        "target_file = \"/nlp/data/karthik9/Sprint1/Dental/Data/jsons/continuous_outcomes.json\"\n",
        "\n",
        "with open(source_file, 'r') as f:\n",
        "    source_data = json.load(f)\n",
        "\n",
        "with open(target_file, 'r') as f:\n",
        "    target_data = json.load(f)\n",
        "\n",
        "# Extract markdown content\n",
        "markdown_content = source_data['marker']['markdown']\n",
        "\n",
        "# Use OpenAI tokenizer (cl100k_base is the same one GPT-4/4o/5 use)\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "tokens = encoding.encode(markdown_content)\n",
        "\n",
        "print(f\"Markdown content length: {len(markdown_content)} characters\")\n",
        "print(f\"Token count: {len(tokens)}\")\n",
        "print(f\"Target data contains {len(target_data)} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25 records in target data\n",
            "\n",
            "Example target record structure:\n",
            "Ref_ID: 2518.0\n",
            "First_Author: Kellstein\n",
            "Trial_Name: \n",
            "Population: 2\n",
            "Intervention_Code: 1\n",
            "Intervention_Description: Ibuprofen 200 mg/Acetaminophen 500 mg\n",
            "Outcome_Type: 1\n",
            "Outcome_Other_Specify: \n",
            "Pain_Relief_Scale_Name: \n",
            "Pain_Relief_Scale_Type: categorical, ordinal\n",
            "Pain_Relief_Scale_Range: 0-4\n",
            "Pain_Relief_Scale_Questions: 0 = none, 1 = a little, 2 = some, 3 = a lot, and 4 = complete\n",
            "Global_Efficacy_Scale_Name: \n",
            "Global_Efficacy_Scale_Type: \n",
            "Global_Efficacy_Scale_Range: \n",
            "Global_Efficacy_Scale_Questions: \n",
            "TOTPAR_Definition: \n",
            "TOTPAR_Scale_Name: \n",
            "TOTPAR_Scale_Type: \n",
            "TOTPAR_Scale_Range: \n",
            "TOTPAR_Scale_Questions: \n",
            "SPID_Definition: \n",
            "SPID_Scale_Name: \n",
            "SPID_Scale_Type: \n",
            "SPID_Scale_Range: \n",
            "SPID_Scale_Questions: \n",
            "N_Analyzed: 90\n",
            "Central_Tendency_Type: 1\n",
            "Central_Tendency_Value: 2.47\n",
            "Variability_Type: NR\n",
            "Variability_Value: NR\n",
            "Other_Results: \n",
            "Comments: Webplot from fig 2; During that time, study participants provided self-ratings of pain severity (on both the categorical PSR4 and numerical PSR11 scales as described above) and pain relief, using a 5-point categorical pain relief rating (PRR) scale (0 = none, 1 = a little, 2 = some, 3 = a lot, and 4 = complete). The PRR self-assessments took place at 0.25, 0.5, 1, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12 h post-treatment, after taking study medication, immediately before taking rescue medication, or at time of study withdrawal (if either occurred).\n",
            "filename: 2518_Kellstein\n"
          ]
        }
      ],
      "source": [
        "# Filter target data for  study to understand expected output\n",
        "one_study_records = [record for record in target_data if record.get('filename') == '2518_Kellstein']\n",
        "print(f\"Found {len(one_study_records)} records in target data\")\n",
        "\n",
        "# Show example record structure\n",
        "if one_study_records:\n",
        "    print(\"\\nExample target record structure:\")\n",
        "    for key, value in one_study_records[0].items():\n",
        "        print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DSPy Signature Definitions\n",
        "\n",
        "We'll define specialized signatures for each extraction task:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExtractStudyMetadata(dspy.Signature):\n",
        "    \"\"\"Extract basic study metadata from medical research paper markdown.\n",
        "    \n",
        "    This extracts core identifying information about the study including reference ID,\n",
        "    author information, trial name, and population type for pain management research.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    \n",
        "    first_author: str = dspy.OutputField(\n",
        "        desc=\"Last name of the first author (e.g., 'Cooper', 'Seymour'). Extract only the surname.\"\n",
        "    )\n",
        "    \n",
        "    \n",
        "    population_code: str = dspy.OutputField(\n",
        "        desc=\"Numeric code representing the study population type. Codes: 1=simple tooth extraction, 2=surgical tooth extraction (third molar/wisdom teeth), 3=surgical tooth extraction (other teeth), 4=pulpitis or its complications. Can be multiple codes separated by commas (e.g., '2, 3')\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractInterventions(dspy.Signature):\n",
        "    \"\"\"Extract intervention details from medical research paper markdown.\n",
        "    \n",
        "    This extracts information about pain management interventions including\n",
        "    intervention codes and detailed descriptions with dosages.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    \n",
        "    interventions_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string containing list of interventions. Each intervention object must have:\n",
        "        - intervention_code (integer): Numeric code 1-11 where:\n",
        "          1=Ibuprofen 200-400mg + Acetaminophen 500-1000mg\n",
        "          2=Oxycodone 5mg or Codeine 60mg  \n",
        "          3=Acetaminophen 650mg + Oxycodone 10mg\n",
        "          4=Ibuprofen 200mg + Hydrocodone 5mg\n",
        "          5=Hydrocodone 5mg + Acetaminophen 300-325mg\n",
        "          6=Ibuprofen 400mg (fast acting or acid)\n",
        "          7=Tramadol 37.5mg + Acetaminophen 325mg\n",
        "          8=Acetaminophen 500-1000mg\n",
        "          9=Acetaminophen 600-650mg + Codeine 60mg\n",
        "          10=Naproxen 400-440mg\n",
        "          11=Placebo/no treatment\n",
        "        - intervention_description (string): Full description with medication name and exact dose (e.g., \"Ibuprofen 400 mg\", \"Paracetamol 500 mg\", \"NA\" for placebo)\n",
        "        \n",
        "        Example: [{\"intervention_code\": 6, \"intervention_description\": \"Ibuprofen 400 mg\"}, {\"intervention_code\": 8, \"intervention_description\": \"Paracetamol 500 mg\"}]\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractOutcomeTypes(dspy.Signature):\n",
        "    \"\"\"Identify which types of continuous outcomes are reported in the medical research paper.\n",
        "    \n",
        "    This focuses on identifying what outcomes are present before extracting detailed data.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention to check outcomes for\")\n",
        "    \n",
        "    outcome_types_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string containing list of outcome types present for this intervention. Each outcome type object must have:\n",
        "        - outcome_code (integer): Outcome type code where:\n",
        "          1=Pain relief at 6 hours\n",
        "          2=Pain relief at 7 hours  \n",
        "          3=Pain relief at 8 hours\n",
        "          4=Pain relief at 48 hours\n",
        "          5=TOTPAR over 6 hours\n",
        "          6=TOTPAR over 7 hours\n",
        "          7=TOTPAR over 8 hours\n",
        "          8=TOTPAR over 48 hours\n",
        "          9=SPID over 6 hours\n",
        "          10=SPID over 7 hours\n",
        "          11=SPID over 8 hours\n",
        "          12=SPID over 12 hours\n",
        "          13=Global subjective efficacy ratings at 6 hours\n",
        "          14=Global subjective efficacy ratings at 7 hours\n",
        "          15=Global subjective efficacy ratings at 8 hours\n",
        "          16=Global subjective efficacy ratings at 48 hours\n",
        "        - outcome_category (string): Category of outcome (\"pain_relief\", \"totpar\", \"spid\", \"global_efficacy\", \"other\")\n",
        "        - time_point (string): Time point for this outcome (e.g., \"6 hours\", \"7 hours\", \"8 hours\", \"48 hours\")\n",
        "        - outcome_other_specify (string): If outcome_code=17, specify what the other outcome is. Use \"NA\" otherwise.\n",
        "        \n",
        "        Example: [\n",
        "          {\"outcome_code\": 1, \"outcome_category\": \"pain_relief\", \"time_point\": \"6 hours\", \"outcome_other_specify\": \"NA\"},\n",
        "          {\"outcome_code\": 13, \"outcome_category\": \"global_efficacy\", \"time_point\": \"6 hours\", \"outcome_other_specify\": \"NA\"}\n",
        "        ]\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractPainReliefDetails(dspy.Signature):\n",
        "    \"\"\"Extract detailed pain relief measurement information for pain relief outcomes (codes 1-4).\n",
        "    \n",
        "    This extracts comprehensive details about how pain relief was measured and assessed.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention for this outcome\")\n",
        "    outcome_code: int = dspy.InputField(desc=\"Pain relief outcome code (1-4)\")\n",
        "    time_point: str = dspy.InputField(desc=\"Time point (e.g., '6 hours', '7 hours', '8 hours', '48 hours')\")\n",
        "    \n",
        "    pain_relief_details_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string with comprehensive pain relief measurement details:\n",
        "        - type_of_scale_used (string): Type of scale used to collect this data (e.g., \"ordinal, categorical\", \"VAS\", \"numerical rating scale\", \"Likert scale\")\n",
        "        - name_of_scale_used (string): Specific name of the scale used (e.g., \"5-point categorical pain relief scale\", \"Visual Analog Scale\", \"Categorical Pain Relief Scale\")\n",
        "        - range_of_scale_used (string): Range of the scale (e.g., \"0-4\", \"0-10\", \"1-5\", \"0-100mm\")\n",
        "        - copy_paste_scale (string): Exact verbatim description of the scale as written in the paper (e.g., \"0=no relief, 1=a little relief, 2=some relief, 3=a lot of relief, 4=complete relief\")\n",
        "        - all_scale_responses (string): All possible response options/categories listed verbatim (e.g., \"complete (4), a lot (3), some (2), a little (1), none (0)\")\n",
        "        - extraction_notes (string): Source location and extraction methodology\n",
        "        - additional_details (string): Any additional relevant information about the pain relief assessment\n",
        "        \n",
        "        Example: {\"type_of_scale_used\": \"ordinal, categorical\", \"name_of_scale_used\": \"5-point categorical pain relief scale\", \"range_of_scale_used\": \"0-4\", \"copy_paste_scale\": \"patients recorded level of pain relief as complete (4), a lot (3), some (2), a little (1), or none (0)\", \"all_scale_responses\": \"complete (4), a lot (3), some (2), a little (1), none (0)\", \"extraction_notes\": \"From methods section, Figure II caption\", \"additional_details\": \"Pain relief assessed hourly for 6 hours post-dose\"}\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractGlobalEfficacyDetails(dspy.Signature):\n",
        "    \"\"\"Extract detailed global subjective efficacy measurement information for global efficacy outcomes (codes 13-16).\n",
        "    \n",
        "    This extracts comprehensive details about how global subjective efficacy was measured and assessed.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention for this outcome\")\n",
        "    outcome_code: int = dspy.InputField(desc=\"Global efficacy outcome code (13-16)\")\n",
        "    time_point: str = dspy.InputField(desc=\"Time point (e.g., '6 hours', '7 hours', '8 hours', '48 hours')\")\n",
        "    \n",
        "    global_efficacy_details_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string with comprehensive global subjective efficacy measurement details:\n",
        "        - type_of_scale_used (string): Type of scale used to collect this data (e.g., \"ordinal, categorical\", \"Likert scale\", \"VAS\")\n",
        "        - name_of_scale_used (string): Specific name of the scale used (e.g., \"Global evaluation scale\", \"Patient global assessment\", \"Overall medication assessment\")\n",
        "        - range_of_scale_used (string): Range of the scale (e.g., \"1-5\", \"0-4\", \"0-10\", \"1-4\")\n",
        "        - copy_paste_scale (string): Exact verbatim description of the scale as written in the paper\n",
        "        - all_scale_responses (string): All possible response options/categories listed verbatim (e.g., \"excellent, very good, good, fair, poor\")\n",
        "        - extraction_notes (string): Source location and extraction methodology\n",
        "        - additional_details (string): Any additional relevant information about the global efficacy assessment\n",
        "        \n",
        "        Example: {\"type_of_scale_used\": \"ordinal, categorical\", \"name_of_scale_used\": \"Patient global assessment of medication\", \"range_of_scale_used\": \"1-5\", \"copy_paste_scale\": \"patients recorded their overall impression of the study medication as excellent (1), very good (2), good (3), fair (4), or poor (5)\", \"all_scale_responses\": \"excellent (1), very good (2), good (3), fair (4), poor (5)\", \"extraction_notes\": \"From methods section and Table 3\", \"additional_details\": \"Assessment performed at end of study period\"}\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractTOTPARDetails(dspy.Signature):\n",
        "    \"\"\"Extract detailed TOTPAR measurement information for TOTPAR outcomes (codes 5-8).\n",
        "    \n",
        "    This extracts comprehensive details about how TOTPAR was calculated and the underlying scales used.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention for this outcome\")\n",
        "    outcome_code: int = dspy.InputField(desc=\"TOTPAR outcome code (5-8)\")\n",
        "    time_point: str = dspy.InputField(desc=\"Time point (e.g., '6 hours', '7 hours', '8 hours', '48 hours')\")\n",
        "    \n",
        "    totpar_details_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string with comprehensive TOTPAR measurement details:\n",
        "        - copy_paste_scale (string): Exact verbatim description of the underlying pain relief scale used for TOTPAR calculation\n",
        "        - definition_of_totpar (string): Definition of TOTPAR as indicated by study authors (exact quote from paper)\n",
        "        - name_of_scale_used (string): Name of the underlying scale used for TOTPAR calculation\n",
        "        - type_of_scale_used (string): Type of underlying scale (e.g., \"ordinal, categorical\", \"VAS\", \"numerical rating\")\n",
        "        - range_of_scale_used (string): Range of the underlying scale used for TOTPAR calculation\n",
        "        - copy_paste_scale_questions (string): Copy/paste the scale question(s) and all response options used for pain relief assessment\n",
        "        - all_scale_responses (string): All possible responses for the underlying pain relief scale\n",
        "        - calculation_method (string): How TOTPAR was calculated (e.g., \"sum of hourly pain relief scores\", \"area under curve\")\n",
        "        - time_points_included (string): Specific time points included in TOTPAR calculation\n",
        "        - extraction_notes (string): Source location and extraction methodology\n",
        "        - additional_details (string): Any additional relevant information about TOTPAR methodology\n",
        "        \n",
        "        Example: {\"copy_paste_scale\": \"patients recorded level of pain relief as complete (4), a lot (3), some (2), a little (1), or none (0)\", \"definition_of_totpar\": \"The sum of total pain relief (TOTPAR) scores was calculated by adding the pain relief scores at each time point\", \"name_of_scale_used\": \"5-point categorical pain relief scale\", \"type_of_scale_used\": \"ordinal, categorical\", \"range_of_scale_used\": \"0-4\", \"copy_paste_scale_questions\": \"How much pain relief have you experienced? Complete relief (4), A lot of relief (3), Some relief (2), A little relief (1), No relief (0)\", \"all_scale_responses\": \"complete (4), a lot (3), some (2), a little (1), none (0)\", \"calculation_method\": \"sum of hourly pain relief scores from 0-6 hours\", \"time_points_included\": \"0.5, 1, 1.5, 2, 3, 4, 5, 6 hours\", \"extraction_notes\": \"From methods section and statistical analysis\", \"additional_details\": \"TOTPAR calculated for 6-hour period post-dose\"}\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractSPIDDetails(dspy.Signature):\n",
        "    \"\"\"Extract detailed SPID measurement information for SPID outcomes (codes 9-12).\n",
        "    \n",
        "    This extracts comprehensive details about how SPID was calculated and the underlying scales used.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention for this outcome\")\n",
        "    outcome_code: int = dspy.InputField(desc=\"SPID outcome code (9-12)\")\n",
        "    time_point: str = dspy.InputField(desc=\"Time point (e.g., '6 hours', '7 hours', '8 hours', '48 hours')\")\n",
        "    \n",
        "    spid_details_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string with comprehensive SPID measurement details:\n",
        "        - copy_paste_scale (string): Exact verbatim description of the underlying pain intensity scale used for SPID calculation\n",
        "        - definition_of_spid (string): Definition of SPID as indicated by study authors (exact quote from paper)\n",
        "        - name_of_scale_used (string): Name of the underlying scale used for SPID calculation\n",
        "        - type_of_scale_used (string): Type of underlying scale (e.g., \"VAS\", \"numerical rating scale\", \"categorical\")\n",
        "        - range_of_scale_used (string): Range of the underlying scale used for SPID calculation\n",
        "        - copy_paste_scale_questions (string): Copy/paste the scale question(s) and all response options used for pain intensity assessment\n",
        "        - all_scale_responses (string): All possible responses for the underlying pain intensity scale\n",
        "        - calculation_method (string): How SPID was calculated (e.g., \"sum of pain intensity differences\", \"area under curve\")\n",
        "        - time_points_included (string): Specific time points included in SPID calculation\n",
        "        - extraction_notes (string): Source location and extraction methodology\n",
        "        - additional_details (string): Any additional relevant information about SPID methodology\n",
        "        \n",
        "        Example: {\"copy_paste_scale\": \"patients rated pain intensity on a 0-10 numerical rating scale where 0=no pain and 10=worst possible pain\", \"definition_of_spid\": \"The sum of pain intensity differences (SPID) scores were calculated by adding the pain intensity difference scores at each time point\", \"name_of_scale_used\": \"11-point numerical rating scale\", \"type_of_scale_used\": \"numerical rating scale\", \"range_of_scale_used\": \"0-10\", \"copy_paste_scale_questions\": \"Rate your current pain intensity: 0=no pain, 1-3=mild pain, 4-6=moderate pain, 7-10=severe pain\", \"all_scale_responses\": \"0=no pain, 1=minimal, 2=mild, 3=mild, 4=moderate, 5=moderate, 6=moderate, 7=severe, 8=severe, 9=severe, 10=worst possible\", \"calculation_method\": \"sum of hourly pain intensity difference scores\", \"time_points_included\": \"0.5, 1, 1.5, 2, 3, 4, 5, 6 hours\", \"extraction_notes\": \"From methods section and Figure 1\", \"additional_details\": \"Pain intensity differences calculated as baseline minus post-dose scores\"}\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# class ExtractOtherOutcomeDetails(dspy.Signature):\n",
        "#     \"\"\"Extract detailed measurement information for other continuous outcomes (code 17).\n",
        "    \n",
        "#     This extracts comprehensive details about how other outcomes were measured.\n",
        "#     \"\"\"\n",
        "    \n",
        "#     markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "#     intervention_description: str = dspy.InputField(desc=\"Specific intervention for this outcome\")\n",
        "#     outcome_other_specify: str = dspy.InputField(desc=\"Specific description of the other outcome\")\n",
        "    \n",
        "#     other_outcome_details_json: str = dspy.OutputField(\n",
        "#         desc=\"\"\"JSON string with comprehensive other outcome measurement details:\n",
        "#         - outcome_name (string): Name of the specific other outcome\n",
        "#         - type_of_scale_used (string): Type of scale used to collect this data\n",
        "#         - name_of_scale_used (string): Specific name of the scale used\n",
        "#         - range_of_scale_used (string): Range of the scale\n",
        "#         - copy_paste_scale (string): Exact verbatim description of the scale as written in the paper\n",
        "#         - all_scale_responses (string): All possible response options/categories listed verbatim\n",
        "#         - measurement_method (string): How the outcome was measured\n",
        "#         - time_points (string): When the outcome was assessed\n",
        "#         - extraction_notes (string): Source location and extraction methodology\n",
        "#         - additional_details (string): Any additional relevant information\n",
        "        \n",
        "#         Example: {\"outcome_name\": \"Time to meaningful pain relief\", \"type_of_scale_used\": \"time measurement\", \"name_of_scale_used\": \"stopwatch timing\", \"range_of_scale_used\": \"0-360 minutes\", \"copy_paste_scale\": \"time from first dose to when patient reported meaningful pain relief\", \"all_scale_responses\": \"continuous time measurement in minutes\", \"measurement_method\": \"patient-reported time to first meaningful relief\", \"time_points\": \"continuously monitored for 6 hours\", \"extraction_notes\": \"From Table 4 and methods\", \"additional_details\": \"Meaningful relief defined as 50% reduction in pain intensity\"}\"\"\"\n",
        "#     )\n",
        "\n",
        "\n",
        "class ExtractStatisticalData(dspy.Signature):\n",
        "    \"\"\"Extract statistical measures and numerical data for a specific outcome.\n",
        "    \n",
        "    This extracts the quantitative results including sample sizes, central tendency, and variability measures.\n",
        "    \"\"\"\n",
        "    \n",
        "    markdown_content: str = dspy.InputField(desc=\"Full markdown content of the medical research paper\")\n",
        "    intervention_description: str = dspy.InputField(desc=\"Specific intervention for this outcome\")\n",
        "    outcome_code: int = dspy.InputField(desc=\"Specific outcome code (1-17)\")\n",
        "    time_point: str = dspy.InputField(desc=\"Time point for this outcome\")\n",
        "    \n",
        "    statistical_data_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"JSON string with statistical measures for this specific outcome:\n",
        "        - n_analyzed (integer): Number of participants analyzed for this outcome\n",
        "        - measure_of_central_tendency (string): Type of central tendency reported (e.g., \"mean\", \"median\", \"mode\")\n",
        "        - central_tendency_value (float): Actual value of central tendency measure. Use null if not reported.\n",
        "        - measure_of_variability (string): Type of variability measure (e.g., \"SD\", \"SE\", \"IQR\", \"95% CI\", \"NR\")\n",
        "        - variability_value (string): Value of variability measure (may include ranges like \"1.2-2.4\" or \"NR\")\n",
        "        - other_reporting_method (string): If other reporting methods are used, include results here. Use \"NA\" if standard reporting.\n",
        "        - data_source (string): Source of the data (e.g., \"Table 1\", \"Figure II\", \"Supplementary materials\")\n",
        "        - extraction_method (string): How data was extracted (e.g., \"direct from table\", \"digitized from figure\", \"calculated\")\n",
        "        \n",
        "        Example: {\"n_analyzed\": 37, \"measure_of_central_tendency\": \"mean\", \"central_tendency_value\": 1.51, \"measure_of_variability\": \"SD\", \"variability_value\": \"1.2\", \"other_reporting_method\": \"NA\", \"data_source\": \"Figure II\", \"extraction_method\": \"Webplot digitizer used to extract mean from graph\"}\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "class StructureCompleteRecord(dspy.Signature):\n",
        "    \"\"\"Structure all extracted data into the final comprehensive CSV format.\n",
        "    \n",
        "    This combines study metadata, intervention details, outcome types, outcome details, \n",
        "    and statistical data into the standardized format with all required fields.\n",
        "    \"\"\"\n",
        "    \n",
        "    study_metadata_json: str = dspy.InputField(desc=\"Study metadata with  first_author,  population_code\")\n",
        "    intervention_json: str = dspy.InputField(desc=\"Intervention details with intervention_code, intervention_description\")\n",
        "    outcome_type_json: str = dspy.InputField(desc=\"Outcome type with outcome_code, outcome_category, time_point\")\n",
        "    outcome_details_json: str = dspy.InputField(desc=\"Detailed outcome information based on category\")\n",
        "    statistical_data_json: str = dspy.InputField(desc=\"Statistical measures and numerical data\")\n",
        "    \n",
        "    final_record_json: str = dspy.OutputField(\n",
        "        desc=\"\"\"Complete structured record as JSON string with exactly these fields:\n",
        "     \n",
        "        - First_Author (string): First author last name  \n",
        "       \n",
        "        - Population (string): Population code (can be multiple like \"2, 3\")\n",
        "        - Intervention_Code (integer): Intervention code (1-11)\n",
        "        - Intervention_Description (string): Full intervention description with dose\n",
        "        - Outcome_Code (integer): Outcome type code (1-17)\n",
        "        - Outcome_Other_Specify (string): Specific outcome description if code=17, otherwise \"NA\"\n",
        "        \n",
        "        PAIN RELIEF FIELDS (fill only for codes 1-4, \"NA\" for others):\n",
        "        - Pain_Relief_Type_Of_Scale (string): Type of scale used for pain relief\n",
        "        - Pain_Relief_Name_Of_Scale (string): Name of scale used for pain relief\n",
        "        - Pain_Relief_Range_Of_Scale (string): Range of scale used for pain relief\n",
        "        - Pain_Relief_Copy_Paste_Scale (string): Verbatim scale description for pain relief\n",
        "        - Pain_Relief_All_Responses (string): All response options for pain relief scale\n",
        "        \n",
        "        GLOBAL EFFICACY FIELDS (fill only for codes 13-16, \"NA\" for others):\n",
        "        - Global_Efficacy_Type_Of_Scale (string): Type of scale used for global efficacy\n",
        "        - Global_Efficacy_Name_Of_Scale (string): Name of scale used for global efficacy\n",
        "        - Global_Efficacy_Range_Of_Scale (string): Range of scale used for global efficacy\n",
        "        - Global_Efficacy_Copy_Paste_Scale (string): Verbatim scale description for global efficacy\n",
        "        - Global_Efficacy_All_Responses (string): All response options for global efficacy scale\n",
        "        \n",
        "        TOTPAR FIELDS (fill only for codes 5-8, \"NA\" for others):\n",
        "        - TOTPAR_Copy_Paste_Scale (string): Verbatim underlying scale for TOTPAR\n",
        "        - TOTPAR_Definition (string): Definition of TOTPAR by study authors\n",
        "        - TOTPAR_Name_Of_Scale (string): Name of underlying scale for TOTPAR\n",
        "        - TOTPAR_Type_Of_Scale (string): Type of underlying scale for TOTPAR\n",
        "        - TOTPAR_Range_Of_Scale (string): Range of underlying scale for TOTPAR\n",
        "        - TOTPAR_Copy_Paste_Questions (string): Scale questions and responses for TOTPAR\n",
        "        - TOTPAR_All_Responses (string): All responses for underlying TOTPAR scale\n",
        "        \n",
        "        SPID FIELDS (fill only for codes 9-12, \"NA\" for others):\n",
        "        - SPID_Copy_Paste_Scale (string): Verbatim underlying scale for SPID\n",
        "        - SPID_Definition (string): Definition of SPID by study authors\n",
        "        - SPID_Name_Of_Scale (string): Name of underlying scale for SPID\n",
        "        - SPID_Type_Of_Scale (string): Type of underlying scale for SPID\n",
        "        - SPID_Range_Of_Scale (string): Range of underlying scale for SPID\n",
        "        - SPID_Copy_Paste_Questions (string): Scale questions and responses for SPID\n",
        "        - SPID_All_Responses (string): All responses for underlying SPID scale\n",
        "        \n",
        "        STATISTICAL MEASURES:\n",
        "        - N_Analyzed (integer): Number of participants analyzed\n",
        "        - Measure_Of_Central_Tendency (string): Type of central tendency\n",
        "        - Central_Tendency_Value (float): Central tendency value (can be null)\n",
        "        - Measure_Of_Variability (string): Type of variability measure\n",
        "        - Variability_Value (string): Variability value\n",
        "        - Other_Reporting_Method (string): Alternative reporting methods if used, \"NA\" otherwise\n",
        "        - Comments (string): Comprehensive extraction notes, methodology, data sources, and additional details\n",
        "        \n",
        "        FIELD MAPPING RULES:\n",
        "        - For pain relief outcomes (1-4): Fill pain relief fields, set all others to \"NA\"\n",
        "        - For TOTPAR outcomes (5-8): Fill TOTPAR fields, set all others to \"NA\"\n",
        "        - For SPID outcomes (9-12): Fill SPID fields, set all others to \"NA\" \n",
        "        - For global efficacy (13-16): Fill global efficacy fields, set all others to \"NA\"\n",
        "        - For other outcomes (17): Fill outcome_other_specify, set specific fields to \"NA\"\n",
        "        \n",
        "        Example: { \"First_Author\": \"Cooper\",  \"Population\": \"2, 3\", \"Intervention_Code\": 6, \"Intervention_Description\": \"Ibuprofen 400 mg\", \"Outcome_Code\": 1, \"Outcome_Other_Specify\": \"NA\", \"Pain_Relief_Type_Of_Scale\": \"ordinal, categorical\", \"Pain_Relief_Name_Of_Scale\": \"5-point categorical pain relief scale\", \"Pain_Relief_Range_Of_Scale\": \"0-4\", \"Pain_Relief_Copy_Paste_Scale\": \"patients recorded level of pain relief as complete (4), a lot (3), some (2), a little (1), or none (0)\", \"Pain_Relief_All_Responses\": \"complete (4), a lot (3), some (2), a little (1), none (0)\", \"Global_Efficacy_Type_Of_Scale\": \"NA\", \"Global_Efficacy_Name_Of_Scale\": \"NA\", \"Global_Efficacy_Range_Of_Scale\": \"NA\", \"Global_Efficacy_Copy_Paste_Scale\": \"NA\", \"Global_Efficacy_All_Responses\": \"NA\", \"TOTPAR_Copy_Paste_Scale\": \"NA\", \"TOTPAR_Definition\": \"NA\", \"TOTPAR_Name_Of_Scale\": \"NA\", \"TOTPAR_Type_Of_Scale\": \"NA\", \"TOTPAR_Range_Of_Scale\": \"NA\", \"TOTPAR_Copy_Paste_Questions\": \"NA\", \"TOTPAR_All_Responses\": \"NA\", \"SPID_Copy_Paste_Scale\": \"NA\", \"SPID_Definition\": \"NA\", \"SPID_Name_Of_Scale\": \"NA\", \"SPID_Type_Of_Scale\": \"NA\", \"SPID_Range_Of_Scale\": \"NA\", \"SPID_Copy_Paste_Questions\": \"NA\", \"SPID_All_Responses\": \"NA\", \"N_Analyzed\": 37, \"Measure_Of_Central_Tendency\": \"mean\", \"Central_Tendency_Value\": 1.51, \"Measure_Of_Variability\": \"NR\", \"Variability_Value\": \"NR\", \"Other_Reporting_Method\": \"NA\", \"Comments\": \"Data extracted from Figure II using Webplot digitizer; single dose study; pain relief recorded hourly by patients\"}\"\"\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_json_parse(json_string, fallback=None):\n",
        "    \"\"\"Robust JSON parser with multiple recovery strategies.\"\"\"\n",
        "    if fallback is None:\n",
        "        fallback = {}\n",
        "    \n",
        "    if not json_string or not isinstance(json_string, str):\n",
        "        return fallback\n",
        "    \n",
        "    # Clean markdown fences first\n",
        "    import re\n",
        "    json_string = re.sub(r\"```[a-zA-Z]*\\n?\", \"\", json_string).replace(\"```\", \"\")\n",
        "    json_string = json_string.strip()\n",
        "    \n",
        "    # Strategy 1: Direct parsing\n",
        "    try:\n",
        "        result = json.loads(json_string)\n",
        "        if isinstance(result, str) and result.strip().startswith((\"{\", \"[\")):\n",
        "            return safe_json_parse(result, fallback)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    \n",
        "    # Strategy 2: Clean common issues and handle nested single quotes\n",
        "    try:\n",
        "        cleaned = json_string.strip()\n",
        "        cleaned = cleaned.replace('\\n', '\\\\n').replace('\\r', '\\\\r').replace('\\t', '\\\\t')\n",
        "        cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n",
        "        \n",
        "        if cleaned.startswith(\"'\") or \"': '\" in cleaned or \"': {'\" in cleaned:\n",
        "            cleaned = cleaned.replace(\"'\", '\"')\n",
        "            cleaned = cleaned.replace('\"\"', '\"')\n",
        "        else:\n",
        "            cleaned = re.sub(r\"'([^']*)':\", r'\"\\1\":', cleaned)\n",
        "            cleaned = re.sub(r\":\\s*'([^']*)'\", r': \"\\1\"', cleaned)\n",
        "        \n",
        "        result = json.loads(cleaned)\n",
        "        if isinstance(result, str) and result.strip().startswith((\"{\", \"[\")):\n",
        "            return safe_json_parse(result, fallback)\n",
        "        return result\n",
        "    except (json.JSONDecodeError, AttributeError):\n",
        "        pass\n",
        "    \n",
        "    # Strategy 3: Extract key-value pairs manually\n",
        "    try:\n",
        "        data = {}\n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*(\\d+(?:\\.\\d+)?)', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = float(value) if '.' in value else int(value)\n",
        "        \n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*\"([^\"]*)\"', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = value\n",
        "        \n",
        "        for match in re.finditer(r'\"([^\"]+)\":\\s*(true|false)', json_string):\n",
        "            key, value = match.groups()\n",
        "            data[key] = value == 'true'\n",
        "        \n",
        "        if data:\n",
        "            return data\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return fallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DSPy Module Implementation\n",
        "\n",
        "Now we'll create DSPy modules that use these signatures with reasoning patterns:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class StudyMetadataExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract study metadata using chain of thought reasoning.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_metadata = dspy.ChainOfThought(ExtractStudyMetadata)\n",
        "    \n",
        "    def forward(self, markdown_content: str) -> Dict[str, Any]:\n",
        "        result = self.extract_metadata(markdown_content=markdown_content)\n",
        "        return {\n",
        "            \n",
        "            \"first_author\": result.first_author,\n",
        "         \n",
        "            \"population_code\": result.population_code\n",
        "        }\n",
        "\n",
        "\n",
        "class InterventionExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract intervention details.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_interventions = dspy.ChainOfThought(ExtractInterventions)\n",
        "    \n",
        "    def forward(self, markdown_content: str) -> List[Dict[str, Any]]:\n",
        "        result = self.extract_interventions(markdown_content=markdown_content)\n",
        "        try:\n",
        "            return safe_json_parse(result.interventions_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing interventions JSON, returning empty list\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class OutcomeTypeExtractor(dspy.Module):\n",
        "    \"\"\"Module to identify which outcome types are present.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_outcome_types = dspy.ChainOfThought(ExtractOutcomeTypes)\n",
        "    \n",
        "    def forward(self, markdown_content: str, intervention_description: str) -> List[Dict[str, Any]]:\n",
        "        result = self.extract_outcome_types(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.outcome_types_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing outcome types JSON, returning empty list\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class PainReliefDetailExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract detailed pain relief measurement information.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_pain_relief_details = dspy.ChainOfThought(ExtractPainReliefDetails)\n",
        "    \n",
        "    def forward(self, markdown_content: str, intervention_description: str, \n",
        "                outcome_code: int, time_point: str) -> Dict[str, Any]:\n",
        "        result = self.extract_pain_relief_details(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description,\n",
        "            outcome_code=outcome_code,\n",
        "            time_point=time_point\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.pain_relief_details_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print('_'*50)\n",
        "            print(result.pain_relief_details_json)\n",
        "            print('_'*50)\n",
        "            print(\"Error parsing pain relief details JSON, returning basic structure\")\n",
        "            return {\n",
        "                \"type_of_scale_used\": \"\",\n",
        "                \"name_of_scale_used\": \"\",\n",
        "                \"range_of_scale_used\": \"\",\n",
        "                \"copy_paste_scale\": \"\",\n",
        "                \"all_scale_responses\": \"\",\n",
        "                \"extraction_notes\": \"Error in parsing\",\n",
        "                \"additional_details\": \"\"\n",
        "            }\n",
        "\n",
        "\n",
        "class GlobalEfficacyDetailExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract detailed global efficacy measurement information.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_global_efficacy_details = dspy.ChainOfThought(ExtractGlobalEfficacyDetails)\n",
        "    \n",
        "    def forward(self, markdown_content: str, intervention_description: str, \n",
        "                outcome_code: int, time_point: str) -> Dict[str, Any]:\n",
        "        result = self.extract_global_efficacy_details(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description,\n",
        "            outcome_code=outcome_code,\n",
        "            time_point=time_point\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.global_efficacy_details_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing global efficacy details JSON, returning basic structure\")\n",
        "            return {\n",
        "                \"type_of_scale_used\": \"\",\n",
        "                \"name_of_scale_used\": \"\",\n",
        "                \"range_of_scale_used\": \"\",\n",
        "                \"copy_paste_scale\": \"\",\n",
        "                \"all_scale_responses\": \"\",\n",
        "                \"extraction_notes\": \"Error in parsing\",\n",
        "                \"additional_details\": \"\"\n",
        "            }\n",
        "\n",
        "\n",
        "class TOTPARDetailExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract detailed TOTPAR measurement information.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_totpar_details = dspy.ChainOfThought(ExtractTOTPARDetails)\n",
        "    \n",
        "    def forward(self, markdown_content: str, intervention_description: str, \n",
        "                outcome_code: int, time_point: str) -> Dict[str, Any]:\n",
        "        result = self.extract_totpar_details(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description,\n",
        "            outcome_code=outcome_code,\n",
        "            time_point=time_point\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.totpar_details_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print('_'*50)\n",
        "            print(result.totpar_details_json)\n",
        "            print('_'*50)\n",
        "            print(\"Error parsing TOTPAR details JSON, returning basic structure\")\n",
        "            return {\n",
        "                \"copy_paste_scale\": \"\",\n",
        "                \"definition_of_totpar\": \"\",\n",
        "                \"name_of_scale_used\": \"\",\n",
        "                \"type_of_scale_used\": \"\",\n",
        "                \"range_of_scale_used\": \"\",\n",
        "                \"copy_paste_scale_questions\": \"\",\n",
        "                \"all_scale_responses\": \"\",\n",
        "                \"calculation_method\": \"\",\n",
        "                \"time_points_included\": \"\",\n",
        "                \"extraction_notes\": \"Error in parsing\",\n",
        "                \"additional_details\": \"\"\n",
        "            }\n",
        "\n",
        "\n",
        "class SPIDDetailExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract detailed SPID measurement information.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_spid_details = dspy.ChainOfThought(ExtractSPIDDetails)\n",
        "    \n",
        "    def forward(self, markdown_content: str, intervention_description: str, \n",
        "                outcome_code: int, time_point: str) -> Dict[str, Any]:\n",
        "        result = self.extract_spid_details(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description,\n",
        "            outcome_code=outcome_code,\n",
        "            time_point=time_point\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.spid_details_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing SPID details JSON, returning basic structure\")\n",
        "            return {\n",
        "                \"copy_paste_scale\": \"\",\n",
        "                \"definition_of_spid\": \"\",\n",
        "                \"name_of_scale_used\": \"\",\n",
        "                \"type_of_scale_used\": \"\",\n",
        "                \"range_of_scale_used\": \"\",\n",
        "                \"copy_paste_scale_questions\": \"\",\n",
        "                \"all_scale_responses\": \"\",\n",
        "                \"calculation_method\": \"\",\n",
        "                \"time_points_included\": \"\",\n",
        "                \"extraction_notes\": \"Error in parsing\",\n",
        "                \"additional_details\": \"\"\n",
        "            }\n",
        "\n",
        "\n",
        "# class OtherOutcomeDetailExtractor(dspy.Module):\n",
        "#     \"\"\"Module to extract detailed other outcome measurement information.\"\"\"\n",
        "    \n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.extract_other_outcome_details = dspy.ChainOfThought(ExtractOtherOutcomeDetails)\n",
        "    \n",
        "#     def forward(self, markdown_content: str, intervention_description: str, \n",
        "#                 outcome_other_specify: str) -> Dict[str, Any]:\n",
        "#         result = self.extract_other_outcome_details(\n",
        "#             markdown_content=markdown_content,\n",
        "#             intervention_description=intervention_description,\n",
        "#             outcome_other_specify=outcome_other_specify\n",
        "#         )\n",
        "#         try:\n",
        "#             return safe_json_parse(result.other_outcome_details_json)\n",
        "#         except json.JSONDecodeError:\n",
        "#             print(\"Error parsing other outcome details JSON, returning basic structure\")\n",
        "#             return {\n",
        "#                 \"outcome_name\": outcome_other_specify,\n",
        "#                 \"type_of_scale_used\": \"\",\n",
        "#                 \"name_of_scale_used\": \"\",\n",
        "#                 \"range_of_scale_used\": \"\",\n",
        "#                 \"copy_paste_scale\": \"\",\n",
        "#                 \"all_scale_responses\": \"\",\n",
        "#                 \"measurement_method\": \"\",\n",
        "#                 \"time_points\": \"\",\n",
        "#                 \"extraction_notes\": \"Error in parsing\",\n",
        "#                 \"additional_details\": \"\"\n",
        "#             }\n",
        "\n",
        "\n",
        "class StatisticalDataExtractor(dspy.Module):\n",
        "    \"\"\"Module to extract statistical measures and numerical data.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract_statistical_data = dspy.ChainOfThought(ExtractStatisticalData)\n",
        "    \n",
        "    def forward(self, markdown_content: str, intervention_description: str, \n",
        "                outcome_code: int, time_point: str) -> Dict[str, Any]:\n",
        "        result = self.extract_statistical_data(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_description,\n",
        "            outcome_code=outcome_code,\n",
        "            time_point=time_point\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.statistical_data_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing statistical data JSON, returning basic structure\")\n",
        "            return {\n",
        "                \"n_analyzed\": None,\n",
        "                \"measure_of_central_tendency\": \"\",\n",
        "                \"central_tendency_value\": None,\n",
        "                \"measure_of_variability\": \"\",\n",
        "                \"variability_value\": \"\",\n",
        "                \"other_reporting_method\": \"NA\",\n",
        "                \"data_source\": \"\",\n",
        "                \"extraction_method\": \"Error in parsing\"\n",
        "            }\n",
        "\n",
        "\n",
        "class CompleteRecordStructurer(dspy.Module):\n",
        "    \"\"\"Module to structure all data into final comprehensive CSV-compatible format.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.structure_record = dspy.ChainOfThought(StructureCompleteRecord)\n",
        "    \n",
        "    def forward(self, study_metadata: Dict, intervention: Dict, outcome_type: Dict,\n",
        "                outcome_details: Dict, statistical_data: Dict) -> Dict[str, Any]:\n",
        "        result = self.structure_record(\n",
        "            study_metadata_json=json.dumps(study_metadata),\n",
        "            intervention_json=json.dumps(intervention),\n",
        "            outcome_type_json=json.dumps(outcome_type),\n",
        "            outcome_details_json=json.dumps(outcome_details),\n",
        "            statistical_data_json=json.dumps(statistical_data)\n",
        "        )\n",
        "        try:\n",
        "            return safe_json_parse(result.final_record_json)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing final record JSON, returning basic structure\")\n",
        "            \n",
        "            # Determine which fields to fill based on outcome category\n",
        "            outcome_code = outcome_type.get(\"outcome_code\", 1)\n",
        "            outcome_category = outcome_type.get(\"outcome_category\", \"\")\n",
        "            \n",
        "            # Initialize all fields to \"NA\"\n",
        "            record = {\n",
        "                \n",
        "                \"First_Author\": study_metadata.get(\"first_author\", \"\"),\n",
        "                \n",
        "                \"Population\": study_metadata.get(\"population_code\", \"\"),\n",
        "                \"Intervention_Code\": intervention.get(\"intervention_code\", \"\"),\n",
        "                \"Intervention_Description\": intervention.get(\"intervention_description\", \"\"),\n",
        "                \"Outcome_Code\": outcome_code,\n",
        "                \"Outcome_Other_Specify\": outcome_type.get(\"outcome_other_specify\", \"NA\"),\n",
        "                \n",
        "                # Pain Relief Fields\n",
        "                \"Pain_Relief_Type_Of_Scale\": \"NA\",\n",
        "                \"Pain_Relief_Name_Of_Scale\": \"NA\",\n",
        "                \"Pain_Relief_Range_Of_Scale\": \"NA\",\n",
        "                \"Pain_Relief_Copy_Paste_Scale\": \"NA\",\n",
        "                \"Pain_Relief_All_Responses\": \"NA\",\n",
        "                \n",
        "                # Global Efficacy Fields\n",
        "                \"Global_Efficacy_Type_Of_Scale\": \"NA\",\n",
        "                \"Global_Efficacy_Name_Of_Scale\": \"NA\",\n",
        "                \"Global_Efficacy_Range_Of_Scale\": \"NA\",\n",
        "                \"Global_Efficacy_Copy_Paste_Scale\": \"NA\",\n",
        "                \"Global_Efficacy_All_Responses\": \"NA\",\n",
        "                \n",
        "                # TOTPAR Fields\n",
        "                \"TOTPAR_Copy_Paste_Scale\": \"NA\",\n",
        "                \"TOTPAR_Definition\": \"NA\",\n",
        "                \"TOTPAR_Name_Of_Scale\": \"NA\",\n",
        "                \"TOTPAR_Type_Of_Scale\": \"NA\",\n",
        "                \"TOTPAR_Range_Of_Scale\": \"NA\",\n",
        "                \"TOTPAR_Copy_Paste_Questions\": \"NA\",\n",
        "                \"TOTPAR_All_Responses\": \"NA\",\n",
        "                \n",
        "                # SPID Fields\n",
        "                \"SPID_Copy_Paste_Scale\": \"NA\",\n",
        "                \"SPID_Definition\": \"NA\",\n",
        "                \"SPID_Name_Of_Scale\": \"NA\",\n",
        "                \"SPID_Type_Of_Scale\": \"NA\",\n",
        "                \"SPID_Range_Of_Scale\": \"NA\",\n",
        "                \"SPID_Copy_Paste_Questions\": \"NA\",\n",
        "                \"SPID_All_Responses\": \"NA\",\n",
        "                \n",
        "                # Statistical Fields\n",
        "                \"N_Analyzed\": statistical_data.get(\"n_analyzed\", \"\"),\n",
        "                \"Measure_Of_Central_Tendency\": statistical_data.get(\"measure_of_central_tendency\", \"\"),\n",
        "                \"Central_Tendency_Value\": statistical_data.get(\"central_tendency_value\", \"\"),\n",
        "                \"Measure_Of_Variability\": statistical_data.get(\"measure_of_variability\", \"\"),\n",
        "                \"Variability_Value\": statistical_data.get(\"variability_value\", \"\"),\n",
        "                \"Other_Reporting_Method\": statistical_data.get(\"other_reporting_method\", \"NA\"),\n",
        "                \"Comments\": f\"{outcome_details.get('extraction_notes', '')} {outcome_details.get('additional_details', '')} {statistical_data.get('extraction_method', '')}\"\n",
        "            }\n",
        "            \n",
        "            # Fill appropriate fields based on outcome category\n",
        "            if outcome_category == \"pain_relief\":\n",
        "                record[\"Pain_Relief_Type_Of_Scale\"] = outcome_details.get(\"type_of_scale_used\", \"\")\n",
        "                record[\"Pain_Relief_Name_Of_Scale\"] = outcome_details.get(\"name_of_scale_used\", \"\")\n",
        "                record[\"Pain_Relief_Range_Of_Scale\"] = outcome_details.get(\"range_of_scale_used\", \"\")\n",
        "                record[\"Pain_Relief_Copy_Paste_Scale\"] = outcome_details.get(\"copy_paste_scale\", \"\")\n",
        "                record[\"Pain_Relief_All_Responses\"] = outcome_details.get(\"all_scale_responses\", \"\")\n",
        "            elif outcome_category == \"global_efficacy\":\n",
        "                record[\"Global_Efficacy_Type_Of_Scale\"] = outcome_details.get(\"type_of_scale_used\", \"\")\n",
        "                record[\"Global_Efficacy_Name_Of_Scale\"] = outcome_details.get(\"name_of_scale_used\", \"\")\n",
        "                record[\"Global_Efficacy_Range_Of_Scale\"] = outcome_details.get(\"range_of_scale_used\", \"\")\n",
        "                record[\"Global_Efficacy_Copy_Paste_Scale\"] = outcome_details.get(\"copy_paste_scale\", \"\")\n",
        "                record[\"Global_Efficacy_All_Responses\"] = outcome_details.get(\"all_scale_responses\", \"\")\n",
        "            elif outcome_category == \"totpar\":\n",
        "                record[\"TOTPAR_Copy_Paste_Scale\"] = outcome_details.get(\"copy_paste_scale\", \"\")\n",
        "                record[\"TOTPAR_Definition\"] = outcome_details.get(\"definition_of_totpar\", \"\")\n",
        "                record[\"TOTPAR_Name_Of_Scale\"] = outcome_details.get(\"name_of_scale_used\", \"\")\n",
        "                record[\"TOTPAR_Type_Of_Scale\"] = outcome_details.get(\"type_of_scale_used\", \"\")\n",
        "                record[\"TOTPAR_Range_Of_Scale\"] = outcome_details.get(\"range_of_scale_used\", \"\")\n",
        "                record[\"TOTPAR_Copy_Paste_Questions\"] = outcome_details.get(\"copy_paste_scale_questions\", \"\")\n",
        "                record[\"TOTPAR_All_Responses\"] = outcome_details.get(\"all_scale_responses\", \"\")\n",
        "            elif outcome_category == \"spid\":\n",
        "                record[\"SPID_Copy_Paste_Scale\"] = outcome_details.get(\"copy_paste_scale\", \"\")\n",
        "                record[\"SPID_Definition\"] = outcome_details.get(\"definition_of_spid\", \"\")\n",
        "                record[\"SPID_Name_Of_Scale\"] = outcome_details.get(\"name_of_scale_used\", \"\")\n",
        "                record[\"SPID_Type_Of_Scale\"] = outcome_details.get(\"type_of_scale_used\", \"\")\n",
        "                record[\"SPID_Range_Of_Scale\"] = outcome_details.get(\"range_of_scale_used\", \"\")\n",
        "                record[\"SPID_Copy_Paste_Questions\"] = outcome_details.get(\"copy_paste_scale_questions\", \"\")\n",
        "                record[\"SPID_All_Responses\"] = outcome_details.get(\"all_scale_responses\", \"\")\n",
        "            # elif outcome_category == \"other\":\n",
        "            #     record[\"Outcome_Other_Specify\"] = outcome_details.get(\"outcome_name\", \"\")\n",
        "            \n",
        "            return record\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Complete Extraction Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete extraction pipeline initialized\n"
          ]
        }
      ],
      "source": [
        "class MedicalDataExtractionPipeline(dspy.Module):\n",
        "    \"\"\"Complete pipeline for extracting structured continuous outcome data from medical research papers.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.metadata_extractor = StudyMetadataExtractor()\n",
        "        self.intervention_extractor = InterventionExtractor()\n",
        "        self.outcome_type_extractor = OutcomeTypeExtractor()\n",
        "        self.pain_relief_extractor = PainReliefDetailExtractor()\n",
        "        self.global_efficacy_extractor = GlobalEfficacyDetailExtractor()\n",
        "        self.totpar_extractor = TOTPARDetailExtractor()\n",
        "        self.spid_extractor = SPIDDetailExtractor()\n",
        "        #self.other_outcome_extractor = OtherOutcomeDetailExtractor()\n",
        "        self.statistical_extractor = StatisticalDataExtractor()\n",
        "        self.record_structurer = CompleteRecordStructurer()\n",
        "    \n",
        "    def _get_outcome_details(self, markdown_content: str, intervention_description: str,\n",
        "                            outcome_type: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"Get detailed outcome information based on outcome category.\"\"\"\n",
        "        outcome_category = outcome_type.get(\"outcome_category\", \"\")\n",
        "        outcome_code = outcome_type.get(\"outcome_code\", 1)\n",
        "        time_point = outcome_type.get(\"time_point\", \"\")\n",
        "        \n",
        "        if outcome_category == \"pain_relief\":\n",
        "            return self.pain_relief_extractor(markdown_content, intervention_description, outcome_code, time_point)\n",
        "        elif outcome_category == \"global_efficacy\":\n",
        "            return self.global_efficacy_extractor(markdown_content, intervention_description, outcome_code, time_point)\n",
        "        elif outcome_category == \"totpar\":\n",
        "            return self.totpar_extractor(markdown_content, intervention_description, outcome_code, time_point)\n",
        "        elif outcome_category == \"spid\":\n",
        "            return self.spid_extractor(markdown_content, intervention_description, outcome_code, time_point)\n",
        "        # elif outcome_category == \"other\":\n",
        "        #     outcome_other_specify = outcome_type.get(\"outcome_other_specify\", \"\")\n",
        "        #     return self.other_outcome_extractor(markdown_content, intervention_description, outcome_other_specify)\n",
        "        else:\n",
        "            return {\n",
        "                \"extraction_notes\": f\"Unknown outcome category: {outcome_category}\",\n",
        "                \"additional_details\": \"\"\n",
        "            }\n",
        "    \n",
        "    def forward(self, markdown_content: str):\n",
        "        \"\"\"Extract all structured continuous outcome records from markdown content.\"\"\"\n",
        "        \n",
        "        # Step 1: Extract study metadata\n",
        "        print(\"Extracting study metadata...\")\n",
        "        study_metadata = self.metadata_extractor(markdown_content)\n",
        "        print(f\"Study metadata: {study_metadata}\")\n",
        "        \n",
        "        # Step 2: Extract interventions\n",
        "        print(\"Extracting interventions...\")\n",
        "        interventions = self.intervention_extractor(markdown_content)\n",
        "        print(f\"Found {len(interventions)} interventions\")\n",
        "        print(interventions)\n",
        "        \n",
        "        # Step 3: For each intervention, extract outcomes through the pipeline\n",
        "        all_records = []\n",
        "        \n",
        "        for i, intervention in enumerate(interventions):\n",
        "            intervention_desc = intervention.get('intervention_description', 'Unknown')\n",
        "            print(f\"Processing intervention {i+1}: {intervention_desc}\")\n",
        "            \n",
        "            # Step 3a: Find what outcome types exist for this intervention\n",
        "            outcome_types = self.outcome_type_extractor(markdown_content, intervention_desc)\n",
        "            print(f\"Found {len(outcome_types)} outcome types for this intervention\")\n",
        "            \n",
        "            # Step 3b: Process each outcome type\n",
        "            for j, outcome_type in enumerate(outcome_types):\n",
        "                outcome_code = outcome_type.get('outcome_code', 'Unknown')\n",
        "                outcome_category = outcome_type.get('outcome_category', 'Unknown')\n",
        "                time_point = outcome_type.get('time_point', 'Unknown')\n",
        "                \n",
        "                print(f\"  Processing outcome {j+1}: Code {outcome_code} ({outcome_category}) at {time_point}\")\n",
        "                \n",
        "                # Step 3c: Extract detailed outcome information based on category\n",
        "                outcome_details = self._get_outcome_details(markdown_content, intervention_desc, outcome_type)\n",
        "                \n",
        "                # Step 3d: Extract statistical data\n",
        "                statistical_data = self.statistical_extractor(\n",
        "                    markdown_content,\n",
        "                    intervention_desc,\n",
        "                    outcome_type.get('outcome_code'),\n",
        "                    time_point\n",
        "                )\n",
        "                \n",
        "                # Step 3e: Structure the complete record\n",
        "                structured_record = self.record_structurer(\n",
        "                    study_metadata,\n",
        "                    intervention,\n",
        "                    outcome_type,\n",
        "                    outcome_details,\n",
        "                    statistical_data\n",
        "                )\n",
        "                \n",
        "                all_records.append(structured_record)\n",
        "        \n",
        "        print(f\"Total records extracted: {len(all_records)}\")\n",
        "        \n",
        "        # Return a dspy.Prediction object instead of a raw list\n",
        "        return dspy.Prediction(extracted_records=all_records)\n",
        "    \n",
        "    def _generate_output_filename(self, source_file_path: str) -> str:\n",
        "        \"\"\"Generate output filename from source filename.\n",
        "        \n",
        "        Args:\n",
        "            source_file_path: Path to source file (e.g., \"1102_Qi_md.json\")\n",
        "            \n",
        "        Returns:\n",
        "            str: Output filename (e.g., \"1102_Qi_co.json\") - 'co' for continuous outcomes\n",
        "        \"\"\"\n",
        "        import os\n",
        "        from pathlib import Path\n",
        "        \n",
        "        source_path = Path(source_file_path)\n",
        "        source_name = source_path.stem  # Get filename without extension\n",
        "        \n",
        "        # Replace '_md' with '_co' (continuous outcomes) in the filename\n",
        "        if source_name.endswith('_md'):\n",
        "            output_name = source_name[:-3] + '_co'  # Remove '_md' and add '_co'\n",
        "        else:\n",
        "            # If no '_md' pattern, just add '_co' suffix\n",
        "            output_name = source_name + '_co'\n",
        "        \n",
        "        return output_name + '.json'\n",
        "    \n",
        "    def save_extracted_results(self, extracted_records, source_file_path: str, output_dir: str = None, override: bool = False) -> str:\n",
        "        \"\"\"Save extracted continuous outcome results to JSON file with naming convention.\n",
        "        \n",
        "        Args:\n",
        "            extracted_records: List of extracted records\n",
        "            source_file_path: Path to source markdown file (e.g., \"1102_Qi_md.json\")\n",
        "            output_dir: Directory to save results (default: same as source)\n",
        "            override: If True, overwrite existing file; if False, skip if exists\n",
        "            \n",
        "        Returns:\n",
        "            str: Path to saved file or None if skipped\n",
        "        \"\"\"\n",
        "        import json\n",
        "        import os\n",
        "        from pathlib import Path\n",
        "        from datetime import datetime\n",
        "        \n",
        "        try:\n",
        "            # Generate output filename\n",
        "            output_filename = self._generate_output_filename(source_file_path)\n",
        "            \n",
        "            # Determine output directory\n",
        "            if output_dir is None:\n",
        "                output_dir = Path(source_file_path).parent\n",
        "            else:\n",
        "                output_dir = Path(output_dir)\n",
        "            \n",
        "            # Create output directory if it doesn't exist\n",
        "            output_dir.mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            # Full output path\n",
        "            output_path = output_dir / output_filename\n",
        "            \n",
        "            # Check if file exists and override flag\n",
        "            if output_path.exists() and not override:\n",
        "                print(f\"⚠️  Output file already exists: {output_path}\")\n",
        "                print(f\"   Use override=True to overwrite, or file will be skipped\")\n",
        "                return None\n",
        "            \n",
        "            # Prepare data to save\n",
        "            save_data = {\n",
        "                \"extracted_records\": extracted_records\n",
        "            }\n",
        "            \n",
        "            # Save to JSON file\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            print(f\"✅ Successfully saved {len(extracted_records)} comprehensive continuous outcome records to: {output_path}\")\n",
        "            return str(output_path)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving results: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run_and_save(self, markdown_content: str, source_file_path: str, output_dir: str = None, override: bool = False):\n",
        "        \"\"\"Run the complete pipeline and save results.\"\"\"\n",
        "        prediction = self.forward(markdown_content)\n",
        "        self.save_extracted_results(prediction.extracted_records, source_file_path, output_dir, override)\n",
        "        return prediction\n",
        "    \n",
        "    def extract_specific_categories(self, markdown_content: str, categories: List[str]):\n",
        "        \"\"\"Extract only specific outcome categories.\n",
        "        \n",
        "        Args:\n",
        "            markdown_content: Full markdown content\n",
        "            categories: List of categories to extract ('pain_relief', 'totpar', 'spid', 'global_efficacy', 'other')\n",
        "        \"\"\"\n",
        "        print(f\"Extracting specific categories: {categories}\")\n",
        "        \n",
        "        # Run full extraction first\n",
        "        prediction = self.forward(markdown_content)\n",
        "        \n",
        "        # Category to outcome code mapping\n",
        "        category_codes = {\n",
        "            \"pain_relief\": [1, 2, 3, 4],\n",
        "            \"totpar\": [5, 6, 7, 8],\n",
        "            \"spid\": [9, 10, 11, 12],\n",
        "            \"global_efficacy\": [13, 14, 15, 16],\n",
        "            \"other\": [17]\n",
        "        }\n",
        "        \n",
        "        # Get target outcome codes\n",
        "        target_codes = []\n",
        "        for category in categories:\n",
        "            if category in category_codes:\n",
        "                target_codes.extend(category_codes[category])\n",
        "        \n",
        "        # Filter records\n",
        "        filtered_records = [\n",
        "            record for record in prediction.extracted_records\n",
        "            if record.get(\"Outcome_Code\") in target_codes\n",
        "        ]\n",
        "        \n",
        "        print(f\"Filtered to {len(filtered_records)} records for categories: {categories}\")\n",
        "        return dspy.Prediction(extracted_records=filtered_records)\n",
        "\n",
        "\n",
        "# Initialize the pipeline\n",
        "extraction_pipeline = MedicalDataExtractionPipeline()\n",
        "print(\"Complete extraction pipeline initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluation Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The 4 Core Outcomes in Classification\n",
        "\n",
        "When evaluating a system’s predictions against the **ground truth**, each result falls into one of four categories:\n",
        "\n",
        "### 1. **True Positive (TP)**\n",
        "- System says **“Yes”**\n",
        "- Ground truth is **“Yes”**\n",
        "- ✅ Correct detection  \n",
        "- **Example:** System extracts `First_Author = Cooper`, and ground truth really has `Cooper`.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **False Positive (FP)**\n",
        "- System says **“Yes”**\n",
        "- Ground truth is **“No”**\n",
        "- ❌ Wrong detection (system “hallucinated”)  \n",
        "- **Example:** System extracts `First_Author = Jones`, but ground truth has `Smith`.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **True Negative (TN)**\n",
        "- System says **“No”**\n",
        "- Ground truth is **“No”**\n",
        "- ✅ Correct rejection  \n",
        "- **Example:** Ground truth has no `Adverse_Effect_Specify`, and system also leaves it empty.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **False Negative (FN)**\n",
        "- System says **“No”**\n",
        "- Ground truth is **“Yes”**\n",
        "- ❌ Missed detection (system failed to extract)  \n",
        "- **Example:** Ground truth has `Trial_Name = MOLAR`, but system extracts nothing (or extracts wrong value).\n",
        "\n",
        "\n",
        "\n",
        "### In `MedicalExtractionEvaluator` Context\n",
        "\n",
        "- **TP (True Positive)** → A field value was extracted **and** it matched the ground truth.  \n",
        "- **FP (False Positive)** → A field value was extracted, but it was **wrong** (mismatch) or **extra** (system filled something that shouldn’t exist).  \n",
        "- **FN (False Negative)** → A ground-truth field existed, but the system didn’t produce it (missing record or missing field).  \n",
        "- **TN (True Negative)** → Neither system nor ground truth had a value for a field.  \n",
        "\n",
        "**Note:** TNs are **not explicitly tracked** in the evaluator, because in information extraction tasks the number of “true negatives” is usually very large and not informative. This is common in IR/NLP evaluation — most focus only on TP, FP, FN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MedicalExtractionEvaluator:\n",
        "    \"\"\"Enhanced evaluator for medical data extraction quality with precision, recall, accuracy metrics, and semantic matching with caching.\"\"\"\n",
        "    \n",
        "    def __init__(self, use_semantic=True, semantic_threshold=0.8, cache_dir='.semantic_cache'):\n",
        "        self.required_fields = [\n",
        "            'First_Author', 'Population', 'Intervention_Code', 'Intervention_Description', \n",
        "            'Outcome_Code', 'Outcome_Other_Specify',\n",
        "            \n",
        "            # Pain Relief Fields\n",
        "            'Pain_Relief_Type_Of_Scale', 'Pain_Relief_Name_Of_Scale', 'Pain_Relief_Range_Of_Scale',\n",
        "            'Pain_Relief_Copy_Paste_Scale', 'Pain_Relief_All_Responses',\n",
        "            \n",
        "            # Global Efficacy Fields  \n",
        "            'Global_Efficacy_Type_Of_Scale', 'Global_Efficacy_Name_Of_Scale', 'Global_Efficacy_Range_Of_Scale',\n",
        "            'Global_Efficacy_Copy_Paste_Scale', 'Global_Efficacy_All_Responses',\n",
        "            \n",
        "            # TOTPAR Fields\n",
        "            'TOTPAR_Copy_Paste_Scale', 'TOTPAR_Definition', 'TOTPAR_Name_Of_Scale',\n",
        "            'TOTPAR_Type_Of_Scale', 'TOTPAR_Range_Of_Scale', 'TOTPAR_Copy_Paste_Questions',\n",
        "            'TOTPAR_All_Responses',\n",
        "            \n",
        "            # SPID Fields\n",
        "            'SPID_Copy_Paste_Scale', 'SPID_Definition', 'SPID_Name_Of_Scale', \n",
        "            'SPID_Type_Of_Scale', 'SPID_Range_Of_Scale', 'SPID_Copy_Paste_Questions',\n",
        "            'SPID_All_Responses',\n",
        "            \n",
        "            # Statistical Measures\n",
        "            'N_Analyzed', 'Measure_Of_Central_Tendency', 'Central_Tendency_Value',\n",
        "            'Measure_Of_Variability', 'Variability_Value', 'Other_Reporting_Method',\n",
        "            'Comments'\n",
        "        ]\n",
        "        \n",
        "        # Semantic matching setup\n",
        "        self.use_semantic = use_semantic\n",
        "        self.semantic_threshold = semantic_threshold\n",
        "        \n",
        "        # Cache for Hungarian matching results to avoid recomputation\n",
        "        self._matching_cache = {}\n",
        "        self._cache_key = None\n",
        "        \n",
        "        if self.use_semantic:\n",
        "            # Use a lightweight model for cost efficiency\n",
        "            self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast, small model\n",
        "            \n",
        "            # Initialize cache\n",
        "            self.cache = dc.Cache(cache_dir)\n",
        "            \n",
        "            # Fields that benefit from semantic matching\n",
        "            self.semantic_fields = [\n",
        "                'Intervention_Description', \n",
        "                'Outcome_Other_Specify',\n",
        "                'Pain_Relief_Type_Of_Scale', 'Pain_Relief_Name_Of_Scale', 'Pain_Relief_Copy_Paste_Scale',\n",
        "                'Global_Efficacy_Type_Of_Scale', 'Global_Efficacy_Name_Of_Scale', 'Global_Efficacy_Copy_Paste_Scale', \n",
        "                'TOTPAR_Copy_Paste_Scale', 'TOTPAR_Definition', 'TOTPAR_Name_Of_Scale',\n",
        "                'SPID_Copy_Paste_Scale', 'SPID_Definition', 'SPID_Name_Of_Scale',\n",
        "                'Measure_Of_Central_Tendency', 'Measure_Of_Variability', 'Other_Reporting_Method',\n",
        "                'Comments'\n",
        "            ]\n",
        "            \n",
        "            # Fields that need exact matching\n",
        "            self.exact_fields = [\n",
        "                'First_Author', 'Population', 'Intervention_Code', 'Outcome_Code',\n",
        "                'Pain_Relief_Range_Of_Scale', 'Pain_Relief_All_Responses',\n",
        "                'Global_Efficacy_Range_Of_Scale', 'Global_Efficacy_All_Responses',\n",
        "                'TOTPAR_Type_Of_Scale', 'TOTPAR_Range_Of_Scale', 'TOTPAR_Copy_Paste_Questions', 'TOTPAR_All_Responses',\n",
        "                'SPID_Type_Of_Scale', 'SPID_Range_Of_Scale', 'SPID_Copy_Paste_Questions', 'SPID_All_Responses',\n",
        "                'N_Analyzed', 'Central_Tendency_Value', 'Variability_Value'\n",
        "            ]\n",
        "    \n",
        "    def _generate_cache_key(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> str:\n",
        "        \"\"\"Generate a unique cache key for the given extracted records and ground truth.\"\"\"\n",
        "        import hashlib\n",
        "        \n",
        "        # Create a simple hash of the record contents\n",
        "        ext_str = str(sorted([str(sorted(record.items())) for record in extracted_records]))\n",
        "        gt_str = str(sorted([str(sorted(record.items())) for record in ground_truth]))\n",
        "        combined = ext_str + gt_str\n",
        "        \n",
        "        return hashlib.md5(combined.encode('utf-8')).hexdigest()\n",
        "    \n",
        "    def _get_cached_matching(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "        \"\"\"Get cached Hungarian matching results or compute and cache them.\"\"\"\n",
        "        cache_key = self._generate_cache_key(extracted_records, ground_truth)\n",
        "        \n",
        "        # Check if we have cached results for this exact combination\n",
        "        if cache_key in self._matching_cache:\n",
        "            return self._matching_cache[cache_key]\n",
        "        \n",
        "        # Compute Hungarian matching\n",
        "        matches = self._compute_hungarian_matching(extracted_records, ground_truth)\n",
        "        \n",
        "        # Cache the results\n",
        "        self._matching_cache[cache_key] = matches\n",
        "        self._cache_key = cache_key\n",
        "        \n",
        "        return matches\n",
        "    \n",
        "    def _get_text_hash(self, text: str) -> str:\n",
        "        \"\"\"Generate a hash for text to use as cache key.\"\"\"\n",
        "        return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
        "    \n",
        "    def _get_embedding(self, text: str):\n",
        "        \"\"\"Get embedding for text, using cache if available.\"\"\"\n",
        "        text_hash = self._get_text_hash(text)\n",
        "        \n",
        "        # Check cache first\n",
        "        if text_hash in self.cache:\n",
        "            return self.cache[text_hash]\n",
        "        \n",
        "        # Generate embedding\n",
        "        embedding = self.semantic_model.encode(text)\n",
        "        \n",
        "        # Store in cache\n",
        "        self.cache[text_hash] = embedding\n",
        "        \n",
        "        return embedding\n",
        "    \n",
        "    def normalize_value(self, value: Any) -> str:\n",
        "        \"\"\"Normalize values for comparison.\"\"\"\n",
        "        if value is None:\n",
        "            return \"\"\n",
        "        return str(value).strip().lower()\n",
        "    \n",
        "    def semantic_similarity(self, text1: str, text2: str) -> float:\n",
        "        \"\"\"Calculate semantic similarity between two texts using cached embeddings.\"\"\"\n",
        "        if not self.use_semantic:\n",
        "            return 1.0 if text1.lower() == text2.lower() else 0.0\n",
        "            \n",
        "        if not text1.strip() or not text2.strip():\n",
        "            return 1.0 if text1.strip() == text2.strip() else 0.0\n",
        "        \n",
        "        # Get cached embeddings\n",
        "        embedding1 = self._get_embedding(text1)\n",
        "        embedding2 = self._get_embedding(text2)\n",
        "        \n",
        "        similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "        return float(similarity)\n",
        "    \n",
        "    def field_match_score(self, extracted_value: Any, ground_truth_value: Any, field_name: str) -> float:\n",
        "        \"\"\"Calculate field-level match score (exact or semantic).\"\"\"\n",
        "        \n",
        "        # Handle None/empty values\n",
        "        ext_val = str(extracted_value).strip() if extracted_value is not None else \"\"\n",
        "        gt_val = str(ground_truth_value).strip() if ground_truth_value is not None else \"\"\n",
        "        \n",
        "        if not self.use_semantic:\n",
        "            # Fall back to normalized exact matching\n",
        "            return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "        \n",
        "        # Exact matching for certain fields\n",
        "        if field_name in self.exact_fields:\n",
        "            return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "        \n",
        "        # Semantic matching for text fields\n",
        "        if field_name in self.semantic_fields:\n",
        "            if not ext_val and not gt_val:\n",
        "                return 1.0  # Both empty\n",
        "            if not ext_val or not gt_val:\n",
        "                return 0.0  # One empty, one not\n",
        "            \n",
        "            similarity = self.semantic_similarity(ext_val, gt_val)\n",
        "            return 1.0 if similarity >= self.semantic_threshold else 0.0\n",
        "        \n",
        "        # Default exact matching\n",
        "        return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "    \n",
        "    def calculate_record_similarity(self, extracted_record: Dict, ground_truth_record: Dict) -> float:\n",
        "        \"\"\"Calculate overall similarity score between two records.\"\"\"\n",
        "        matches = 0\n",
        "        total_fields = 0\n",
        "        \n",
        "        for field in self.required_fields:\n",
        "            if field in extracted_record and field in ground_truth_record:\n",
        "                match_score = self.field_match_score(\n",
        "                    extracted_record[field], \n",
        "                    ground_truth_record[field], \n",
        "                    field\n",
        "                )\n",
        "                matches += match_score\n",
        "                total_fields += 1\n",
        "        \n",
        "        return matches / total_fields if total_fields > 0 else 0.0\n",
        "    \n",
        "    def find_best_match(self, extracted_record: Dict, ground_truth_records: List[Dict]) -> Tuple[Dict, float]:\n",
        "        \"\"\"Find the best matching ground truth record using Hungarian algorithm for global optimization.\"\"\"\n",
        "        # For single record matching, we still need to find the best match\n",
        "        # This method is used in contexts where we're matching one record at a time\n",
        "        best_match = None\n",
        "        best_score = 0.0\n",
        "        \n",
        "        for gt_record in ground_truth_records:\n",
        "            score = self.calculate_record_similarity(extracted_record, gt_record)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match = gt_record\n",
        "        \n",
        "        return best_match, best_score\n",
        "    \n",
        "    def _compute_hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "        \"\"\"\n",
        "        Compute Hungarian algorithm to find optimal matching between extracted and ground truth records.\n",
        "        Returns list of (extracted_idx, ground_truth_idx, similarity_score) tuples.\n",
        "        \"\"\"\n",
        "        if not extracted_records or not ground_truth_records:\n",
        "            return []\n",
        "        \n",
        "        n_extracted = len(extracted_records)\n",
        "        n_ground_truth = len(ground_truth_records)\n",
        "        \n",
        "        # Create cost matrix (we'll convert similarity to cost)\n",
        "        # Make it square by padding with zeros if needed\n",
        "        max_size = max(n_extracted, n_ground_truth)\n",
        "        cost_matrix = np.zeros((max_size, max_size))\n",
        "        \n",
        "        # Fill the cost matrix with similarity scores\n",
        "        for i in range(n_extracted):\n",
        "            for j in range(n_ground_truth):\n",
        "                similarity = self.calculate_record_similarity(extracted_records[i], ground_truth_records[j])\n",
        "                # Convert similarity to cost (higher similarity = lower cost)\n",
        "                cost_matrix[i][j] = 1.0 - similarity\n",
        "        \n",
        "        # Apply Hungarian algorithm\n",
        "        row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "        \n",
        "        # Extract valid matches (within original matrix bounds and above threshold)\n",
        "        matches = []\n",
        "        for i, j in zip(row_indices, col_indices):\n",
        "            if i < n_extracted and j < n_ground_truth:\n",
        "                similarity = 1.0 - cost_matrix[i][j]\n",
        "                if similarity > 0.0:  # Only include non-zero similarities\n",
        "                    matches.append((i, j, similarity))\n",
        "        \n",
        "        return matches\n",
        "    \n",
        "    def hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "        \"\"\"\n",
        "        Get Hungarian matching results (cached version).\n",
        "        Returns list of (extracted_idx, ground_truth_idx, similarity_score) tuples.\n",
        "        \"\"\"\n",
        "        return self._get_cached_matching(extracted_records, ground_truth_records)\n",
        "    \n",
        "    def evaluate_completeness(self, extracted_records: List[Dict]) -> float:\n",
        "        \"\"\"Evaluate field completeness.\"\"\"\n",
        "        if not extracted_records:\n",
        "            return 0.0\n",
        "        \n",
        "        total_fields = len(self.required_fields) * len(extracted_records)\n",
        "        filled_fields = 0\n",
        "        \n",
        "        for record in extracted_records:\n",
        "            for field in self.required_fields:\n",
        "                if field in record and record[field] is not None and str(record[field]).strip() != \"\":\n",
        "                    filled_fields += 1\n",
        "        \n",
        "        return filled_fields / total_fields if total_fields > 0 else 0.0\n",
        "    \n",
        "    def evaluate_record_metrics(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "        \"\"\"Calculate record-level precision, recall, and F1 using cached Hungarian algorithm.\"\"\"\n",
        "        # Use cached Hungarian algorithm to find optimal matching\n",
        "        matches = self._get_cached_matching(extracted_records, ground_truth)\n",
        "        \n",
        "        # Filter matches by minimum threshold\n",
        "        valid_matches = [match for match in matches if match[2] >= 0.5]\n",
        "        \n",
        "        # Calculate metrics\n",
        "        true_positives = len(valid_matches)\n",
        "        false_positives = len(extracted_records) - true_positives\n",
        "        false_negatives = len(ground_truth) - true_positives\n",
        "        \n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        \n",
        "        return {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'TP': true_positives,\n",
        "            'FP': false_positives,\n",
        "            'FN': false_negatives\n",
        "        }\n",
        "    \n",
        "    def evaluate_accuracy(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate extraction accuracy against ground truth with precision, recall, and F1.\"\"\"\n",
        "        if not extracted_records or not ground_truth:\n",
        "            return {\"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        \n",
        "        # Record-level metrics using cached Hungarian algorithm\n",
        "        record_metrics = self.evaluate_record_metrics(extracted_records, ground_truth)\n",
        "        \n",
        "        return {\n",
        "            \"precision\": record_metrics['precision'],\n",
        "            \"recall\": record_metrics['recall'],\n",
        "            \"f1\": record_metrics['f1'],\n",
        "            \"TP\": record_metrics['TP'],\n",
        "            \"FP\": record_metrics['FP'],\n",
        "            \"FN\": record_metrics['FN'],\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records)\n",
        "        }\n",
        "    \n",
        "    def evaluate(self, extracted_records: List[Dict], ground_truth: List[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Complete evaluation with precision, recall, and accuracy metrics.\"\"\"\n",
        "        results = {\n",
        "            \"num_extracted\": len(extracted_records),\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records),\n",
        "            \"semantic_enabled\": self.use_semantic,\n",
        "            \"semantic_threshold\": self.semantic_threshold if self.use_semantic else None\n",
        "        }\n",
        "        \n",
        "        if ground_truth:\n",
        "            accuracy_results = self.evaluate_accuracy(extracted_records, ground_truth)\n",
        "            results.update(accuracy_results)\n",
        "            results[\"num_ground_truth\"] = len(ground_truth)\n",
        "        \n",
        "        return results\n",
        " \n",
        "    def save_evaluation_to_csv(self, baseline_results: List[Dict], ground_truth: List[Dict], \n",
        "                            source_file: str, csv_dir: str = \"/nlp/data/karthik9/Sprint1/Dental/Data/csvs\", \n",
        "                            override: bool = False):\n",
        "        \"\"\"\n",
        "        Save evaluation results as CSV with ground truth and extracted pairs including TP/FP/FN labels.\n",
        "        \n",
        "        Args:\n",
        "            baseline_results: List of extracted records\n",
        "            ground_truth: List of ground truth records  \n",
        "            source_file: Name of the source markdown file\n",
        "            csv_dir: Directory to save CSV files\n",
        "            override: If True, overwrite existing results for this file\n",
        "        \"\"\"\n",
        "        from datetime import datetime\n",
        "        \n",
        "        # Ensure directory exists\n",
        "        os.makedirs(csv_dir, exist_ok=True)\n",
        "\n",
        "        from datetime import datetime\n",
        "        import pandas as pd\n",
        "        \n",
        "        # CSV file path\n",
        "        csv_path = os.path.join(csv_dir, \"co_evaluation_results.csv\")\n",
        "        \n",
        "        # Get cached Hungarian matching results\n",
        "        matches = self._get_cached_matching(baseline_results, ground_truth)\n",
        "        \n",
        "        # Prepare data rows\n",
        "        rows = []\n",
        "        \n",
        "        # Add matched pairs\n",
        "        matched_gt_indices = set()\n",
        "        matched_ext_indices = set()\n",
        "        \n",
        "        for ext_idx, gt_idx, score in matches:\n",
        "            if score >= 0.5:  # Only include good matches\n",
        "                matched_gt_indices.add(gt_idx)\n",
        "                matched_ext_indices.add(ext_idx)\n",
        "                \n",
        "                # Ground truth row (TP - correctly found)\n",
        "                gt_row = ground_truth[gt_idx].copy()\n",
        "                gt_row['data_type'] = 'ground_truth'\n",
        "                gt_row['source_file'] = source_file\n",
        "                gt_row['match_score'] = score\n",
        "                gt_row['pair_id'] = f\"{source_file}_{gt_idx}\"\n",
        "                gt_row['classification'] = 'TP'\n",
        "                gt_row['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                rows.append(gt_row)\n",
        "                \n",
        "                # Extracted row (TP - correct extraction)\n",
        "                ext_row = baseline_results[ext_idx].copy()\n",
        "                ext_row['data_type'] = 'extracted'\n",
        "                ext_row['source_file'] = source_file\n",
        "                ext_row['match_score'] = score\n",
        "                ext_row['pair_id'] = f\"{source_file}_{gt_idx}\"\n",
        "                ext_row['classification'] = 'TP'\n",
        "                ext_row['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                rows.append(ext_row)\n",
        "        \n",
        "        # Add unmatched ground truth (missing extractions - FN)\n",
        "        for gt_idx, gt_record in enumerate(ground_truth):\n",
        "            if gt_idx not in matched_gt_indices:\n",
        "                gt_row = gt_record.copy()\n",
        "                gt_row['data_type'] = 'ground_truth'\n",
        "                gt_row['source_file'] = source_file\n",
        "                gt_row['match_score'] = 0.0\n",
        "                gt_row['pair_id'] = f\"{source_file}_{gt_idx}_missing\"\n",
        "                gt_row['classification'] = 'FN'\n",
        "                gt_row['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                rows.append(gt_row)\n",
        "                \n",
        "        \n",
        "        # Add unmatched extractions (false positives - FP)\n",
        "        for ext_idx, ext_record in enumerate(baseline_results):\n",
        "            if ext_idx not in matched_ext_indices:\n",
        "                ext_row = ext_record.copy()\n",
        "                ext_row['data_type'] = 'extracted'\n",
        "                ext_row['source_file'] = source_file\n",
        "                ext_row['match_score'] = 0.0\n",
        "                ext_row['pair_id'] = f\"{source_file}_fp_{ext_idx}\"\n",
        "                ext_row['classification'] = 'FP'\n",
        "                ext_row['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                rows.append(ext_row)\n",
        "                \n",
        "        \n",
        "        # Convert to DataFrame\n",
        "        new_df = pd.DataFrame(rows)\n",
        "        \n",
        "        if not new_df.empty:\n",
        "            # Handle existing CSV\n",
        "            if os.path.exists(csv_path) and not override:\n",
        "                # Load existing and remove old results for this source_file if override\n",
        "                existing_df = pd.read_csv(csv_path)\n",
        "                if override:\n",
        "                    existing_df = existing_df[existing_df['source_file'] != source_file]\n",
        "                final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "            else:\n",
        "                final_df = new_df\n",
        "            \n",
        "            # Save to CSV\n",
        "            final_df.to_csv(csv_path, index=False)\n",
        "            \n",
        "            print(f\"Results saved to: {csv_path}\")\n",
        "            print(f\"Added {len(new_df)} rows for file: {source_file}\")\n",
        "            print(f\"Total rows in CSV: {len(final_df)}\")\n",
        "        \n",
        "        return csv_path\n",
        "    \n",
        "    def clear_cache(self):\n",
        "        \"\"\"Clear both semantic similarity cache and Hungarian matching cache.\"\"\"\n",
        "        if self.use_semantic:\n",
        "            self.cache.clear()\n",
        "        # Clear Hungarian matching cache\n",
        "        self._matching_cache.clear()\n",
        "        self._cache_key = None\n",
        "\n",
        "    def cache_stats(self):\n",
        "        \"\"\"Get cache statistics.\"\"\"\n",
        "        stats = {'hungarian_cache_size': len(self._matching_cache)}\n",
        "        \n",
        "        if self.use_semantic:\n",
        "            stats.update({\n",
        "                'semantic_cache_size': len(self.cache),\n",
        "                'cache_directory': self.cache.directory\n",
        "            })\n",
        "        else:\n",
        "            stats['cache_enabled'] = False\n",
        "            \n",
        "        return stats\n",
        "\n",
        "# Example usage:\n",
        "# For semantic matching with caching (default)\n",
        "evaluator = MedicalExtractionEvaluator(use_semantic=True, semantic_threshold=0.8, cache_dir='.semantic_cache')\n",
        "\n",
        "# Clear cache if needed\n",
        "# evaluator.clear_cache()\n",
        "\n",
        "# Get cache stats\n",
        "# stats = evaluator.cache_stats()\n",
        "# print(f\"Hungarian cache contains {stats['hungarian_cache_size']} matching results\")\n",
        "# if 'semantic_cache_size' in stats:\n",
        "#     print(f\"Semantic cache contains {stats['semantic_cache_size']} embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import hashlib\n",
        "import json\n",
        "import os\n",
        "from typing import Any, Dict, List, Tuple, Optional\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import aiofiles\n",
        "import aiohttp\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "class AsyncLLMCache:\n",
        "    \"\"\"Async cache for LLM responses to avoid repeated API calls.\"\"\"\n",
        "    \n",
        "    def __init__(self, cache_dir: str = '.llm_cache'):\n",
        "        self.cache_dir = cache_dir\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "        self.cache_file = os.path.join(cache_dir, 'llm_cache.json')\n",
        "        self._memory_cache = {}\n",
        "        self._loaded = False\n",
        "    \n",
        "    async def _load_cache(self):\n",
        "        \"\"\"Load cache from disk on first use.\"\"\"\n",
        "        if self._loaded:\n",
        "            return\n",
        "            \n",
        "        try:\n",
        "            if os.path.exists(self.cache_file):\n",
        "                async with aiofiles.open(self.cache_file, 'r') as f:\n",
        "                    content = await f.read()\n",
        "                    self._memory_cache = json.loads(content)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load LLM cache: {e}\")\n",
        "            self._memory_cache = {}\n",
        "        \n",
        "        self._loaded = True\n",
        "    \n",
        "    async def get(self, key: str) -> Optional[float]:\n",
        "        \"\"\"Get cached result.\"\"\"\n",
        "        await self._load_cache()\n",
        "        return self._memory_cache.get(key)\n",
        "    \n",
        "    async def set(self, key: str, value: float):\n",
        "        \"\"\"Set cached result.\"\"\"\n",
        "        await self._load_cache()\n",
        "        self._memory_cache[key] = value\n",
        "        \n",
        "        # Save to disk periodically (every 10 new entries)\n",
        "        if len(self._memory_cache) % 10 == 0:\n",
        "            await self._save_cache()\n",
        "    \n",
        "    async def _save_cache(self):\n",
        "        \"\"\"Save cache to disk.\"\"\"\n",
        "        try:\n",
        "            async with aiofiles.open(self.cache_file, 'w') as f:\n",
        "                await f.write(json.dumps(self._memory_cache, indent=2))\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not save LLM cache: {e}\")\n",
        "    \n",
        "    async def clear(self):\n",
        "        \"\"\"Clear cache.\"\"\"\n",
        "        self._memory_cache = {}\n",
        "        if os.path.exists(self.cache_file):\n",
        "            os.remove(self.cache_file)\n",
        "\n",
        "class MedicalExtractionEvaluator:\n",
        "    \"\"\"Async evaluator for medical data extraction quality using GPT-4o for semantic matching with caching.\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 \n",
        "                 use_llm_semantic=True, \n",
        "                 semantic_threshold=0.8, \n",
        "                 cache_dir='.evaluation_cache',\n",
        "                 max_concurrent_requests=10):\n",
        "        \n",
        "        self.required_fields = [\n",
        "            'First_Author', 'Population', 'Intervention_Code', 'Intervention_Description', \n",
        "            'Outcome_Code', 'Outcome_Other_Specify',\n",
        "            \n",
        "            # Pain Relief Fields\n",
        "            'Pain_Relief_Type_Of_Scale', 'Pain_Relief_Name_Of_Scale', 'Pain_Relief_Range_Of_Scale',\n",
        "            'Pain_Relief_Copy_Paste_Scale', 'Pain_Relief_All_Responses',\n",
        "            \n",
        "            # Global Efficacy Fields  \n",
        "            'Global_Efficacy_Type_Of_Scale', 'Global_Efficacy_Name_Of_Scale', 'Global_Efficacy_Range_Of_Scale',\n",
        "            'Global_Efficacy_Copy_Paste_Scale', 'Global_Efficacy_All_Responses',\n",
        "            \n",
        "            # TOTPAR Fields\n",
        "            'TOTPAR_Copy_Paste_Scale', 'TOTPAR_Definition', 'TOTPAR_Name_Of_Scale',\n",
        "            'TOTPAR_Type_Of_Scale', 'TOTPAR_Range_Of_Scale', 'TOTPAR_Copy_Paste_Questions',\n",
        "            'TOTPAR_All_Responses',\n",
        "            \n",
        "            # SPID Fields\n",
        "            'SPID_Copy_Paste_Scale', 'SPID_Definition', 'SPID_Name_Of_Scale', \n",
        "            'SPID_Type_Of_Scale', 'SPID_Range_Of_Scale', 'SPID_Copy_Paste_Questions',\n",
        "            'SPID_All_Responses',\n",
        "            \n",
        "            # Statistical Measures\n",
        "            'N_Analyzed', 'Measure_Of_Central_Tendency', 'Central_Tendency_Value',\n",
        "            'Measure_Of_Variability', 'Variability_Value', 'Other_Reporting_Method',\n",
        "            'Comments'\n",
        "        ]\n",
        "        \n",
        "        # LLM semantic matching setup\n",
        "        self.use_llm_semantic = use_llm_semantic\n",
        "        self.semantic_threshold = semantic_threshold\n",
        "        self.max_concurrent_requests = max_concurrent_requests\n",
        "        \n",
        "        # Initialize OpenAI client\n",
        "        self.openai_client = AsyncOpenAI(api_key= os.environ[\"OPENAI_API_KEY\"])\n",
        "        \n",
        "        # Cache setup\n",
        "        self.llm_cache = AsyncLLMCache(cache_dir)\n",
        "        self._matching_cache = {}\n",
        "        \n",
        "        # Semaphore for rate limiting\n",
        "        self._semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
        "        \n",
        "        # Fields that benefit from LLM semantic matching\n",
        "        self.semantic_fields = [\n",
        "            'Population',\n",
        "            'Intervention_Description', \n",
        "            'Outcome_Other_Specify',\n",
        "            'Pain_Relief_Type_Of_Scale', 'Pain_Relief_Name_Of_Scale', 'Pain_Relief_Copy_Paste_Scale',\n",
        "            'Global_Efficacy_Type_Of_Scale', 'Global_Efficacy_Name_Of_Scale', 'Global_Efficacy_Copy_Paste_Scale', \n",
        "            'TOTPAR_Copy_Paste_Scale', 'TOTPAR_Definition', 'TOTPAR_Name_Of_Scale',\n",
        "            'SPID_Copy_Paste_Scale', 'SPID_Definition', 'SPID_Name_Of_Scale',\n",
        "            'Measure_Of_Central_Tendency', 'Measure_Of_Variability', 'Other_Reporting_Method',\n",
        "            'Comments'\n",
        "        ]\n",
        "        \n",
        "        # Fields that need exact matching\n",
        "        self.exact_fields = [\n",
        "            'First_Author', 'Population', 'Intervention_Code', 'Outcome_Code',\n",
        "            'Pain_Relief_Range_Of_Scale', 'Pain_Relief_All_Responses',\n",
        "            'Global_Efficacy_Range_Of_Scale', 'Global_Efficacy_All_Responses',\n",
        "            'TOTPAR_Type_Of_Scale', 'TOTPAR_Range_Of_Scale', 'TOTPAR_Copy_Paste_Questions', 'TOTPAR_All_Responses',\n",
        "            'SPID_Type_Of_Scale', 'SPID_Range_Of_Scale', 'SPID_Copy_Paste_Questions', 'SPID_All_Responses',\n",
        "            'N_Analyzed', 'Central_Tendency_Value', 'Variability_Value'\n",
        "        ]\n",
        "    \n",
        "    def _generate_cache_key(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> str:\n",
        "        \"\"\"Generate a unique cache key for the given extracted records and ground truth.\"\"\"\n",
        "        ext_str = str(sorted([str(sorted(record.items())) for record in extracted_records]))\n",
        "        gt_str = str(sorted([str(sorted(record.items())) for record in ground_truth]))\n",
        "        combined = ext_str + gt_str\n",
        "        return hashlib.md5(combined.encode('utf-8')).hexdigest()\n",
        "    \n",
        "    def _get_similarity_cache_key(self, text1: str, text2: str, field_name: str) -> str:\n",
        "        \"\"\"Generate cache key for similarity comparison.\"\"\"\n",
        "        combined = f\"{field_name}|{text1}|{text2}\"\n",
        "        return hashlib.md5(combined.encode('utf-8')).hexdigest()\n",
        "    \n",
        "    async def _llm_semantic_similarity(self, text1: str, text2: str, field_name: str) -> float:\n",
        "        \"\"\"Use GPT-4o to determine semantic similarity between two texts.\"\"\"\n",
        "        async with self._semaphore:\n",
        "            cache_key = self._get_similarity_cache_key(text1, text2, field_name)\n",
        "            \n",
        "            # Check cache first\n",
        "            cached_result = await self.llm_cache.get(cache_key)\n",
        "            if cached_result is not None:\n",
        "                return cached_result\n",
        "            \n",
        "            # Prepare prompt for GPT-4o\n",
        "            prompt = f\"\"\"Compare these two medical data extraction values for the field '{field_name}' and determine if they are semantically equivalent.\n",
        "\n",
        "Value 1: \"{text1}\"\n",
        "Value 2: \"{text2}\"\n",
        "\n",
        "Consider:\n",
        "- Medical terminology and abbreviations\n",
        "- Different ways to express the same concept\n",
        "- Numerical equivalents (e.g., \"four\" vs \"4\")\n",
        "- Minor formatting differences\n",
        "- Synonymous medical terms\n",
        "\n",
        "Respond with ONLY a number between 0.0 and 1.0 where:\n",
        "- 1.0 = Semantically identical/equivalent\n",
        "- 0.8-0.9 = Very similar meaning with minor differences\n",
        "- 0.6-0.7 = Similar meaning but notable differences\n",
        "- 0.4-0.5 = Somewhat related but different meanings\n",
        "- 0.0-0.3 = Different meanings or unrelated\n",
        "\n",
        "Score:\"\"\"\n",
        "\n",
        "            try:\n",
        "                response = await self.openai_client.chat.completions.create(\n",
        "                    model=\"gpt-4o\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": \"You are a medical data extraction expert. Provide only numerical similarity scores.\"},\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    max_tokens=10,\n",
        "                    temperature=0.0\n",
        "                )\n",
        "                \n",
        "                score_text = response.choices[0].message.content.strip()\n",
        "                score = float(score_text)\n",
        "                score = max(0.0, min(1.0, score))  # Clamp between 0 and 1\n",
        "                \n",
        "                # Cache the result\n",
        "                await self.llm_cache.set(cache_key, score)\n",
        "                return score\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error in LLM semantic similarity: {e}\")\n",
        "                # Fallback to exact matching\n",
        "                return 1.0 if text1.lower().strip() == text2.lower().strip() else 0.0\n",
        "    \n",
        "    def normalize_value(self, value: Any) -> str:\n",
        "        \"\"\"Normalize values for comparison.\"\"\"\n",
        "        if value is None:\n",
        "            return \"\"\n",
        "        return str(value).strip().lower()\n",
        "    \n",
        "    async def field_match_score(self, extracted_value: Any, ground_truth_value: Any, field_name: str) -> float:\n",
        "        \"\"\"Calculate field-level match score (exact or LLM semantic).\"\"\"\n",
        "        \n",
        "        # Handle None/empty values\n",
        "        ext_val = str(extracted_value).strip() if extracted_value is not None else \"\"\n",
        "        gt_val = str(ground_truth_value).strip() if ground_truth_value is not None else \"\"\n",
        "        \n",
        "        # Both empty\n",
        "        if not ext_val and not gt_val:\n",
        "            return 1.0\n",
        "        \n",
        "        # One empty, one not\n",
        "        if not ext_val or not gt_val:\n",
        "            return 0.0\n",
        "        \n",
        "        # Exact matching for certain fields\n",
        "        if field_name in self.exact_fields:\n",
        "            return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "        \n",
        "        # LLM semantic matching for text fields\n",
        "        if self.use_llm_semantic and field_name in self.semantic_fields:\n",
        "            similarity = await self._llm_semantic_similarity(ext_val, gt_val, field_name)\n",
        "            return 1.0 if similarity >= self.semantic_threshold else 0.0\n",
        "        \n",
        "        # Default exact matching\n",
        "        return 1.0 if ext_val.lower() == gt_val.lower() else 0.0\n",
        "    \n",
        "    async def calculate_record_similarity(self, extracted_record: Dict, ground_truth_record: Dict) -> float:\n",
        "        \"\"\"Calculate overall similarity score between two records.\"\"\"\n",
        "        tasks = []\n",
        "        field_names = []\n",
        "        \n",
        "        for field in self.required_fields:\n",
        "            if field in extracted_record and field in ground_truth_record:\n",
        "                task = self.field_match_score(\n",
        "                    extracted_record[field], \n",
        "                    ground_truth_record[field], \n",
        "                    field\n",
        "                )\n",
        "                tasks.append(task)\n",
        "                field_names.append(field)\n",
        "        \n",
        "        if not tasks:\n",
        "            return 0.0\n",
        "        \n",
        "        # Run all field comparisons concurrently\n",
        "        match_scores = await asyncio.gather(*tasks)\n",
        "        \n",
        "        total_score = sum(match_scores)\n",
        "        return total_score / len(match_scores)\n",
        "    \n",
        "    async def _compute_hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "        \"\"\"\n",
        "        Async computation of Hungarian algorithm to find optimal matching.\n",
        "        \"\"\"\n",
        "        if not extracted_records or not ground_truth_records:\n",
        "            return []\n",
        "        \n",
        "        n_extracted = len(extracted_records)\n",
        "        n_ground_truth = len(ground_truth_records)\n",
        "        \n",
        "        # Create all similarity calculation tasks\n",
        "        similarity_tasks = []\n",
        "        indices = []\n",
        "        \n",
        "        for i in range(n_extracted):\n",
        "            for j in range(n_ground_truth):\n",
        "                task = self.calculate_record_similarity(extracted_records[i], ground_truth_records[j])\n",
        "                similarity_tasks.append(task)\n",
        "                indices.append((i, j))\n",
        "        \n",
        "        # Run all similarity calculations concurrently\n",
        "        similarities = await asyncio.gather(*similarity_tasks)\n",
        "        \n",
        "        # Build cost matrix\n",
        "        max_size = max(n_extracted, n_ground_truth)\n",
        "        cost_matrix = np.zeros((max_size, max_size))\n",
        "        \n",
        "        for (i, j), similarity in zip(indices, similarities):\n",
        "            cost_matrix[i][j] = 1.0 - similarity\n",
        "        \n",
        "        # Apply Hungarian algorithm\n",
        "        row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "        \n",
        "        # Extract valid matches\n",
        "        matches = []\n",
        "        for i, j in zip(row_indices, col_indices):\n",
        "            if i < n_extracted and j < n_ground_truth:\n",
        "                similarity = 1.0 - cost_matrix[i][j]\n",
        "                if similarity > 0.0:\n",
        "                    matches.append((i, j, similarity))\n",
        "        \n",
        "        return matches\n",
        "    \n",
        "    async def hungarian_matching(self, extracted_records: List[Dict], ground_truth_records: List[Dict]) -> List[Tuple[int, int, float]]:\n",
        "        \"\"\"\n",
        "        Get Hungarian matching results with caching.\n",
        "        \"\"\"\n",
        "        cache_key = self._generate_cache_key(extracted_records, ground_truth_records)\n",
        "        \n",
        "        if cache_key in self._matching_cache:\n",
        "            return self._matching_cache[cache_key]\n",
        "        \n",
        "        matches = await self._compute_hungarian_matching(extracted_records, ground_truth_records)\n",
        "        self._matching_cache[cache_key] = matches\n",
        "        \n",
        "        return matches\n",
        "    \n",
        "    def evaluate_completeness(self, extracted_records: List[Dict]) -> float:\n",
        "        \"\"\"Evaluate field completeness.\"\"\"\n",
        "        if not extracted_records:\n",
        "            return 0.0\n",
        "        \n",
        "        total_fields = len(self.required_fields) * len(extracted_records)\n",
        "        filled_fields = 0\n",
        "        \n",
        "        for record in extracted_records:\n",
        "            for field in self.required_fields:\n",
        "                if field in record and record[field] is not None and str(record[field]).strip() != \"\":\n",
        "                    filled_fields += 1\n",
        "        \n",
        "        return filled_fields / total_fields if total_fields > 0 else 0.0\n",
        "    \n",
        "    async def evaluate_record_metrics(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "        \"\"\"Calculate record-level precision, recall, and F1 using async Hungarian algorithm.\"\"\"\n",
        "        matches = await self.hungarian_matching(extracted_records, ground_truth)\n",
        "        \n",
        "        # Filter matches by minimum threshold\n",
        "        valid_matches = [match for match in matches if match[2] >= 0.5]\n",
        "        \n",
        "        # Calculate metrics\n",
        "        true_positives = len(valid_matches)\n",
        "        false_positives = len(extracted_records) - true_positives\n",
        "        false_negatives = len(ground_truth) - true_positives\n",
        "        \n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        \n",
        "        return {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'TP': true_positives,\n",
        "            'FP': false_positives,\n",
        "            'FN': false_negatives\n",
        "        }\n",
        "    \n",
        "    async def evaluate_accuracy(self, extracted_records: List[Dict], ground_truth: List[Dict]) -> Dict[str, float]:\n",
        "        \"\"\"Async evaluation of extraction accuracy against ground truth.\"\"\"\n",
        "        if not extracted_records or not ground_truth:\n",
        "            return {\"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
        "        \n",
        "        record_metrics = await self.evaluate_record_metrics(extracted_records, ground_truth)\n",
        "        \n",
        "        return {\n",
        "            \"precision\": record_metrics['precision'],\n",
        "            \"recall\": record_metrics['recall'],\n",
        "            \"f1\": record_metrics['f1'],\n",
        "            \"TP\": record_metrics['TP'],\n",
        "            \"FP\": record_metrics['FP'],\n",
        "            \"FN\": record_metrics['FN'],\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records)\n",
        "        }\n",
        "    \n",
        "    async def evaluate(self, extracted_records: List[Dict], ground_truth: List[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Complete async evaluation with precision, recall, and accuracy metrics.\"\"\"\n",
        "        results = {\n",
        "            \"num_extracted\": len(extracted_records),\n",
        "            \"completeness\": self.evaluate_completeness(extracted_records),\n",
        "            \"llm_semantic_enabled\": self.use_llm_semantic,\n",
        "            \"semantic_threshold\": self.semantic_threshold if self.use_llm_semantic else None\n",
        "        }\n",
        "        \n",
        "        if ground_truth:\n",
        "            accuracy_results = await self.evaluate_accuracy(extracted_records, ground_truth)\n",
        "            results.update(accuracy_results)\n",
        "            results[\"num_ground_truth\"] = len(ground_truth)\n",
        "        \n",
        "        return results\n",
        " \n",
        "    async def save_evaluation_to_csv(self, baseline_results: List[Dict], ground_truth: List[Dict], \n",
        "                                   source_file: str, csv_dir: str = \"/nlp/data/karthik9/Sprint1/Dental/Data/csvs\", \n",
        "                                   override: bool = False):\n",
        "        \"\"\"\n",
        "        Async save evaluation results as CSV with ground truth and extracted pairs.\n",
        "        \"\"\"\n",
        "        os.makedirs(csv_dir, exist_ok=True)\n",
        "        csv_path = os.path.join(csv_dir, \"co_evaluation_results.csv\")\n",
        "        \n",
        "        # Get cached Hungarian matching results\n",
        "        matches = await self.hungarian_matching(baseline_results, ground_truth)\n",
        "        \n",
        "        # Prepare data rows\n",
        "        rows = []\n",
        "        \n",
        "        # Add matched pairs\n",
        "        matched_gt_indices = set()\n",
        "        matched_ext_indices = set()\n",
        "        \n",
        "        for ext_idx, gt_idx, score in matches:\n",
        "            if score >= 0.5:\n",
        "                matched_gt_indices.add(gt_idx)\n",
        "                matched_ext_indices.add(ext_idx)\n",
        "                \n",
        "                # Ground truth row (TP)\n",
        "                gt_row = ground_truth[gt_idx].copy()\n",
        "                gt_row.update({\n",
        "                    'data_type': 'ground_truth',\n",
        "                    'source_file': source_file,\n",
        "                    'match_score': score,\n",
        "                    'pair_id': f\"{source_file}_{gt_idx}\",\n",
        "                    'classification': 'TP',\n",
        "                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                })\n",
        "                rows.append(gt_row)\n",
        "                \n",
        "                # Extracted row (TP)\n",
        "                ext_row = baseline_results[ext_idx].copy()\n",
        "                ext_row.update({\n",
        "                    'data_type': 'extracted',\n",
        "                    'source_file': source_file,\n",
        "                    'match_score': score,\n",
        "                    'pair_id': f\"{source_file}_{gt_idx}\",\n",
        "                    'classification': 'TP',\n",
        "                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                })\n",
        "                rows.append(ext_row)\n",
        "        \n",
        "        # Add unmatched ground truth (FN)\n",
        "        for gt_idx, gt_record in enumerate(ground_truth):\n",
        "            if gt_idx not in matched_gt_indices:\n",
        "                gt_row = gt_record.copy()\n",
        "                gt_row.update({\n",
        "                    'data_type': 'ground_truth',\n",
        "                    'source_file': source_file,\n",
        "                    'match_score': 0.0,\n",
        "                    'pair_id': f\"{source_file}_{gt_idx}_missing\",\n",
        "                    'classification': 'FN',\n",
        "                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                })\n",
        "                rows.append(gt_row)\n",
        "        \n",
        "        # Add unmatched extractions (FP)\n",
        "        for ext_idx, ext_record in enumerate(baseline_results):\n",
        "            if ext_idx not in matched_ext_indices:\n",
        "                ext_row = ext_record.copy()\n",
        "                ext_row.update({\n",
        "                    'data_type': 'extracted',\n",
        "                    'source_file': source_file,\n",
        "                    'match_score': 0.0,\n",
        "                    'pair_id': f\"{source_file}_fp_{ext_idx}\",\n",
        "                    'classification': 'FP',\n",
        "                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                })\n",
        "                rows.append(ext_row)\n",
        "        \n",
        "        # Convert to DataFrame and save\n",
        "        new_df = pd.DataFrame(rows)\n",
        "        \n",
        "        if not new_df.empty:\n",
        "            if os.path.exists(csv_path) and not override:\n",
        "                existing_df = pd.read_csv(csv_path)\n",
        "                if override:\n",
        "                    existing_df = existing_df[existing_df['source_file'] != source_file]\n",
        "                final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "            else:\n",
        "                final_df = new_df\n",
        "            \n",
        "            final_df.to_csv(csv_path, index=False)\n",
        "            \n",
        "            print(f\"Results saved to: {csv_path}\")\n",
        "            print(f\"Added {len(new_df)} rows for file: {source_file}\")\n",
        "            print(f\"Total rows in CSV: {len(final_df)}\")\n",
        "        \n",
        "        return csv_path\n",
        "    \n",
        "    async def clear_cache(self):\n",
        "        \"\"\"Clear all caches.\"\"\"\n",
        "        await self.llm_cache.clear()\n",
        "        self._matching_cache.clear()\n",
        "    \n",
        "    async def cache_stats(self):\n",
        "        \"\"\"Get cache statistics.\"\"\"\n",
        "        await self.llm_cache._load_cache()\n",
        "        return {\n",
        "            'hungarian_cache_size': len(self._matching_cache),\n",
        "            'llm_cache_size': len(self.llm_cache._memory_cache),\n",
        "            'cache_directory': self.llm_cache.cache_dir\n",
        "        }\n",
        "\n",
        "evaluator = MedicalExtractionEvaluator(\n",
        "        use_llm_semantic=True,\n",
        "        semantic_threshold=0.8,\n",
        "        cache_dir='.evaluation_cache',\n",
        "        max_concurrent_requests=20  # Adjust based on your rate limits\n",
        "    )\n",
        "\n",
        "# # Example usage:\n",
        "# async def main():\n",
        "#     # Initialize evaluator (will use OPENAI_API_KEY environment variable)\n",
        "    \n",
        "    \n",
        "#     # Example data\n",
        "#     extracted_records = [{\"First_Author\": \"Smith\", \"Population\": \"Adults\"}]\n",
        "#     ground_truth = [{\"First_Author\": \"Smith\", \"Population\": \"Adult patients\"}]\n",
        "    \n",
        "#     # Run evaluation\n",
        "#     results = await evaluator.evaluate(extracted_records, ground_truth)\n",
        "#     print(\"Evaluation results:\", results)\n",
        "    \n",
        "#     # Save to CSV\n",
        "#     await evaluator.save_evaluation_to_csv(extracted_records, ground_truth, \"test_file.md\")\n",
        "    \n",
        "#     # Get cache stats\n",
        "#     stats = await evaluator.cache_stats()\n",
        "#     print(\"Cache stats:\", stats)\n",
        "\n",
        "# # Run the async example\n",
        "# await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def save_evaluation_to_json(evaluation_results, source_file, json_path=\"co_evaluation_results.json\"):\n",
        "    \"\"\"\n",
        "    Save evaluation results to JSON file, appending if file exists.\n",
        "    \n",
        "    Args:\n",
        "        evaluation_results: Dictionary of evaluation metrics\n",
        "        source_file: Name of the source file being evaluated\n",
        "        json_path: Path to the JSON file to save/append to\n",
        "    \"\"\"\n",
        "    \n",
        "    # Prepare the new entry\n",
        "    new_entry = {\n",
        "        \"source_file\": source_file,\n",
        "        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        **{k: v for k, v in evaluation_results.items() if k != 'field_accuracies'}\n",
        "    }\n",
        "    \n",
        "    # Ensure directory exists\n",
        "    dir_path = os.path.dirname(json_path)\n",
        "    if dir_path:  # Only create directory if there is one\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "    \n",
        "    # Load existing data or create empty list\n",
        "    if os.path.exists(json_path):\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    else:\n",
        "        data = []\n",
        "    \n",
        "    # Check if source_file already exists\n",
        "    existing_index = None\n",
        "    for i, entry in enumerate(data):\n",
        "        if entry.get('source_file') == source_file:\n",
        "            existing_index = i\n",
        "            break\n",
        "    \n",
        "    if existing_index is not None:\n",
        "        # Replace existing entry\n",
        "        data[existing_index] = new_entry\n",
        "        print(f\"Updated existing results for {source_file}\")\n",
        "    else:\n",
        "        # Append new entry\n",
        "        data.append(new_entry)\n",
        "        print(f\"Added new results for {source_file}\")\n",
        "    \n",
        "    # Save to JSON\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "    \n",
        "    print(f\"Results saved to: {json_path}\")\n",
        "    return json_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Initial Baseline Extraction Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/11 12:37:01 WARNING dspy.primitives.module: Calling module.forward(...) on MedicalDataExtractionPipeline directly is discouraged. Please use module(...) instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running baseline extraction...\n",
            "==================================================\n",
            "Extracting study metadata...\n",
            "Study metadata: {'first_author': 'Kellstein', 'population_code': '2'}\n",
            "Extracting interventions...\n",
            "Found 5 interventions\n",
            "[{'intervention_code': 11, 'intervention_description': 'Placebo'}, {'intervention_code': 6, 'intervention_description': 'Ibuprofen 400 mg'}, {'intervention_code': 1, 'intervention_description': 'Ibuprofen 200 mg + Acetaminophen 500 mg'}, {'intervention_code': 1, 'intervention_description': 'Ibuprofen 250 mg + Acetaminophen 500 mg'}, {'intervention_code': 1, 'intervention_description': 'Ibuprofen 300 mg + Acetaminophen 500 mg'}]\n",
            "Processing intervention 1: Placebo\n",
            "Found 8 outcome types for this intervention\n",
            "  Processing outcome 1: Code 1 (pain_relief) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 2: Code 2 (pain_relief) at 7 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 3: Code 3 (pain_relief) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 4: Code 5 (totpar) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 5: Code 7 (totpar) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 6: Code 9 (spid) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 7: Code 11 (spid) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 8: Code 12 (spid) at 12 hours\n",
            "    ✓ Structured record created\n",
            "Processing intervention 2: Ibuprofen 400 mg\n",
            "Found 8 outcome types for this intervention\n",
            "  Processing outcome 1: Code 1 (pain_relief) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 2: Code 2 (pain_relief) at 7 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 3: Code 3 (pain_relief) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 4: Code 5 (totpar) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 5: Code 7 (totpar) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 6: Code 9 (spid) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 7: Code 11 (spid) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 8: Code 12 (spid) at 12 hours\n",
            "    ✓ Structured record created\n",
            "Processing intervention 3: Ibuprofen 200 mg + Acetaminophen 500 mg\n",
            "Found 8 outcome types for this intervention\n",
            "  Processing outcome 1: Code 1 (pain_relief) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 2: Code 2 (pain_relief) at 7 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 3: Code 3 (pain_relief) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 4: Code 5 (totpar) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 5: Code 7 (totpar) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 6: Code 9 (spid) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 7: Code 11 (spid) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 8: Code 12 (spid) at 12 hours\n",
            "    ✓ Structured record created\n",
            "Processing intervention 4: Ibuprofen 250 mg + Acetaminophen 500 mg\n",
            "Found 8 outcome types for this intervention\n",
            "  Processing outcome 1: Code 1 (pain_relief) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 2: Code 2 (pain_relief) at 7 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 3: Code 3 (pain_relief) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 4: Code 5 (totpar) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 5: Code 7 (totpar) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 6: Code 9 (spid) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 7: Code 11 (spid) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 8: Code 12 (spid) at 12 hours\n",
            "    ✓ Structured record created\n",
            "Processing intervention 5: Ibuprofen 300 mg + Acetaminophen 500 mg\n",
            "Found 8 outcome types for this intervention\n",
            "  Processing outcome 1: Code 1 (pain_relief) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 2: Code 2 (pain_relief) at 7 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 3: Code 3 (pain_relief) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 4: Code 5 (totpar) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 5: Code 7 (totpar) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 6: Code 9 (spid) at 6 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 7: Code 11 (spid) at 8 hours\n",
            "    ✓ Structured record created\n",
            "  Processing outcome 8: Code 12 (spid) at 12 hours\n",
            "    ✓ Structured record created\n",
            "Total records extracted: 40\n",
            "⚠️  Output file already exists: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2518_Kellstein_md/2518_Kellstein_co.json\n",
            "   Use override=True to overwrite, or file will be skipped\n",
            "\n",
            "Baseline extraction completed. Extracted 40 records.\n",
            "\n",
            "First extracted record:\n",
            "------------------------------\n",
            "First_Author: Kellstein\n",
            "Population: 2\n",
            "Intervention_Code: 11\n",
            "Intervention_Description: Placebo\n",
            "Outcome_Code: 1\n",
            "Outcome_Other_Specify: NA\n",
            "Pain_Relief_Type_Of_Scale: ordinal, categorical\n",
            "Pain_Relief_Name_Of_Scale: 5-point categorical pain relief rating (PRR) scale\n",
            "Pain_Relief_Range_Of_Scale: 0-4\n",
            "Pain_Relief_Copy_Paste_Scale: pain relief, using a 5-point categorical pain relief rating (PRR) scale (0=none, 1=a little, 2=some, 3=a lot, and 4=complete)\n",
            "Pain_Relief_All_Responses: complete (4), a lot (3), some (2), a little (1), none (0)\n",
            "Global_Efficacy_Type_Of_Scale: NA\n",
            "Global_Efficacy_Name_Of_Scale: NA\n",
            "Global_Efficacy_Range_Of_Scale: NA\n",
            "Global_Efficacy_Copy_Paste_Scale: NA\n",
            "Global_Efficacy_All_Responses: NA\n",
            "TOTPAR_Copy_Paste_Scale: NA\n",
            "TOTPAR_Definition: NA\n",
            "TOTPAR_Name_Of_Scale: NA\n",
            "TOTPAR_Type_Of_Scale: NA\n",
            "TOTPAR_Range_Of_Scale: NA\n",
            "TOTPAR_Copy_Paste_Questions: NA\n",
            "TOTPAR_All_Responses: NA\n",
            "SPID_Copy_Paste_Scale: NA\n",
            "SPID_Definition: NA\n",
            "SPID_Name_Of_Scale: NA\n",
            "SPID_Type_Of_Scale: NA\n",
            "SPID_Range_Of_Scale: NA\n",
            "SPID_Copy_Paste_Questions: NA\n",
            "SPID_All_Responses: NA\n",
            "N_Analyzed: 30\n",
            "Measure_Of_Central_Tendency: mean\n",
            "Central_Tendency_Value: 2.8\n",
            "Measure_Of_Variability: SD\n",
            "Variability_Value: 5.4\n",
            "Other_Reporting_Method: NA\n",
            "Comments: Data is for pain relief at 6 hours. Data extracted directly from Table 2. Scale information extracted from the Methods section, subsection 2.2 Study Assessments and Endpoints. The PRR self-assessments took place at 0.25, 0.5, 1, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12 h post-treatment, after taking study medication, immediately before taking rescue medication, or at time of study withdrawal.\n",
            "\n",
            "==================================================\n",
            "BASELINE EVALUATION RESULTS:\n",
            "==================================================\n",
            "num_extracted: 40\n",
            "completeness: 0.995945945945946\n",
            "llm_semantic_enabled: True\n",
            "semantic_threshold: 0.8\n",
            "precision: 0.35\n",
            "recall: 0.56\n",
            "f1: 0.4307692307692308\n",
            "TP: 14\n",
            "FP: 26\n",
            "FN: 11\n",
            "num_ground_truth: 25\n",
            "Added new results for /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2518_Kellstein_md/2518_Kellstein_md.json\n",
            "Results saved to: co_evaluation_results.json\n",
            "\n",
            "==================================================\n",
            "SAVING RESULTS TO CSV...\n",
            "==================================================\n",
            "Results saved to: /nlp/data/karthik9/Sprint1/Dental/Data/csvs/co_evaluation_results.csv\n",
            "Added 65 rows for file: /nlp/data/karthik9/Sprint1/Dental/Data/acute_pain_mds/2518_Kellstein_md/2518_Kellstein_md.json\n",
            "Total rows in CSV: 65\n",
            "Results successfully saved to: /nlp/data/karthik9/Sprint1/Dental/Data/csvs/co_evaluation_results.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"Running baseline extraction...\")\n",
        "print(\"=\" * 50) \n",
        "\n",
        "try:\n",
        "    baseline_prediction = extraction_pipeline.run_and_save(markdown_content, source_file)\n",
        "    baseline_results = baseline_prediction.extracted_records if hasattr(baseline_prediction, 'extracted_records') else []\n",
        "    print(f\"\\nBaseline extraction completed. Extracted {len(baseline_results)} records.\")\n",
        "    \n",
        "    if baseline_results:\n",
        "        print(\"\\nFirst extracted record:\")\n",
        "        print(\"-\" * 30)\n",
        "        for key, value in baseline_results[0].items():\n",
        "            print(f\"{key}: {value}\")\n",
        "    \n",
        "    # Evaluate baseline performance\n",
        "    baseline_evaluation = await evaluator.evaluate(baseline_results, one_study_records)\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"BASELINE EVALUATION RESULTS:\")\n",
        "    print(\"=\" * 50)\n",
        "    for key, value in baseline_evaluation.items():\n",
        "        if key != 'field_accuracies':\n",
        "            print(f\"{key}: {value}\")\n",
        "    \n",
        "    save_evaluation_to_json(baseline_evaluation, source_file)\n",
        "    # ADD THIS NEW CODE: Save results to CSV\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"SAVING RESULTS TO CSV...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    csv_path = await evaluator.save_evaluation_to_csv(\n",
        "        baseline_results, \n",
        "        one_study_records, \n",
        "        source_file=source_file,  # or whatever your source file variable is\n",
        "        override=False  # Set True if you want to replace existing results for this file\n",
        "    )\n",
        "\n",
        "    # # matrix_result = evaluator.create_field_matching_matrix(baseline_results, one_study_records)\n",
        "        \n",
        "    #     # # Print summary\n",
        "    #     # summary = matrix_result['summary']\n",
        "    #     # print(f\"Total Ground Truth Records: {summary['total_gt_records']}\")\n",
        "    #     # print(f\"Matched Records: {summary['matched_records']}\")\n",
        "    #     # print(f\"Missing Records: {summary['missing_records']}\")\n",
        "    #     # print()\n",
        "    \n",
        "    print(f\"Results successfully saved to: {csv_path}\")\n",
        "                                        \n",
        "except Exception as e:\n",
        "    print(f\"Error in baseline extraction: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    baseline_results = []\n",
        "    baseline_evaluation = {\"completeness\": 0.0, \"overall_accuracy\": 0.0}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.828098125000001"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])  # cost in USD, as calculated by LiteLLM for certain providers\n",
        "cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Example Generation and Few-Shot Learning Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating examples for study: Qi\n",
            "Population code: 2\n",
            "Found 3 interventions:\n",
            "  - Acetaminophen 1000mg: 15 outcomes\n",
            "  - Acetaminophen 650mg: 15 outcomes\n",
            "  - : 15 outcomes\n",
            "✓ Created 3 structure examples\n",
            "\n",
            "📊 TOTAL EXAMPLES CREATED: 8\n",
            "\n",
            "📋 Example METADATA:\n",
            "  Input: markdown_content (length: 51831)\n",
            "  Output: first_author='Qi', population_code='2'\n",
            "\n",
            "📋 Example INTERVENTIONS:\n",
            "  Input: markdown_content (length: 51831)\n",
            "  Output: 3 interventions\n",
            "    1. Acetaminophen 1000mg (n=239)\n",
            "    2. Acetaminophen 650mg (n=241)\n",
            "    3.  (n=60)\n",
            "\n",
            "📋 Example OUTCOMES:\n",
            "  Input: intervention='Acetaminophen 1000mg'\n",
            "  Output: 15 outcomes\n",
            "    1. Type 2, 4 hours: 48.04/239 (20.1%)\n",
            "    2. Type 1, 6 hours: 70.03/239 (29.3%)\n",
            "    ... and 13 more\n",
            "\n",
            "📋 Example STRUCTURE:\n",
            "  Input: study metadata + intervention + outcome\n",
            "  Output: Qi - Acetaminophen 1000mg - Type 2\n"
          ]
        }
      ],
      "source": [
        "def create_training_examples_from_records(one_study_records, markdown_content):\n",
        "    \"\"\"\n",
        "    Create proper DSPy training examples from existing study records.\n",
        "    This creates examples for each signature: metadata, interventions, and outcomes.\n",
        "    \"\"\"\n",
        "    \n",
        "    if not one_study_records:\n",
        "        print(\"No study records provided!\")\n",
        "        return []\n",
        "    \n",
        "    # Get basic study info from first record\n",
        "    first_record = one_study_records[0]\n",
        "    first_author = first_record['First_Author']\n",
        "    population_code = str(first_record['Population'])\n",
        "    \n",
        "    print(f\"Creating examples for study: {first_author}\")\n",
        "    print(f\"Population code: {population_code}\")\n",
        "    \n",
        "    # Group records by intervention\n",
        "    interventions_data = defaultdict(list)\n",
        "    for record in one_study_records:\n",
        "        intervention_key = record['Intervention_Description']\n",
        "        interventions_data[intervention_key].append(record)\n",
        "    \n",
        "    print(f\"Found {len(interventions_data)} interventions:\")\n",
        "    for intervention, records in interventions_data.items():\n",
        "        print(f\"  - {intervention}: {len(records)} outcomes\")\n",
        "    \n",
        "    # Create training examples\n",
        "    training_examples = []\n",
        "    \n",
        "    # 1. METADATA EXTRACTION EXAMPLE\n",
        "    metadata_example = dspy.Example(\n",
        "        markdown_content=markdown_content,\n",
        "        first_author=first_author,\n",
        "        population_code=population_code\n",
        "    ).with_inputs(\"markdown_content\")\n",
        "    \n",
        "    training_examples.append((\"metadata\", metadata_example))\n",
        "    \n",
        "    # 2. INTERVENTIONS EXTRACTION EXAMPLE\n",
        "    # Create list of unique interventions with their participant counts\n",
        "    interventions_list = []\n",
        "    for intervention_desc, records in interventions_data.items():\n",
        "        # Get intervention code and participant count from first record of each intervention\n",
        "        first_record_for_intervention = records[0]\n",
        "        intervention_info = {\n",
        "            \"intervention_code\": first_record_for_intervention['Intervention_Code'],\n",
        "            \"intervention_description\": intervention_desc,\n",
        "            \"n_analyzed\": first_record_for_intervention['N_Analyzed']\n",
        "        }\n",
        "        interventions_list.append(intervention_info)\n",
        "    \n",
        "    interventions_example = dspy.Example(\n",
        "        markdown_content=markdown_content,\n",
        "        interventions_json=json.dumps(interventions_list, indent=2)\n",
        "    ).with_inputs(\"markdown_content\")\n",
        "    \n",
        "    training_examples.append((\"interventions\", interventions_example))\n",
        "    \n",
        "    # 3. OUTCOMES EXTRACTION EXAMPLES\n",
        "    # Create one example for each intervention\n",
        "    for intervention_desc, records in interventions_data.items():\n",
        "        \n",
        "        # Convert records to the expected outcome format\n",
        "        outcomes_list = []\n",
        "        for record in records:\n",
        "            outcome_info = {\n",
        "                \"outcome_type\": record['Outcome_Type'],\n",
        "                \"follow_up_time\": record['Follow_Up_Time'],\n",
        "                \"n_analyzed\": record['N_Analyzed'],\n",
        "                \"n_events_number\": record['N_Events_Number'],\n",
        "                \"n_events_percentage\": float(record['N_Events_Percentage']),\n",
        "                \"adverse_effect_specify\": record['Adverse_Effect_Specify'] if record['Adverse_Effect_Specify'] else \"NA\",\n",
        "                \"other_outcome_specify\": record['Outcome_Other_Specify'] if record['Outcome_Other_Specify'] else \"NA\",\n",
        "                \"adverse_effects_all_study\": record['Adverse_Effects_All_Study'] if record['Adverse_Effects_All_Study'] else \"NA\",\n",
        "                \"extraction_notes\": f\"From study data for {intervention_desc}\",\n",
        "                \"comments\": record['Comments']\n",
        "            }\n",
        "            outcomes_list.append(outcome_info)\n",
        "        \n",
        "        outcomes_example = dspy.Example(\n",
        "            markdown_content=markdown_content,\n",
        "            intervention_description=intervention_desc,\n",
        "            all_outcomes_json=json.dumps(outcomes_list, indent=2)\n",
        "        ).with_inputs(\"markdown_content\", \"intervention_description\")\n",
        "        \n",
        "        training_examples.append((\"outcomes\", outcomes_example))\n",
        "    \n",
        "    # 4. STRUCTURED RECORD EXAMPLES\n",
        "    # Create examples for the final structuring step\n",
        "    for record in one_study_records[:3]:  # Just use first 3 as examples\n",
        "        \n",
        "        # Create the input data\n",
        "        study_metadata = {\n",
        "            \"first_author\": record['First_Author'],\n",
        "            \"population_code\": record['Population']\n",
        "        }\n",
        "        \n",
        "        intervention_data = {\n",
        "            \"intervention_code\": record['Intervention_Code'],\n",
        "            \"intervention_description\": record['Intervention_Description'],\n",
        "            \"n_analyzed\": record['N_Analyzed']\n",
        "        }\n",
        "        \n",
        "        outcome_data = {\n",
        "            \"outcome_type\": record['Outcome_Type'],\n",
        "            \"follow_up_time\": record['Follow_Up_Time'],\n",
        "            \"n_analyzed\": record['N_Analyzed'],\n",
        "            \"n_events_number\": record['N_Events_Number'],\n",
        "            \"n_events_percentage\": float(record['N_Events_Percentage']),\n",
        "            \"adverse_effect_specify\": record['Adverse_Effect_Specify'] if record['Adverse_Effect_Specify'] else \"NA\",\n",
        "            \"other_outcome_specify\": record['Outcome_Other_Specify'] if record['Outcome_Other_Specify'] else \"NA\",\n",
        "            \"adverse_effects_all_study\": record['Adverse_Effects_All_Study'] if record['Adverse_Effects_All_Study'] else \"NA\",\n",
        "            \"extraction_notes\": f\"From study data\",\n",
        "            \"comments\": record['Comments']\n",
        "        }\n",
        "        \n",
        "        # Create expected output\n",
        "        expected_output = {\n",
        "            \"First_Author\": record['First_Author'],\n",
        "            \"Population\": record['Population'],\n",
        "            \"Intervention_Code\": record['Intervention_Code'],\n",
        "            \"Intervention_Description\": record['Intervention_Description'],\n",
        "            \"Outcome_Type\": record['Outcome_Type'],\n",
        "            \"Outcome_Other_Specify\": record['Outcome_Other_Specify'],\n",
        "            \"Follow_Up_Time\": record['Follow_Up_Time'],\n",
        "            \"N_Analyzed\": record['N_Analyzed'],\n",
        "            \"Adverse_Effect_Specify\": record['Adverse_Effect_Specify'],\n",
        "            \"Adverse_Effects_All_Study\": record['Adverse_Effects_All_Study'],\n",
        "            \"N_Events_Number\": record['N_Events_Number'],\n",
        "            \"N_Events_Percentage\": float(record['N_Events_Percentage']),\n",
        "            \"Comments\": record['Comments']\n",
        "        }\n",
        "        \n",
        "        structure_example = dspy.Example(\n",
        "            study_metadata_json=json.dumps(study_metadata),\n",
        "            intervention_json=json.dumps(intervention_data),\n",
        "            outcome_json=json.dumps(outcome_data),\n",
        "            structured_record_json=json.dumps(expected_output, indent=2)\n",
        "        ).with_inputs(\"study_metadata_json\", \"intervention_json\", \"outcome_json\")\n",
        "        \n",
        "        training_examples.append((\"structure\", structure_example))\n",
        "    \n",
        "    print(f\"✓ Created 3 structure examples\")\n",
        "    \n",
        "    # Print summary and examples\n",
        "    print(f\"\\n📊 TOTAL EXAMPLES CREATED: {len(training_examples)}\")\n",
        "    \n",
        "    # Show example of each type\n",
        "    example_types = [\"metadata\", \"interventions\", \"outcomes\", \"structure\"]\n",
        "    for ex_type in example_types:\n",
        "        example = next((ex for ex_type_found, ex in training_examples if ex_type_found == ex_type), None)\n",
        "        if example:\n",
        "            print(f\"\\n📋 Example {ex_type.upper()}:\")\n",
        "            if ex_type == \"metadata\":\n",
        "                print(f\"  Input: markdown_content (length: {len(example.markdown_content)})\")\n",
        "                print(f\"  Output: first_author='{example.first_author}', population_code='{example.population_code}'\")\n",
        "            elif ex_type == \"interventions\":\n",
        "                interventions_data = safe_json_parse(example.interventions_json)\n",
        "                print(f\"  Input: markdown_content (length: {len(example.markdown_content)})\")\n",
        "                print(f\"  Output: {len(interventions_data)} interventions\")\n",
        "                for i, intervention in enumerate(interventions_data):\n",
        "                    print(f\"    {i+1}. {intervention['intervention_description']} (n={intervention['n_analyzed']})\")\n",
        "            elif ex_type == \"outcomes\":\n",
        "                outcomes_data = safe_json_parse(example.all_outcomes_json)\n",
        "                print(f\"  Input: intervention='{example.intervention_description}'\")\n",
        "                print(f\"  Output: {len(outcomes_data)} outcomes\")\n",
        "                for i, outcome in enumerate(outcomes_data[:2]):  # Show first 2\n",
        "                    print(f\"    {i+1}. Type {outcome['outcome_type']}, {outcome['follow_up_time']}: {outcome['n_events_number']}/{outcome['n_analyzed']} ({outcome['n_events_percentage']}%)\")\n",
        "                if len(outcomes_data) > 2:\n",
        "                    print(f\"    ... and {len(outcomes_data) - 2} more\")\n",
        "            elif ex_type == \"structure\":\n",
        "                output_data = safe_json_parse(example.structured_record_json)\n",
        "                print(f\"  Input: study metadata + intervention + outcome\")\n",
        "                print(f\"  Output: {output_data['First_Author']} - {output_data['Intervention_Description']} - Type {output_data['Outcome_Type']}\")\n",
        "    \n",
        "    return training_examples\n",
        "\n",
        "# Usage:\n",
        "training_examples = create_training_examples_from_records(one_study_records, markdown_content)\n",
        "# metadata_examples = [ex for ex_type, ex in training_examples if ex_type == 'metadata']\n",
        "# intervention_examples = [ex for ex_type, ex in training_examples if ex_type == 'interventions']\n",
        "outcome_examples = [ex for ex_type, ex in training_examples if ex_type == 'outcomes']\n",
        "# structure_examples = [ex for ex_type, ex in training_examples if ex_type == 'structure']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dspy.primitives.example.Example"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dspy.Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. DSPy Optimizers Setup and Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up BootstrapFewShot optimizer...\n",
            "Setting up LabeledFewShot optimizer...\n",
            "Optimizers initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Setup optimizers\n",
        "from dspy.teleprompt import BootstrapFewShot, LabeledFewShot\n",
        "\n",
        "# Define metric for optimization\n",
        "def medical_extraction_metric(example, prediction, trace=None):\n",
        "    \"\"\"Custom metric for medical extraction quality.\"\"\"\n",
        "    try:\n",
        "        # Check if key fields are extracted correctly\n",
        "        score = 0.0\n",
        "        total_fields = 4  # ref_id, first_author, trial_name, population_code\n",
        "        \n",
        "        if hasattr(prediction, 'ref_id') and prediction.ref_id == example.ref_id:\n",
        "            score += 1\n",
        "        if hasattr(prediction, 'first_author') and prediction.first_author.lower() == example.first_author.lower():\n",
        "            score += 1\n",
        "        if hasattr(prediction, 'trial_name'):\n",
        "            score += 1  # Trial name can be flexible\n",
        "        if hasattr(prediction, 'population_code') and prediction.population_code == example.population_code:\n",
        "            score += 1\n",
        "        \n",
        "        return score / total_fields\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# Initialize optimizers\n",
        "if training_examples:\n",
        "    print(\"Setting up BootstrapFewShot optimizer...\")\n",
        "    bootstrap_optimizer = BootstrapFewShot(\n",
        "        metric=medical_extraction_metric,\n",
        "        max_bootstrapped_demos=3,\n",
        "        max_labeled_demos=2\n",
        "    )\n",
        "    \n",
        "    print(\"Setting up LabeledFewShot optimizer...\")\n",
        "    labeled_optimizer = LabeledFewShot(k=2)\n",
        "    \n",
        "    print(\"Optimizers initialized successfully\")\n",
        "else:\n",
        "    print(\"No training examples available for optimization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing StudyMetadataExtractor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:20<00:00, 20.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 0 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Optimization completed successfully\n",
            "\\nOptimized metadata extraction result:\n",
            "{'ref_id': '1655257', 'first_author': 'Cooper', 'trial_name': 'NR', 'population_code': '2'}\n"
          ]
        }
      ],
      "source": [
        "# Optimize the metadata extractor\n",
        "if training_examples:\n",
        "    try:\n",
        "        print(\"Optimizing StudyMetadataExtractor...\")\n",
        "        \n",
        "        # Compile with BootstrapFewShot\n",
        "        optimized_metadata_extractor = bootstrap_optimizer.compile(\n",
        "            StudyMetadataExtractor(),\n",
        "            trainset=[metadata_example]  # Use metadata example\n",
        "        )\n",
        "        \n",
        "        print(\"Optimization completed successfully\")\n",
        "        \n",
        "        # Test optimized extractor\n",
        "        test_result = optimized_metadata_extractor(markdown_content[:2000])\n",
        "        print(\"\\\\nOptimized metadata extraction result:\")\n",
        "        print(test_result)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Optimization failed: {e}\")\n",
        "        print(\"Using baseline extractor\")\n",
        "        optimized_metadata_extractor = StudyMetadataExtractor()\n",
        "else:\n",
        "    print(\"Using baseline extractor (no training data)\")\n",
        "    optimized_metadata_extractor = StudyMetadataExtractor()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Optimized Pipeline and Final Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized pipeline initialized with baseline components\n"
          ]
        }
      ],
      "source": [
        "# Create optimized pipeline\n",
        "class OptimizedMedicalDataExtractionPipeline(dspy.Module):\n",
        "    \"\"\"Optimized version of the extraction pipeline.\"\"\"\n",
        "    \n",
        "    def __init__(self, optimized_metadata_extractor=None):\n",
        "        super().__init__()\n",
        "        self.metadata_extractor = optimized_metadata_extractor or StudyMetadataExtractor()\n",
        "        self.intervention_extractor = InterventionExtractor()\n",
        "        self.outcome_extractor = OutcomeExtractor()\n",
        "        self.data_structurer = DataStructurer()\n",
        "    \n",
        "    def forward(self, markdown_content: str):\n",
        "        \"\"\"Extract all structured records from markdown content.\"\"\"\n",
        "        \n",
        "        print(\"=== OPTIMIZED EXTRACTION PIPELINE ===\")\n",
        "        \n",
        "        # Step 1: Extract study metadata\n",
        "        print(\"Extracting study metadata...\")\n",
        "        study_metadata = self.metadata_extractor(markdown_content)\n",
        "        print(f\"Study metadata: {study_metadata}\")\n",
        "        \n",
        "        # Step 2: Extract interventions\n",
        "        print(\"Extracting interventions...\")\n",
        "        interventions = self.intervention_extractor(markdown_content)\n",
        "        print(f\"Found {len(interventions)} interventions\")\n",
        "        print(interventions)\n",
        "        \n",
        "        # Step 3: For each intervention, extract outcomes and structure data\n",
        "        all_records = []\n",
        "        \n",
        "        for i, intervention in enumerate(interventions):\n",
        "            print(f\"Processing intervention {i+1}: {intervention.get('intervention_description', 'Unknown')}\")\n",
        "            \n",
        "            outcomes = self.outcome_extractor(\n",
        "                markdown_content, \n",
        "                intervention.get('intervention_description', '')\n",
        "            )\n",
        "            \n",
        "            print(f\"Found {len(outcomes)} outcomes for this intervention\")\n",
        "            \n",
        "            for j, outcome in enumerate(outcomes):\n",
        "                outcome_description = outcome.get('adverse_effect_specify', outcome.get('other_outcome_specify', 'Unknown'))\n",
        "                #print(f\"  Structuring outcome {j+1}: {outcome_description}\")\n",
        "                \n",
        "                structured_record = self.data_structurer(\n",
        "                    study_metadata, \n",
        "                    intervention, \n",
        "                    outcome\n",
        "                )\n",
        "                all_records.append(structured_record)\n",
        "        \n",
        "        print(f\"Total records extracted: {len(all_records)}\")\n",
        "        \n",
        "        # Return a dspy.Prediction object instead of a raw list\n",
        "        return dspy.Prediction(extracted_records=all_records)\n",
        "\n",
        "\n",
        "# Initialize optimized pipeline\n",
        "try:\n",
        "    optimized_pipeline = OptimizedMedicalDataExtractionPipeline(optimized_metadata_extractor)\n",
        "    print(\"Optimized pipeline initialized\")\n",
        "except:\n",
        "    optimized_pipeline = OptimizedMedicalDataExtractionPipeline()\n",
        "    print(\"Optimized pipeline initialized with baseline components\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Performance Comparison and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PERFORMANCE COMPARISON:\n",
            "==================================================\n",
            "          Metric  Baseline  Optimized  Ground Truth\n",
            "    Completeness  0.941558   0.941558           1.0\n",
            "Overall Accuracy  0.292208   0.292208           1.0\n",
            "     Num Records 11.000000  11.000000          45.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n📊 SUMMARY:\n",
            "Ground Truth Records: 45\n",
            "Baseline Extracted: 11\n",
            "Optimized Extracted: 11\n",
            "Baseline Completeness: 94.16%\n",
            "Optimized Completeness: 94.16%\n"
          ]
        }
      ],
      "source": [
        "# Compare baseline vs optimized performance\n",
        "try:\n",
        "    baseline_completeness = baseline_evaluation.get('completeness', 0.0)\n",
        "    baseline_accuracy = baseline_evaluation.get('overall_accuracy', 0.0)\n",
        "    baseline_count = len(baseline_results) if 'baseline_results' in locals() else 0\n",
        "except:\n",
        "    baseline_completeness = 0.0\n",
        "    baseline_accuracy = 0.0\n",
        "    baseline_count = 0\n",
        "\n",
        "try:\n",
        "    optimized_completeness = optimized_evaluation.get('completeness', 0.0)\n",
        "    optimized_accuracy = optimized_evaluation.get('overall_accuracy', 0.0)\n",
        "    optimized_count = len(optimized_results) if 'optimized_results' in locals() else 0\n",
        "except:\n",
        "    optimized_completeness = 0.0\n",
        "    optimized_accuracy = 0.0\n",
        "    optimized_count = 0\n",
        "\n",
        "comparison_data = {\n",
        "    'Metric': ['Completeness', 'Overall Accuracy', 'Num Records'],\n",
        "    'Baseline': [baseline_completeness, baseline_accuracy, baseline_count],\n",
        "    'Optimized': [optimized_completeness, optimized_accuracy, optimized_count],\n",
        "    'Ground Truth': [1.0, 1.0, len(one_study_records)]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"PERFORMANCE COMPARISON:\")\n",
        "print(\"=\" * 50)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Performance metrics comparison\n",
        "metrics_data = comparison_df[comparison_df['Metric'].isin(['Completeness', 'Overall Accuracy'])]\n",
        "x = range(len(metrics_data))\n",
        "width = 0.25\n",
        "\n",
        "axes[0].bar([i - width for i in x], metrics_data['Baseline'], width, label='Baseline', alpha=0.8, color='lightblue')\n",
        "axes[0].bar(x, metrics_data['Optimized'], width, label='Optimized', alpha=0.8, color='orange')\n",
        "axes[0].bar([i + width for i in x], metrics_data['Ground Truth'], width, label='Ground Truth', alpha=0.8, color='green')\n",
        "\n",
        "axes[0].set_xlabel('Metrics')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Performance Comparison')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(metrics_data['Metric'])\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1.1)\n",
        "\n",
        "# Record count comparison\n",
        "record_data = ['Baseline', 'Optimized', 'Ground Truth']\n",
        "record_counts = [baseline_count, optimized_count, len(one_study_records)]\n",
        "\n",
        "bars = axes[1].bar(record_data, record_counts, alpha=0.8, color=['lightblue', 'orange', 'green'])\n",
        "axes[1].set_xlabel('Method')\n",
        "axes[1].set_ylabel('Number of Records')\n",
        "axes[1].set_title('Record Count Comparison')\n",
        "\n",
        "for i, v in enumerate(record_counts):\n",
        "    axes[1].text(i, v + 0.1, str(v), ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\\\n📊 SUMMARY:\")\n",
        "print(f\"Ground Truth Records: {len(one_study_records)}\")\n",
        "print(f\"Baseline Extracted: {baseline_count}\")\n",
        "print(f\"Optimized Extracted: {optimized_count}\")\n",
        "print(f\"Baseline Completeness: {baseline_completeness:.2%}\")\n",
        "print(f\"Optimized Completeness: {optimized_completeness:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save Results and Export Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save extracted results\n",
        "output_dir = Path(\"/nlp/data/karthik9/Sprint1/Dental/dspy_output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save baseline results\n",
        "if 'baseline_results' in locals() and baseline_results:\n",
        "    with open(output_dir / \"baseline_extracted_records.json\", 'w') as f:\n",
        "        json.dump(baseline_results, f, indent=2)\n",
        "    print(\"✅ Saved baseline results\")\n",
        "\n",
        "# Save optimized results\n",
        "if 'optimized_results' in locals() and optimized_results:\n",
        "    with open(output_dir / \"optimized_extracted_records.json\", 'w') as f:\n",
        "        json.dump(optimized_results, f, indent=2)\n",
        "    print(\"✅ Saved optimized results\")\n",
        "\n",
        "# Save evaluation results\n",
        "evaluation_summary = {\n",
        "    \"baseline_evaluation\": baseline_evaluation if 'baseline_evaluation' in locals() else {},\n",
        "    \"optimized_evaluation\": optimized_evaluation if 'optimized_evaluation' in locals() else {},\n",
        "    \"ground_truth_count\": len(one_study_records),\n",
        "    \"comparison_summary\": comparison_data if 'comparison_data' in locals() else {}\n",
        "}\n",
        "\n",
        "with open(output_dir / \"evaluation_results.json\", 'w') as f:\n",
        "    json.dump(evaluation_summary, f, indent=2)\n",
        "\n",
        "# Save ground truth for reference\n",
        "with open(output_dir / \"ground_truth_1.json\", 'w') as f:\n",
        "    json.dump(one_study_records, f, indent=2)\n",
        "\n",
        "print(f\"\\\\n📁 Results saved to {output_dir}\")\n",
        "print(\"\\\\nFiles created:\")\n",
        "for file in output_dir.glob(\"*\"):\n",
        "    print(f\"  - {file.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Production Pipeline Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_medical_data(markdown_content: str, use_optimized: bool = True) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Production function for extracting medical data from markdown.\n",
        "    \n",
        "    Args:\n",
        "        markdown_content: Full markdown content of medical research paper\n",
        "        use_optimized: Whether to use optimized pipeline (default: True)\n",
        "    \n",
        "    Returns:\n",
        "        List of structured records matching dichotomous_outcomes.json format\n",
        "    \"\"\"\n",
        "    pipeline = optimized_pipeline if (use_optimized and 'optimized_pipeline' in locals()) else extraction_pipeline\n",
        "    \n",
        "    try:\n",
        "        prediction = pipeline(markdown_content)\n",
        "        # Extract the actual records from the DSPy Prediction object\n",
        "        return prediction.extracted_records if hasattr(prediction, 'extracted_records') else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error in extraction: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def batch_extract_medical_data(json_files: List[str], output_file: str) -> None:\n",
        "    \"\"\"Batch extraction from multiple JSON files.\n",
        "    \n",
        "    Args:\n",
        "        json_files: List of paths to JSON files with markdown content\n",
        "        output_file: Path to save combined results\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    \n",
        "    for file_path in json_files:\n",
        "        print(f\"Processing {file_path}...\")\n",
        "        \n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            \n",
        "            markdown_content = data.get('marker', {}).get('markdown', '')\n",
        "            \n",
        "            if markdown_content:\n",
        "                results = extract_medical_data(markdown_content)\n",
        "                all_results.extend(results)\n",
        "                print(f\"  Extracted {len(results)} records\")\n",
        "            else:\n",
        "                print(f\"  No markdown content found\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing {file_path}: {e}\")\n",
        "    \n",
        "    # Save combined results\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    \n",
        "    print(f\"\\\\nBatch extraction completed. Total records: {len(all_results)}\")\n",
        "    print(f\"Results saved to: {output_file}\")\n",
        "\n",
        "\n",
        "def quick_test_extraction(file_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"Quick test function for a single file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        markdown_content = data.get('marker', {}).get('markdown', '')\n",
        "        \n",
        "        if not markdown_content:\n",
        "            return {\"error\": \"No markdown content found\"}\n",
        "        \n",
        "        results = extract_medical_data(markdown_content)\n",
        "        evaluation = evaluator.evaluate(results)\n",
        "        \n",
        "        return {\n",
        "            \"file_path\": file_path,\n",
        "            \"extracted_records\": len(results),\n",
        "            \"completeness\": evaluation.get(\"completeness\", 0.0),\n",
        "            \"sample_record\": results[0] if results else None\n",
        "        }\n",
        "    \n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "print(\"Production functions defined:\")\n",
        "print(\"  - extract_medical_data(markdown_content, use_optimized=True)\")\n",
        "print(\"  - batch_extract_medical_data(json_files, output_file)\")\n",
        "print(\"  - quick_test_extraction(file_path)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Final Summary and Usage Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"🎉 DSPy 3.0.3 Medical Data Extraction Pipeline - COMPLETE! 🎉\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\\\n📊 PIPELINE SUMMARY:\")\n",
        "print(f\"  • Framework: DSPy 3.0.3 with ChainOfThought reasoning\")\n",
        "print(f\"  • Source Data: Medical research markdown (One Specific study)\")\n",
        "print(f\"  • Target Format: Dichotomous outcomes JSON structure\")\n",
        "print(f\"  • Ground Truth Records: {len(one_study_records)}\")\n",
        "\n",
        "print(\"\\\\n🔧 COMPONENTS IMPLEMENTED:\")\n",
        "print(\"  ✅ DSPy Signatures for medical data extraction\")\n",
        "print(\"  ✅ Modular pipeline with error handling\")\n",
        "print(\"  ✅ Baseline and optimized pipelines\")\n",
        "print(\"  ✅ Comprehensive evaluation framework\")\n",
        "print(\"  ✅ BootstrapFewShot optimizer\")\n",
        "print(\"  ✅ Performance visualization\")\n",
        "print(\"  ✅ Production-ready functions\")\n",
        "print(\"  ✅ Batch processing capabilities\")\n",
        "\n",
        "print(\"\\\\n🎯 KEY FEATURES:\")\n",
        "print(\"  • Structured extraction from medical research markdown\")\n",
        "print(\"  • Multi-intervention and multi-outcome support\")\n",
        "print(\"  • DSPy 3.0.3 optimization with rollout_id support\")\n",
        "print(\"  • JSON output with validation\")\n",
        "print(\"  • Comprehensive error handling\")\n",
        "\n",
        "print(\"\\\\n📁 OUTPUT FILES LOCATION:\")\n",
        "print(f\"  {output_dir}\")\n",
        "\n",
        "print(\"\\\\n🚀 USAGE EXAMPLES:\")\n",
        "print(\"\\\\n1. Extract from single markdown content:\")\n",
        "print(\"   results = extract_medical_data(markdown_content)\")\n",
        "\n",
        "print(\"\\\\n2. Batch process multiple files:\")\n",
        "print(\"   file_list = ['file1.json', 'file2.json']\")\n",
        "print(\"   batch_extract_medical_data(file_list, 'output.json')\")\n",
        "\n",
        "print(\"\\\\n3. Quick test a single file:\")\n",
        "print(\"   test_result = quick_test_extraction('/path/to/file.json')\")\n",
        "\n",
        "print(\"\\\\n🔄 NEXT STEPS:\")\n",
        "print(\"  1. Add your OpenAI API key to run the extraction\")\n",
        "print(\"  2. Test on additional medical papers\")\n",
        "print(\"  3. Fine-tune with more training examples\")\n",
        "print(\"  4. Scale to batch processing\")\n",
        "print(\"  5. Deploy as production service\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"Ready for production use! Add your API key and run the cells above.\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "topics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
