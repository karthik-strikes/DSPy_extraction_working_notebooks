{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374279b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlpgpu/data/karthik9/miniconda3/envs/topics/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy version: 3.0.3\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import aiofiles\n",
    "import traceback\n",
    "\n",
    "import tiktoken\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import diskcache as dc\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Print DSPy version\n",
    "print(f\"DSPy version: {dspy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b690ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language model configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Set your API key (uncomment and add your key)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Configure DSPy with OpenAI GPT-4o-mini for cost efficiency\n",
    "lm = dspy.LM('gemini/gemini-2.5-pro', max_tokens=20000, temperature=1.0)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"Language model configured successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640013eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dspy\n",
    "# from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# qa = dspy.ChainOfThought(\"question -> answer\")\n",
    "# trainset = [\n",
    "#     dspy.Example(question=\"What is the capital of France?\", answer=\"Paris\").with_inputs(\"question\"),\n",
    "#     dspy.Example(question=\"What is the capital of Germany?\", answer=\"Berlin\").with_inputs(\"question\"),\n",
    "# ]\n",
    "\n",
    "# def exact_match(pred, gold, trace=None):\n",
    "#     return pred.answer.strip().lower() == gold.answer.strip().lower()\n",
    "\n",
    "# fewshot_optimizer = BootstrapFewShot(metric=exact_match, max_bootstrapped_demos=2, max_labeled_demos=2)\n",
    "# qa_compiled = fewshot_optimizer.compile(student=qa, trainset=trainset)\n",
    "\n",
    "# # Save the optimized program\n",
    "# qa_compiled.save(\"optimized_qa.json\")\n",
    "\n",
    "# # Load the optimized program for future use\n",
    "# qa_loaded = dspy.ChainOfThought(\"question -> answer\")\n",
    "# qa_loaded.load(\"optimized_qa.json\")\n",
    "\n",
    "# # Inference\n",
    "# result = qa_loaded(question=\"What is the capital of Italy?\")\n",
    "# print(result.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dafd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
    "# # Import the optimizer\n",
    "# from dspy.teleprompt import MIPROv2\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize optimizer\n",
    "# teleprompter = MIPROv2(\n",
    "#     metric=gsm8k_metric,\n",
    "#     auto=\"light\", # Can choose between light, medium, and heavy optimization runs\n",
    "# )\n",
    "\n",
    "# # Optimize program\n",
    "# print(f\"Optimizing program with MIPROv2...\")\n",
    "# gsm8k = GSM8K()\n",
    "# optimized_program = teleprompter.compile(\n",
    "#     dspy.ChainOfThought(\"question -> answer\"),\n",
    "#     trainset=gsm8k.train,\n",
    "# )\n",
    "\n",
    "# # Save optimize program for future use\n",
    "# optimized_program.save(f\"optimized.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2) Recreate the same architecture/signature\n",
    "# prog = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "# # 3) Load the saved state (demos + instructions + configs)\n",
    "# prog.load(\"optimized.json\")\n",
    "\n",
    "# # 4) Use it\n",
    "# out = prog(question=\"If a pen costs $2 and I buy 7, how much do I pay?\")\n",
    "# print(\"Reasoning:\", getattr(out, \"reasoning\", None))\n",
    "# print(\"Answer:\", out.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
